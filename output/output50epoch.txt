Thu Oct 6 02:32:14 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_basic2.py
Started: 06/10/2022 02:32:19

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-initialtest
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_100f_devdata
train_filename: test_u_100f
evaluation_filename: train_u_50f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
per_device_train_batch_size: 4
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 55
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 500
save_strategy: epoch
save_steps: 500
fp16: False
load_best_model_at_end: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_100f.csv
--> data_test_fp: data/train_u_50f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.0548e+00,  1.2067e-01, -1.1413e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.6675e-03, -9.8046e-03,  8.6166e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.4337e-01, -2.1734e-01, -1.9753e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.9295e-02,  1.9548e-02,  1.7013e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 3, 1])}
Training DataCustom Files: 398
Training Data Files: 100
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.bias', 'quantizer.weight_proj.bias', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.weight', 'projector.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.2871, -0.3011, -0.3474,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.8762,  0.8288,  0.7099,  ...,  0.0000,  0.0000,  0.0000],
        [-0.9452, -0.7173, -0.7586,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0006,  0.3103, -0.6643,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 1, 2, 2])}
Test CustomData Files: 195
Test Data Files: 49
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Defining Classifer
--> Loading pre-trained checkpoint...
GPUs Used :  2 GPUs!
-------- Setting up Model --------
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
start train
start validation
Epoch 0 Train Acc 29.0% Val Acc 27.040815353393555% Train Loss 0.690994143486023 Val Loss 1.393726110458374
Trainable Parameters : 198660
start train
start validation
Epoch 1 Train Acc 30.0% Val Acc 28.224489212036133% Train Loss 0.6903977990150452 Val Loss 1.395411729812622
Trainable Parameters : 198660
start train
start validation
Epoch 2 Train Acc 32.25% Val Acc 27.040815353393555% Train Loss 0.6892780661582947 Val Loss 1.3984609842300415
Trainable Parameters : 198660
start train
start validation
Epoch 3 Train Acc 34.5% Val Acc 23.816326141357422% Train Loss 0.6861359477043152 Val Loss 1.4034779071807861
Trainable Parameters : 198660
start train
start validation
Epoch 4 Train Acc 38.5% Val Acc 25.346939086914062% Train Loss 0.6820877194404602 Val Loss 1.4121922254562378
Trainable Parameters : 198660
start train
start validation
Epoch 5 Train Acc 36.0% Val Acc 24.489795684814453% Train Loss 0.6786128282546997 Val Loss 1.4208399057388306
Trainable Parameters : 198660
start train
start validation
Epoch 6 Train Acc 42.0% Val Acc 24.836734771728516% Train Loss 0.6727016568183899 Val Loss 1.43690824508667
Trainable Parameters : 198660
start train
start validation
Epoch 7 Train Acc 39.0% Val Acc 25.0% Train Loss 0.6711317300796509 Val Loss 1.4480544328689575
Trainable Parameters : 198660
start train
start validation
Epoch 8 Train Acc 43.75% Val Acc 23.632652282714844% Train Loss 0.6709206104278564 Val Loss 1.4558038711547852
Trainable Parameters : 198660
start train
start validation
Epoch 9 Train Acc 43.0% Val Acc 21.59183692932129% Train Loss 0.6664429306983948 Val Loss 1.4658393859863281
Trainable Parameters : 198660
start train
start validation
Epoch 10 Train Acc 40.5% Val Acc 17.510204315185547% Train Loss 0.6613115668296814 Val Loss 1.4794455766677856
Trainable Parameters : 198660
start train
start validation
Epoch 11 Train Acc 46.5% Val Acc 20.918367385864258% Train Loss 0.6487501859664917 Val Loss 1.4989807605743408
Trainable Parameters : 198660
start train
start validation
Epoch 12 Train Acc 50.25% Val Acc 22.959182739257812% Train Loss 0.6466599702835083 Val Loss 1.5116922855377197
Trainable Parameters : 198660
start train
start validation
Epoch 13 Train Acc 47.0% Val Acc 16.163265228271484% Train Loss 0.6436054706573486 Val Loss 1.5245879888534546
Trainable Parameters : 198660
start train
start validation
Epoch 14 Train Acc 47.75% Val Acc 17.346939086914062% Train Loss 0.647074282169342 Val Loss 1.5335984230041504
Trainable Parameters : 198660
start train
start validation
Epoch 15 Train Acc 47.0% Val Acc 17.85714340209961% Train Loss 0.6358537077903748 Val Loss 1.538074254989624
Trainable Parameters : 198660
start train
start validation
Epoch 16 Train Acc 46.75% Val Acc 18.367345809936523% Train Loss 0.6334974765777588 Val Loss 1.549177646636963
Trainable Parameters : 198660
start train
start validation
Epoch 17 Train Acc 48.0% Val Acc 17.85714340209961% Train Loss 0.6260273456573486 Val Loss 1.564199447631836
Trainable Parameters : 198660
start train
start validation
Epoch 18 Train Acc 49.5% Val Acc 18.530611038208008% Train Loss 0.6162770390510559 Val Loss 1.5699834823608398
Trainable Parameters : 198660
start train
start validation
Epoch 19 Train Acc 49.25% Val Acc 17.346939086914062% Train Loss 0.6062338352203369 Val Loss 1.6196568012237549
Trainable Parameters : 198660
start train
start validation
Epoch 20 Train Acc 50.75% Val Acc 18.367345809936523% Train Loss 0.6080902814865112 Val Loss 1.6087485551834106
Trainable Parameters : 198660
start train
start validation
Epoch 21 Train Acc 52.5% Val Acc 16.163265228271484% Train Loss 0.5986446142196655 Val Loss 1.6532186269760132
Trainable Parameters : 198660
start train
start validation
Epoch 22 Train Acc 51.25% Val Acc 17.85714340209961% Train Loss 0.5895042419433594 Val Loss 1.6984916925430298
Trainable Parameters : 198660
start train
start validation
Epoch 23 Train Acc 53.25% Val Acc 17.510204315185547% Train Loss 0.5853633880615234 Val Loss 1.6899104118347168
Trainable Parameters : 198660
start train
start validation
Epoch 24 Train Acc 51.75% Val Acc 17.183673858642578% Train Loss 0.5783079862594604 Val Loss 1.7091137170791626
Trainable Parameters : 198660
start train
start validation
Epoch 25 Train Acc 55.5% Val Acc 16.836734771728516% Train Loss 0.5685129165649414 Val Loss 1.7859306335449219
Trainable Parameters : 198660
start train
start validation
Epoch 26 Train Acc 53.0% Val Acc 17.346939086914062% Train Loss 0.5694307088851929 Val Loss 1.825087070465088
Trainable Parameters : 198660
start train
start validation
Epoch 27 Train Acc 55.75% Val Acc 15.306121826171875% Train Loss 0.5570478439331055 Val Loss 1.8530433177947998
Trainable Parameters : 198660
start train
start validation
Epoch 28 Train Acc 55.75% Val Acc 19.5510196685791% Train Loss 0.5474683046340942 Val Loss 1.8382031917572021
Trainable Parameters : 198660
start train
start validation
Epoch 29 Train Acc 56.25% Val Acc 17.85714340209961% Train Loss 0.5505471229553223 Val Loss 1.9650410413742065
Trainable Parameters : 198660
start train
start validation
Epoch 30 Train Acc 55.25% Val Acc 16.836734771728516% Train Loss 0.5328912734985352 Val Loss 1.9996533393859863
Trainable Parameters : 198660
start train
start validation
Epoch 31 Train Acc 57.0% Val Acc 20.06122398376465% Train Loss 0.52900630235672 Val Loss 2.01708984375
Trainable Parameters : 198660
start train
start validation
Epoch 32 Train Acc 57.5% Val Acc 18.87755012512207% Train Loss 0.5162398219108582 Val Loss 2.0249555110931396
Trainable Parameters : 198660
start train
start validation
Epoch 33 Train Acc 58.0% Val Acc 17.346939086914062% Train Loss 0.5177451372146606 Val Loss 2.0729422569274902
Trainable Parameters : 198660
start train
start validation
Epoch 34 Train Acc 61.0% Val Acc 17.510204315185547% Train Loss 0.49775758385658264 Val Loss 2.1380467414855957
Trainable Parameters : 198660
start train
start validation
Epoch 35 Train Acc 60.75% Val Acc 19.387754440307617% Train Loss 0.4951637089252472 Val Loss 2.1090686321258545
Trainable Parameters : 198660
start train
start validation
Epoch 36 Train Acc 58.75% Val Acc 18.87755012512207% Train Loss 0.4910379648208618 Val Loss 2.3283920288085938
Trainable Parameters : 198660
start train
start validation
Epoch 37 Train Acc 61.0% Val Acc 19.387754440307617% Train Loss 0.4888112545013428 Val Loss 2.1133840084075928
Trainable Parameters : 198660
start train
start validation
Epoch 38 Train Acc 60.5% Val Acc 19.040815353393555% Train Loss 0.4842459261417389 Val Loss 2.2717652320861816
Trainable Parameters : 198660
start train
start validation
Epoch 39 Train Acc 62.0% Val Acc 19.040815353393555% Train Loss 0.46811458468437195 Val Loss 2.333980083465576
Trainable Parameters : 198660
start train
start validation
Epoch 40 Train Acc 62.75% Val Acc 18.714284896850586% Train Loss 0.4684253931045532 Val Loss 2.4431939125061035
Trainable Parameters : 198660
start train
start validation
Epoch 41 Train Acc 62.75% Val Acc 18.367345809936523% Train Loss 0.46400633454322815 Val Loss 2.3800323009490967
Trainable Parameters : 198660
start train
start validation
Epoch 42 Train Acc 67.0% Val Acc 24.489795684814453% Train Loss 0.44073882699012756 Val Loss 2.658421039581299
Trainable Parameters : 198660
start train
start validation
Epoch 43 Train Acc 63.5% Val Acc 18.87755012512207% Train Loss 0.4554360508918762 Val Loss 2.458256483078003
Trainable Parameters : 198660
start train
start validation
Epoch 44 Train Acc 64.75% Val Acc 20.40816307067871% Train Loss 0.4504062533378601 Val Loss 2.2692859172821045
Trainable Parameters : 198660
start train
start validation
Epoch 45 Train Acc 65.75% Val Acc 19.387754440307617% Train Loss 0.44002199172973633 Val Loss 2.575091600418091
Trainable Parameters : 198660
start train
start validation
Epoch 46 Train Acc 67.5% Val Acc 22.102041244506836% Train Loss 0.4303782284259796 Val Loss 2.7626562118530273
Trainable Parameters : 198660
start train
start validation
Epoch 47 Train Acc 68.0% Val Acc 20.571428298950195% Train Loss 0.42630431056022644 Val Loss 2.7331831455230713
Trainable Parameters : 198660
start train
start validation
Epoch 48 Train Acc 66.0% Val Acc 20.571428298950195% Train Loss 0.42526739835739136 Val Loss 2.7053256034851074
Trainable Parameters : 198660
start train
start validation
Epoch 49 Train Acc 67.0% Val Acc 17.0% Train Loss 0.42687028646469116 Val Loss 2.7132561206817627
Trainable Parameters : 198660
start train
start validation
Epoch 50 Train Acc 68.75% Val Acc 20.755102157592773% Train Loss 0.4126107394695282 Val Loss 2.747913122177124
Trainable Parameters : 198660
start train
start validation
Epoch 51 Train Acc 69.5% Val Acc 23.979591369628906% Train Loss 0.41486799716949463 Val Loss 2.5827858448028564
Trainable Parameters : 198660
start train
start validation
Epoch 52 Train Acc 68.75% Val Acc 23.306121826171875% Train Loss 0.40102115273475647 Val Loss 2.989295482635498
Trainable Parameters : 198660
start train
start validation
Epoch 53 Train Acc 70.5% Val Acc 22.61224365234375% Train Loss 0.3927525281906128 Val Loss 2.7095696926116943
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest/config.json
Model weights saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest/pytorch_model.bin
start train
start validation
Epoch 54 Train Acc 69.25% Val Acc 21.081632614135742% Train Loss 0.3843736946582794 Val Loss 2.8667778968811035

------> EVALUATING MODEL... ------------------------------------------ 

Traceback (most recent call last):
  File "/apps/python/3.8.3/lib/python3.8/site-packages/numpy-1.19.0-py3.8-linux-x86_64.egg/numpy/core/fromnumeric.py", line 58, in _wrapfunc
    return bound(*args, **kwds)
TypeError: argmax() got an unexpected keyword argument 'axis'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_basic2.py", line 797, in <module>
    trainer. _evaluate(testDataLoader, tst_itt)
  File "run_basic2.py", line 712, in _evaluate
    y_pred.append(np.argmax(p))
  File "<__array_function__ internals>", line 5, in argmax
  File "/apps/python/3.8.3/lib/python3.8/site-packages/numpy-1.19.0-py3.8-linux-x86_64.egg/numpy/core/fromnumeric.py", line 1188, in argmax
    return _wrapfunc(a, 'argmax', axis=axis, out=out)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/numpy-1.19.0-py3.8-linux-x86_64.egg/numpy/core/fromnumeric.py", line 67, in _wrapfunc
    return _wrapit(obj, method, *args, **kwds)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/numpy-1.19.0-py3.8-linux-x86_64.egg/numpy/core/fromnumeric.py", line 44, in _wrapit
    result = getattr(asarray(obj), method)(*args, **kwds)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/numpy-1.19.0-py3.8-linux-x86_64.egg/numpy/core/_asarray.py", line 83, in asarray
    return array(a, dtype, copy=False, order=order)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_tensor.py", line 757, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
