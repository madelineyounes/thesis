Thu Oct 13 23:21:00 AEDT 2022
------------------------------------------------------------------------
                         run_w2v.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_batch8.py
Started: 13/10/2022 23:21:04

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-batch-8
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 8
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-8
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-8_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0958,  0.5536,  0.0425,  ..., -2.0839, -2.1956, -2.4058],
        [ 0.6329,  0.0420, -0.9073,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.1531,  0.4644, -0.8612,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1755, -0.3334, -0.2864,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.4297,  1.2806,  1.7327,  ..., -0.5917, -0.5459, -0.5172],
        [-0.0250,  0.0584,  0.0300,  ..., -0.8939, -0.9500, -0.9602]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 0, 0, 0, 0, 0, 2, 0])}
Training DataCustom Files: 1963
Training Data Files: 246
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.2262,  0.1218,  0.1374,  ...,  0.6414,  0.9592,  1.0641],
        [-0.1817, -0.1589, -0.1653,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0415,  0.0250, -0.0307,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.6165,  1.6159,  3.0226,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3106, -0.0227, -0.0227,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4562,  0.2210, -0.0308,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 3, 0, 2, 3, 1, 1, 3])}
Test CustomData Files: 398
Test Data Files: 50
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 26.36585235595703% Val Acc 27.059999465942383% Train Loss 0.6935309767723083 Val Loss 1.3858648538589478
Trainable Parameters : 264452
Epoch 1 Train Acc 30.82520294189453% Val Acc 28.599998474121094% Train Loss 0.6906970143318176 Val Loss 1.3856017589569092
Trainable Parameters : 264452
Epoch 2 Train Acc 32.80894088745117% Val Acc 19.65999984741211% Train Loss 0.685222864151001 Val Loss 1.390383005142212
Trainable Parameters : 264452
Epoch 3 Train Acc 35.33333206176758% Val Acc 29.279998779296875% Train Loss 0.6789813041687012 Val Loss 1.3917803764343262
Trainable Parameters : 264452
Epoch 4 Train Acc 39.398372650146484% Val Acc 26.219999313354492% Train Loss 0.6705718040466309 Val Loss 1.401200532913208
Trainable Parameters : 264452
Epoch 5 Train Acc 42.83333206176758% Val Acc 30.139999389648438% Train Loss 0.6615596413612366 Val Loss 1.4163247346878052
Trainable Parameters : 264452
Epoch 6 Train Acc 45.59756088256836% Val Acc 26.34000015258789% Train Loss 0.6504005193710327 Val Loss 1.421671748161316
Trainable Parameters : 264452
Epoch 7 Train Acc 45.0406494140625% Val Acc 30.35999870300293% Train Loss 0.6422559022903442 Val Loss 1.4333916902542114
Trainable Parameters : 264452
Epoch 8 Train Acc 45.495933532714844% Val Acc 26.439998626708984% Train Loss 0.6312686800956726 Val Loss 1.4522007703781128
Trainable Parameters : 264452
Epoch 9 Train Acc 47.52032470703125% Val Acc 27.739999771118164% Train Loss 0.616643488407135 Val Loss 1.4701101779937744
Trainable Parameters : 264452
Epoch 10 Train Acc 49.39430618286133% Val Acc 29.35999870300293% Train Loss 0.6034567952156067 Val Loss 1.494697093963623
Trainable Parameters : 264452
Epoch 11 Train Acc 51.17073059082031% Val Acc 29.559999465942383% Train Loss 0.5908153057098389 Val Loss 1.525179147720337
Trainable Parameters : 264452
Epoch 12 Train Acc 51.5406494140625% Val Acc 30.3799991607666% Train Loss 0.5788070559501648 Val Loss 1.4904779195785522
Trainable Parameters : 264452
Epoch 13 Train Acc 52.82926559448242% Val Acc 29.0% Train Loss 0.5678704380989075 Val Loss 1.5388758182525635
Trainable Parameters : 264452
Epoch 14 Train Acc 53.979671478271484% Val Acc 31.420000076293945% Train Loss 0.554343044757843 Val Loss 1.5042845010757446
Trainable Parameters : 264452
Epoch 15 Train Acc 55.264225006103516% Val Acc 34.47999954223633% Train Loss 0.5431004762649536 Val Loss 1.535873532295227
Trainable Parameters : 264452
Epoch 16 Train Acc 56.89430618286133% Val Acc 32.86000061035156% Train Loss 0.5313441157341003 Val Loss 1.4929444789886475
Trainable Parameters : 264452
Epoch 17 Train Acc 57.15853500366211% Val Acc 34.97999954223633% Train Loss 0.5224665403366089 Val Loss 1.5176615715026855
Trainable Parameters : 264452
Epoch 18 Train Acc 57.13007736206055% Val Acc 34.939998626708984% Train Loss 0.5149210691452026 Val Loss 1.541416883468628
Trainable Parameters : 264452
Epoch 19 Train Acc 57.82926559448242% Val Acc 36.459999084472656% Train Loss 0.5012025833129883 Val Loss 1.5113980770111084
Trainable Parameters : 264452
Epoch 20 Train Acc 59.10162353515625% Val Acc 38.119998931884766% Train Loss 0.49818432331085205 Val Loss 1.5009572505950928
Trainable Parameters : 264452
Epoch 21 Train Acc 59.33333206176758% Val Acc 37.459999084472656% Train Loss 0.4952888488769531 Val Loss 1.523993968963623
Trainable Parameters : 264452
Epoch 22 Train Acc 61.65446853637695% Val Acc 33.599998474121094% Train Loss 0.48358383774757385 Val Loss 1.6039360761642456
Trainable Parameters : 264452
Epoch 23 Train Acc 64.27235412597656% Val Acc 26.84000015258789% Train Loss 0.4740709364414215 Val Loss 2.2462966442108154
Trainable Parameters : 264452
Epoch 24 Train Acc 61.81300735473633% Val Acc 37.599998474121094% Train Loss 0.47551968693733215 Val Loss 1.5690956115722656
Trainable Parameters : 264452
Epoch 25 Train Acc 61.71544647216797% Val Acc 37.39999771118164% Train Loss 0.46639272570610046 Val Loss 1.6226649284362793
Trainable Parameters : 264452
Epoch 26 Train Acc 63.081298828125% Val Acc 38.73999786376953% Train Loss 0.4569690227508545 Val Loss 1.577248454093933
Trainable Parameters : 264452
Epoch 27 Train Acc 65.081298828125% Val Acc 37.439998626708984% Train Loss 0.4446469843387604 Val Loss 1.7000223398208618
Trainable Parameters : 264452
Epoch 28 Train Acc 62.605690002441406% Val Acc 37.70000076293945% Train Loss 0.4532080888748169 Val Loss 1.6027973890304565
Trainable Parameters : 264452
Epoch 29 Train Acc 64.81707000732422% Val Acc 38.599998474121094% Train Loss 0.44673827290534973 Val Loss 1.6641982793807983
Trainable Parameters : 264452
Epoch 30 Train Acc 65.18292236328125% Val Acc 35.619998931884766% Train Loss 0.43656736612319946 Val Loss 1.9022778272628784
Trainable Parameters : 264452
Epoch 31 Train Acc 63.882110595703125% Val Acc 39.13999938964844% Train Loss 0.4362170994281769 Val Loss 1.614208698272705
Trainable Parameters : 264452
Epoch 32 Train Acc 64.6219482421875% Val Acc 36.959999084472656% Train Loss 0.4326958656311035 Val Loss 1.8720965385437012
Trainable Parameters : 264452
Epoch 33 Train Acc 65.50405883789062% Val Acc 35.119998931884766% Train Loss 0.43432801961898804 Val Loss 1.811768651008606
Trainable Parameters : 264452
Epoch 34 Train Acc 64.0975570678711% Val Acc 30.8799991607666% Train Loss 0.43038418889045715 Val Loss 2.177510976791382
Trainable Parameters : 264452
Epoch 35 Train Acc 66.30487823486328% Val Acc 39.63999938964844% Train Loss 0.43258002400398254 Val Loss 1.7065458297729492
Trainable Parameters : 264452
Epoch 36 Train Acc 65.5569076538086% Val Acc 39.18000030517578% Train Loss 0.4272722601890564 Val Loss 1.7324312925338745
Trainable Parameters : 264452
Epoch 37 Train Acc 66.43901824951172% Val Acc 36.79999923706055% Train Loss 0.42902520298957825 Val Loss 1.8676704168319702
Trainable Parameters : 264452
Epoch 38 Train Acc 64.32926940917969% Val Acc 38.37999725341797% Train Loss 0.4322943389415741 Val Loss 1.7011146545410156
Trainable Parameters : 264452
Epoch 39 Train Acc 65.10975646972656% Val Acc 32.63999938964844% Train Loss 0.42952391505241394 Val Loss 2.2632510662078857
Trainable Parameters : 264452
Epoch 40 Train Acc 66.67073059082031% Val Acc 36.459999084472656% Train Loss 0.42825910449028015 Val Loss 2.031632423400879
Trainable Parameters : 264452
Epoch 41 Train Acc 66.2276382446289% Val Acc 29.51999855041504% Train Loss 0.4265541732311249 Val Loss 2.035831928253174
Trainable Parameters : 264452
Epoch 42 Train Acc 65.60975646972656% Val Acc 40.81999969482422% Train Loss 0.4197535812854767 Val Loss 1.7216073274612427
Trainable Parameters : 264452
Epoch 43 Train Acc 67.36991882324219% Val Acc 39.040000915527344% Train Loss 0.41478151082992554 Val Loss 1.6619771718978882
Trainable Parameters : 264452
Epoch 44 Train Acc 66.27642059326172% Val Acc 41.34000015258789% Train Loss 0.41583988070487976 Val Loss 1.681485652923584
Trainable Parameters : 264452
Epoch 45 Train Acc 68.6788558959961% Val Acc 37.84000015258789% Train Loss 0.41364192962646484 Val Loss 1.7770556211471558
Trainable Parameters : 264452
Epoch 46 Train Acc 68.02032470703125% Val Acc 38.779998779296875% Train Loss 0.40573978424072266 Val Loss 2.1429240703582764
Trainable Parameters : 264452
Epoch 47 Train Acc 67.89024353027344% Val Acc 34.73999786376953% Train Loss 0.39871305227279663 Val Loss 1.796579360961914
Trainable Parameters : 264452
Epoch 48 Train Acc 68.74796295166016% Val Acc 37.459999084472656% Train Loss 0.3848716616630554 Val Loss 1.9189215898513794
Trainable Parameters : 264452
Epoch 49 Train Acc 69.67073059082031% Val Acc 39.86000061035156% Train Loss 0.39403918385505676 Val Loss 2.004025459289551
Trainable Parameters : 264452
Epoch 50 Train Acc 68.86585235595703% Val Acc 36.119998931884766% Train Loss 0.39771249890327454 Val Loss 2.282910108566284
Trainable Parameters : 264452
Epoch 51 Train Acc 68.94308471679688% Val Acc 43.279998779296875% Train Loss 0.3817996680736542 Val Loss 1.5870945453643799
Trainable Parameters : 264452
Epoch 52 Train Acc 70.36585235595703% Val Acc 38.439998626708984% Train Loss 0.3834739625453949 Val Loss 1.9598504304885864
Trainable Parameters : 264452
Epoch 53 Train Acc 68.69512176513672% Val Acc 42.20000076293945% Train Loss 0.389148473739624 Val Loss 1.6540189981460571
Trainable Parameters : 264452
Epoch 54 Train Acc 71.21544647216797% Val Acc 40.119998931884766% Train Loss 0.37754228711128235 Val Loss 1.7800697088241577
Trainable Parameters : 264452
Epoch 55 Train Acc 68.86991882324219% Val Acc 29.84000015258789% Train Loss 0.39171481132507324 Val Loss 2.4019856452941895
Trainable Parameters : 264452
Epoch 56 Train Acc 70.23577117919922% Val Acc 38.37999725341797% Train Loss 0.37702110409736633 Val Loss 2.005404233932495
Trainable Parameters : 264452
Epoch 57 Train Acc 69.32926940917969% Val Acc 34.21999740600586% Train Loss 0.3864533305168152 Val Loss 2.1443066596984863
Trainable Parameters : 264452
Epoch 58 Train Acc 71.0975570678711% Val Acc 32.47999954223633% Train Loss 0.3803304135799408 Val Loss 2.396049737930298
Trainable Parameters : 264452
Epoch 59 Train Acc 69.89836883544922% Val Acc 42.36000061035156% Train Loss 0.3832715153694153 Val Loss 1.9138072729110718
Trainable Parameters : 264452
Epoch 60 Train Acc 71.24796295166016% Val Acc 40.7599983215332% Train Loss 0.3741573989391327 Val Loss 1.9166526794433594
Trainable Parameters : 264452
Epoch 61 Train Acc 71.243896484375% Val Acc 39.89999771118164% Train Loss 0.36563870310783386 Val Loss 1.808961272239685
Trainable Parameters : 264452
Epoch 62 Train Acc 67.80487823486328% Val Acc 39.439998626708984% Train Loss 0.3865152597427368 Val Loss 2.046952962875366
Trainable Parameters : 264452
Epoch 63 Train Acc 70.60162353515625% Val Acc 38.13999938964844% Train Loss 0.36793801188468933 Val Loss 2.2135612964630127
Trainable Parameters : 264452
Epoch 64 Train Acc 70.0975570678711% Val Acc 34.959999084472656% Train Loss 0.37298330664634705 Val Loss 2.4977197647094727
Trainable Parameters : 264452
Epoch 65 Train Acc 71.27235412597656% Val Acc 43.65999984741211% Train Loss 0.36668938398361206 Val Loss 1.710766077041626
Trainable Parameters : 264452
Epoch 66 Train Acc 71.41056823730469% Val Acc 41.02000045776367% Train Loss 0.3622893989086151 Val Loss 1.9721170663833618
Trainable Parameters : 264452
Epoch 67 Train Acc 72.91869354248047% Val Acc 39.39999771118164% Train Loss 0.36143866181373596 Val Loss 1.7912942171096802
Trainable Parameters : 264452
Epoch 68 Train Acc 71.66666412353516% Val Acc 41.86000061035156% Train Loss 0.3478788435459137 Val Loss 1.737835168838501
Trainable Parameters : 264452
Epoch 69 Train Acc 71.40650177001953% Val Acc 41.21999740600586% Train Loss 0.3615593910217285 Val Loss 1.9392231702804565
Trainable Parameters : 264452
Epoch 70 Train Acc 71.89024353027344% Val Acc 41.439998626708984% Train Loss 0.3699449598789215 Val Loss 1.7640399932861328
Trainable Parameters : 264452
Epoch 71 Train Acc 70.38211059570312% Val Acc 43.57999801635742% Train Loss 0.36676734685897827 Val Loss 1.6602790355682373
Trainable Parameters : 264452
Epoch 72 Train Acc 72.65040588378906% Val Acc 38.39999771118164% Train Loss 0.35744115710258484 Val Loss 2.249110698699951
Trainable Parameters : 264452
Epoch 73 Train Acc 71.17073059082031% Val Acc 39.65999984741211% Train Loss 0.36267122626304626 Val Loss 1.8391176462173462
Trainable Parameters : 264452
Epoch 74 Train Acc 72.22357177734375% Val Acc 39.0% Train Loss 0.35736575722694397 Val Loss 2.0045347213745117
Trainable Parameters : 264452
Epoch 75 Train Acc 73.77235412597656% Val Acc 42.7599983215332% Train Loss 0.3411223292350769 Val Loss 1.7096989154815674
Trainable Parameters : 264452
Epoch 76 Train Acc 73.97154235839844% Val Acc 33.31999969482422% Train Loss 0.34497347474098206 Val Loss 1.993336796760559
Trainable Parameters : 264452
Epoch 77 Train Acc 73.69918060302734% Val Acc 36.29999923706055% Train Loss 0.3399088978767395 Val Loss 2.206766366958618
Trainable Parameters : 264452
Epoch 78 Train Acc 73.7682876586914% Val Acc 39.63999938964844% Train Loss 0.3369324207305908 Val Loss 1.9604582786560059
Trainable Parameters : 264452
Epoch 79 Train Acc 72.65447235107422% Val Acc 44.29999923706055% Train Loss 0.34438779950141907 Val Loss 1.7818620204925537
Trainable Parameters : 264452
Epoch 80 Train Acc 72.78455352783203% Val Acc 42.459999084472656% Train Loss 0.35109439492225647 Val Loss 1.8223360776901245
Trainable Parameters : 264452
Epoch 81 Train Acc 73.84959411621094% Val Acc 41.84000015258789% Train Loss 0.3339047431945801 Val Loss 1.7285237312316895
Trainable Parameters : 264452
Epoch 82 Train Acc 73.6056900024414% Val Acc 42.20000076293945% Train Loss 0.3446192145347595 Val Loss 1.7454997301101685
Trainable Parameters : 264452
Epoch 83 Train Acc 73.78861236572266% Val Acc 37.540000915527344% Train Loss 0.3455345034599304 Val Loss 2.2825429439544678
Trainable Parameters : 264452
Epoch 84 Train Acc 74.47154235839844% Val Acc 35.81999969482422% Train Loss 0.32891517877578735 Val Loss 2.0327041149139404
Trainable Parameters : 264452
Epoch 85 Train Acc 74.05284118652344% Val Acc 38.97999954223633% Train Loss 0.33571967482566833 Val Loss 2.3686177730560303
Trainable Parameters : 264452
Epoch 86 Train Acc 74.17479705810547% Val Acc 44.21999740600586% Train Loss 0.33329179883003235 Val Loss 1.6343330144882202
Trainable Parameters : 264452
Epoch 87 Train Acc 72.90650177001953% Val Acc 33.63999938964844% Train Loss 0.3462456166744232 Val Loss 2.0048816204071045
Trainable Parameters : 264452
Epoch 88 Train Acc 74.54471588134766% Val Acc 42.34000015258789% Train Loss 0.32890772819519043 Val Loss 1.8132116794586182
Trainable Parameters : 264452
Epoch 89 Train Acc 75.64227294921875% Val Acc 43.81999969482422% Train Loss 0.3311707079410553 Val Loss 1.7739524841308594
Trainable Parameters : 264452
Epoch 90 Train Acc 74.40650177001953% Val Acc 41.65999984741211% Train Loss 0.33883652091026306 Val Loss 1.7120765447616577
Trainable Parameters : 264452
Epoch 91 Train Acc 74.39024353027344% Val Acc 37.65999984741211% Train Loss 0.33882150053977966 Val Loss 2.2472984790802
Trainable Parameters : 264452
Epoch 92 Train Acc 75.34552764892578% Val Acc 42.97999954223633% Train Loss 0.32552051544189453 Val Loss 1.7624622583389282
Trainable Parameters : 264452
Epoch 93 Train Acc 74.89836883544922% Val Acc 42.619998931884766% Train Loss 0.32569485902786255 Val Loss 1.7376247644424438
Trainable Parameters : 264452
Epoch 94 Train Acc 75.35365295410156% Val Acc 41.41999816894531% Train Loss 0.3172752261161804 Val Loss 1.7887147665023804
Trainable Parameters : 264452
Epoch 95 Train Acc 76.19918060302734% Val Acc 42.34000015258789% Train Loss 0.32385993003845215 Val Loss 1.8939532041549683
Trainable Parameters : 264452
Epoch 96 Train Acc 75.7682876586914% Val Acc 44.39999771118164% Train Loss 0.31893837451934814 Val Loss 1.8605194091796875
Trainable Parameters : 264452
Epoch 97 Train Acc 74.65447235107422% Val Acc 43.2599983215332% Train Loss 0.3207325339317322 Val Loss 1.7097898721694946
Trainable Parameters : 264452
Epoch 98 Train Acc 73.48780059814453% Val Acc 42.040000915527344% Train Loss 0.329257607460022 Val Loss 1.927332878112793
Trainable Parameters : 264452
Epoch 99 Train Acc 75.41056823730469% Val Acc 39.13999938964844% Train Loss 0.3214081823825836 Val Loss 1.8699309825897217
Traceback (most recent call last):
  File "run_batch8.py", line 710, in <module>
    model.module.save_pretrained(model_fp)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1627, in save_pretrained
    model_to_save.config.save_pretrained(save_directory)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 445, in save_pretrained
    self.to_json_file(output_config_file, use_diff=True)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 823, in to_json_file
    with open(json_file_path, "w", encoding="utf-8") as writer:
OSError: [Errno 122] Disk quota exceeded: '../output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-8/config.json'
