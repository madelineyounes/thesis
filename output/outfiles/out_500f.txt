Mon Oct 10 03:01:04 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_500f.py
Started: 10/10/2022 03:01:08

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-500-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.5457, -0.7358, -0.9234,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3044,  0.4397,  0.5732,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3402, -0.3358, -0.2844,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.9031, -0.8424, -0.8000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0248,  0.0585, -0.0062,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1056, -0.0981, -0.0755,  ...,  0.0058, -0.0243,  0.0181]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 0, 0, 0, 2, 0, 3, 0, 3, 3, 0, 3])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'quantizer.weight_proj.weight', 'project_hid.bias', 'project_hid.weight', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 2.4396,  2.1874,  0.7738,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0304,  0.0434,  0.0624,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.8219,  0.5581, -0.2596,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.4381, -1.1493, -1.1702,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3354, -0.3187, -0.2942,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6280,  0.3482,  0.2181,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 1, 3, 2, 0, 3, 3, 2, 0, 2, 2])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 26.26219367980957% Val Acc 26.712575912475586% Train Loss 0.6955417990684509 Val Loss 1.3849544525146484
Trainable Parameters : 198660
Epoch 1 Train Acc 25.2439022064209% Val Acc 27.179641723632812% Train Loss 0.6935138702392578 Val Loss 1.3841384649276733
Trainable Parameters : 198660
Epoch 2 Train Acc 27.249998092651367% Val Acc 26.18562889099121% Train Loss 0.6906962990760803 Val Loss 1.384509801864624
Trainable Parameters : 198660
Epoch 3 Train Acc 29.969511032104492% Val Acc 23.934133529663086% Train Loss 0.6885492205619812 Val Loss 1.3861804008483887
Trainable Parameters : 198660
Epoch 4 Train Acc 31.487804412841797% Val Acc 24.299402236938477% Train Loss 0.6856342554092407 Val Loss 1.388248085975647
Trainable Parameters : 198660
Epoch 5 Train Acc 33.71950912475586% Val Acc 25.191617965698242% Train Loss 0.6813624501228333 Val Loss 1.3905423879623413
Trainable Parameters : 198660
Epoch 6 Train Acc 34.01829147338867% Val Acc 23.2215576171875% Train Loss 0.6782031655311584 Val Loss 1.3990795612335205
Trainable Parameters : 198660
Epoch 7 Train Acc 34.896339416503906% Val Acc 24.125749588012695% Train Loss 0.6732631921768188 Val Loss 1.402762532234192
Trainable Parameters : 198660
Epoch 8 Train Acc 34.67682647705078% Val Acc 23.00598907470703% Train Loss 0.6710433959960938 Val Loss 1.4052492380142212
Trainable Parameters : 198660
Epoch 9 Train Acc 37.17682647705078% Val Acc 22.970060348510742% Train Loss 0.6655190587043762 Val Loss 1.4214751720428467
Trainable Parameters : 198660
Epoch 10 Train Acc 36.6219482421875% Val Acc 22.922157287597656% Train Loss 0.6620939373970032 Val Loss 1.440959095954895
Trainable Parameters : 198660
Epoch 11 Train Acc 37.396339416503906% Val Acc 25.149702072143555% Train Loss 0.656997561454773 Val Loss 1.4397261142730713
Trainable Parameters : 198660
Epoch 12 Train Acc 38.60365676879883% Val Acc 22.934133529663086% Train Loss 0.6525505185127258 Val Loss 1.485514760017395
Trainable Parameters : 198660
Epoch 13 Train Acc 38.85365676879883% Val Acc 23.45509147644043% Train Loss 0.6453975439071655 Val Loss 1.4826737642288208
Trainable Parameters : 198660
Epoch 14 Train Acc 40.92073059082031% Val Acc 22.574851989746094% Train Loss 0.6413233280181885 Val Loss 1.515249490737915
Trainable Parameters : 198660
Epoch 15 Train Acc 42.32316970825195% Val Acc 23.203594207763672% Train Loss 0.6346786618232727 Val Loss 1.531598687171936
Trainable Parameters : 198660
Epoch 16 Train Acc 43.07316970825195% Val Acc 24.311378479003906% Train Loss 0.6285045146942139 Val Loss 1.5625990629196167
Trainable Parameters : 198660
Epoch 17 Train Acc 42.20121765136719% Val Acc 23.02395248413086% Train Loss 0.6242650151252747 Val Loss 1.6298757791519165
Trainable Parameters : 198660
Epoch 18 Train Acc 43.189022064208984% Val Acc 23.39521026611328% Train Loss 0.6158518195152283 Val Loss 1.6155681610107422
Trainable Parameters : 198660
Epoch 19 Train Acc 46.030487060546875% Val Acc 23.25748634338379% Train Loss 0.6088186502456665 Val Loss 1.6267980337142944
Trainable Parameters : 198660
Epoch 20 Train Acc 46.42073059082031% Val Acc 23.101797103881836% Train Loss 0.6001228094100952 Val Loss 1.7275489568710327
Trainable Parameters : 198660
Epoch 21 Train Acc 47.85365676879883% Val Acc 23.83832359313965% Train Loss 0.5943838953971863 Val Loss 1.6955828666687012
Trainable Parameters : 198660
Epoch 22 Train Acc 49.40853500366211% Val Acc 24.742515563964844% Train Loss 0.5869737863540649 Val Loss 1.8422712087631226
Trainable Parameters : 198660
Epoch 23 Train Acc 48.01829147338867% Val Acc 24.526947021484375% Train Loss 0.5862030386924744 Val Loss 1.7229489088058472
Trainable Parameters : 198660
Epoch 24 Train Acc 50.5% Val Acc 24.149702072143555% Train Loss 0.5735650658607483 Val Loss 1.7962663173675537
Trainable Parameters : 198660
Epoch 25 Train Acc 52.02438735961914% Val Acc 24.25748634338379% Train Loss 0.5661118626594543 Val Loss 1.8489540815353394
Trainable Parameters : 198660
Epoch 26 Train Acc 51.65853500366211% Val Acc 24.58682632446289% Train Loss 0.5644976496696472 Val Loss 1.9507900476455688
Trainable Parameters : 198660
Epoch 27 Train Acc 52.57316970825195% Val Acc 24.389223098754883% Train Loss 0.5533848404884338 Val Loss 2.0335826873779297
Trainable Parameters : 198660
Epoch 28 Train Acc 53.11585235595703% Val Acc 24.65868377685547% Train Loss 0.5481039881706238 Val Loss 2.128441333770752
Trainable Parameters : 198660
Epoch 29 Train Acc 54.993900299072266% Val Acc 27.2215576171875% Train Loss 0.5412684679031372 Val Loss 2.009411096572876
Trainable Parameters : 198660
Epoch 30 Train Acc 54.92682647705078% Val Acc 24.532934188842773% Train Loss 0.5329657793045044 Val Loss 2.081474542617798
Trainable Parameters : 198660
Epoch 31 Train Acc 56.457313537597656% Val Acc 24.02994155883789% Train Loss 0.5207056999206543 Val Loss 2.1587932109832764
Trainable Parameters : 198660
Epoch 32 Train Acc 57.35365676879883% Val Acc 25.934133529663086% Train Loss 0.5200104117393494 Val Loss 2.1456899642944336
Trainable Parameters : 198660
Epoch 33 Train Acc 58.249996185302734% Val Acc 26.305389404296875% Train Loss 0.5107429623603821 Val Loss 2.2380056381225586
Trainable Parameters : 198660
Epoch 34 Train Acc 57.554874420166016% Val Acc 26.538923263549805% Train Loss 0.5033093094825745 Val Loss 2.344118356704712
Trainable Parameters : 198660
Epoch 35 Train Acc 59.23170471191406% Val Acc 25.173654556274414% Train Loss 0.4998018145561218 Val Loss 2.176497220993042
Trainable Parameters : 198660
Epoch 36 Train Acc 59.67073059082031% Val Acc 25.700599670410156% Train Loss 0.4890030026435852 Val Loss 2.730797529220581
Trainable Parameters : 198660
Epoch 37 Train Acc 58.44511795043945% Val Acc 25.78443145751953% Train Loss 0.4908708930015564 Val Loss 2.4099202156066895
Trainable Parameters : 198660
Epoch 38 Train Acc 61.17682647705078% Val Acc 26.24551010131836% Train Loss 0.4788753092288971 Val Loss 2.6916239261627197
Trainable Parameters : 198660
Epoch 39 Train Acc 60.41463088989258% Val Acc 26.40718650817871% Train Loss 0.48267456889152527 Val Loss 2.7093474864959717
Trainable Parameters : 198660
Epoch 40 Train Acc 61.786582946777344% Val Acc 25.077844619750977% Train Loss 0.48051944375038147 Val Loss 2.6307880878448486
Trainable Parameters : 198660
Epoch 41 Train Acc 63.146339416503906% Val Acc 24.862276077270508% Train Loss 0.471345990896225 Val Loss 3.000199317932129
Trainable Parameters : 198660
Epoch 42 Train Acc 63.804874420166016% Val Acc 25.82634735107422% Train Loss 0.46596604585647583 Val Loss 2.800433397293091
Trainable Parameters : 198660
Epoch 43 Train Acc 62.841461181640625% Val Acc 26.03592872619629% Train Loss 0.4669094979763031 Val Loss 2.647418737411499
Trainable Parameters : 198660
Epoch 44 Train Acc 63.1341438293457% Val Acc 25.131736755371094% Train Loss 0.4608064889907837 Val Loss 3.1529862880706787
Trainable Parameters : 198660
Epoch 45 Train Acc 64.69512176513672% Val Acc 25.329341888427734% Train Loss 0.45188722014427185 Val Loss 3.338181972503662
Trainable Parameters : 198660
Epoch 46 Train Acc 63.17682647705078% Val Acc 24.898204803466797% Train Loss 0.45717278122901917 Val Loss 2.9560534954071045
Trainable Parameters : 198660
Epoch 47 Train Acc 62.98170471191406% Val Acc 24.904191970825195% Train Loss 0.4488730728626251 Val Loss 2.9622092247009277
Trainable Parameters : 198660
Epoch 48 Train Acc 63.82316970825195% Val Acc 25.43113899230957% Train Loss 0.4465828835964203 Val Loss 3.4154105186462402
Trainable Parameters : 198660
Epoch 49 Train Acc 64.62804412841797% Val Acc 25.389223098754883% Train Loss 0.4532991051673889 Val Loss 2.8352532386779785
Trainable Parameters : 198660
Epoch 50 Train Acc 66.83536529541016% Val Acc 25.706586837768555% Train Loss 0.43494436144828796 Val Loss 3.4055845737457275
Trainable Parameters : 198660
Epoch 51 Train Acc 65.39024353027344% Val Acc 25.64072036743164% Train Loss 0.4422660768032074 Val Loss 2.6311943531036377
Trainable Parameters : 198660
Epoch 52 Train Acc 65.1219482421875% Val Acc 25.550899505615234% Train Loss 0.4358293414115906 Val Loss 3.005913257598877
Trainable Parameters : 198660
Epoch 53 Train Acc 65.42073059082031% Val Acc 26.371257781982422% Train Loss 0.4309147894382477 Val Loss 3.343075752258301
Trainable Parameters : 198660
Epoch 54 Train Acc 65.01219177246094% Val Acc 25.2155704498291% Train Loss 0.43282902240753174 Val Loss 3.5685765743255615
Trainable Parameters : 198660
Epoch 55 Train Acc 65.68292236328125% Val Acc 25.742515563964844% Train Loss 0.4292142391204834 Val Loss 3.123547077178955
Trainable Parameters : 198660
Epoch 56 Train Acc 65.68901824951172% Val Acc 26.532934188842773% Train Loss 0.4299536645412445 Val Loss 2.8483481407165527
Trainable Parameters : 198660
Epoch 57 Train Acc 66.20121765136719% Val Acc 26.694612503051758% Train Loss 0.42040175199508667 Val Loss 2.8200037479400635
Trainable Parameters : 198660
Epoch 58 Train Acc 66.243896484375% Val Acc 25.461078643798828% Train Loss 0.41486620903015137 Val Loss 3.1452524662017822
Trainable Parameters : 198660
Epoch 59 Train Acc 67.5182876586914% Val Acc 25.18562889099121% Train Loss 0.41354498267173767 Val Loss 3.344095230102539
Trainable Parameters : 198660
Epoch 60 Train Acc 65.98780059814453% Val Acc 25.544910430908203% Train Loss 0.41744133830070496 Val Loss 3.153855800628662
Trainable Parameters : 198660
Epoch 61 Train Acc 66.93901824951172% Val Acc 24.922157287597656% Train Loss 0.4150739908218384 Val Loss 3.2924184799194336
Trainable Parameters : 198660
Epoch 62 Train Acc 68.42073059082031% Val Acc 24.88024139404297% Train Loss 0.39882123470306396 Val Loss 3.7858026027679443
Trainable Parameters : 198660
Epoch 63 Train Acc 67.9756088256836% Val Acc 24.886228561401367% Train Loss 0.4044054448604584 Val Loss 3.7761967182159424
Trainable Parameters : 198660
Epoch 64 Train Acc 69.03658294677734% Val Acc 25.275449752807617% Train Loss 0.4006045460700989 Val Loss 3.571179151535034
Trainable Parameters : 198660
Epoch 65 Train Acc 68.55487823486328% Val Acc 25.538923263549805% Train Loss 0.40627241134643555 Val Loss 3.5803585052490234
Trainable Parameters : 198660
Epoch 66 Train Acc 69.70121765136719% Val Acc 25.299402236938477% Train Loss 0.38245847821235657 Val Loss 3.910562515258789
Trainable Parameters : 198660
Epoch 67 Train Acc 69.17073059082031% Val Acc 24.568862915039062% Train Loss 0.38759645819664 Val Loss 4.072590351104736
Trainable Parameters : 198660
Epoch 68 Train Acc 69.243896484375% Val Acc 25.113773345947266% Train Loss 0.380902498960495 Val Loss 4.096210479736328
Trainable Parameters : 198660
Mon Oct 10 14:56:20 AEDT 2022
------------------------------------------------------------------------
                         run_500f.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_500f.py
Started: 10/10/2022 14:56:25

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-500-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-8.6027e-04, -4.5755e-04, -4.5755e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.6808e-03, -1.8819e-01, -3.7745e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.8852e-02, -2.6824e-02, -1.8603e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-5.0264e-02,  4.8264e-03, -1.6128e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-7.7667e-02, -8.2385e-02, -4.6322e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.2043e+00,  1.5767e+00,  1.5630e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 3, 0, 1, 2, 2, 0, 3, 3, 0, 0, 0])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.bias', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_hid.weight', 'quantizer.codevectors', 'quantizer.weight_proj.weight', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.bias', 'projector.weight', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-7.2757e-03, -6.5121e-03,  4.1774e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.6573e+00, -2.1752e+00, -1.7111e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-7.4452e-01, -7.1869e-01, -6.6518e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 8.7620e-01,  8.2875e-01,  7.0988e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.1835e+00, -1.6671e-01,  7.3894e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.3463e-01,  3.7641e-01,  3.7839e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 1, 0, 3, 2, 1, 3, 3, 1, 3, 3])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  4 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 24.737804412841797% Val Acc 23.928144454956055% Train Loss 0.6970753073692322 Val Loss 1.3907158374786377
Trainable Parameters : 198660
Epoch 1 Train Acc 26.21341323852539% Val Acc 25.191617965698242% Train Loss 0.6936519742012024 Val Loss 1.387413501739502
Trainable Parameters : 198660
Epoch 2 Train Acc 27.9939022064209% Val Acc 24.526947021484375% Train Loss 0.6902126669883728 Val Loss 1.3886792659759521
Trainable Parameters : 198660
Epoch 3 Train Acc 30.951217651367188% Val Acc 23.26946258544922% Train Loss 0.687831461429596 Val Loss 1.3898800611495972
Trainable Parameters : 198660
Epoch 4 Train Acc 32.32926559448242% Val Acc 24.592815399169922% Train Loss 0.684647262096405 Val Loss 1.3907111883163452
Trainable Parameters : 198660
Epoch 5 Train Acc 33.414634704589844% Val Acc 25.18562889099121% Train Loss 0.6812252402305603 Val Loss 1.3930416107177734
Trainable Parameters : 198660
Epoch 6 Train Acc 33.591461181640625% Val Acc 22.62275505065918% Train Loss 0.6785014271736145 Val Loss 1.4036093950271606
Trainable Parameters : 198660
Epoch 7 Train Acc 34.98170471191406% Val Acc 24.17365264892578% Train Loss 0.6751092672348022 Val Loss 1.4007848501205444
Trainable Parameters : 198660
Epoch 8 Train Acc 36.682926177978516% Val Acc 23.41916275024414% Train Loss 0.6699278354644775 Val Loss 1.4087681770324707
Trainable Parameters : 198660
Epoch 9 Train Acc 36.32926559448242% Val Acc 22.730539321899414% Train Loss 0.6661918759346008 Val Loss 1.4210658073425293
Trainable Parameters : 198660
Epoch 10 Train Acc 37.67073059082031% Val Acc 22.916168212890625% Train Loss 0.6615081429481506 Val Loss 1.4439870119094849
Trainable Parameters : 198660
Epoch 11 Train Acc 38.475608825683594% Val Acc 23.706586837768555% Train Loss 0.6550801396369934 Val Loss 1.4547134637832642
Trainable Parameters : 198660
Epoch 12 Train Acc 39.07926559448242% Val Acc 22.880239486694336% Train Loss 0.6530119776725769 Val Loss 1.4950242042541504
Trainable Parameters : 198660
Epoch 13 Train Acc 38.8719482421875% Val Acc 23.371257781982422% Train Loss 0.6478111743927002 Val Loss 1.4927847385406494
Trainable Parameters : 198660
Epoch 14 Train Acc 40.29877853393555% Val Acc 22.82036018371582% Train Loss 0.6432938575744629 Val Loss 1.5255869626998901
Trainable Parameters : 198660
Epoch 15 Train Acc 41.3597526550293% Val Acc 23.179641723632812% Train Loss 0.6339772939682007 Val Loss 1.5541037321090698
Trainable Parameters : 198660
Epoch 16 Train Acc 42.42073059082031% Val Acc 24.329341888427734% Train Loss 0.6284641623497009 Val Loss 1.5905523300170898
Trainable Parameters : 198660
Epoch 17 Train Acc 44.31097412109375% Val Acc 23.149702072143555% Train Loss 0.6238618493080139 Val Loss 1.649221658706665
Trainable Parameters : 198660
Epoch 18 Train Acc 43.64024353027344% Val Acc 24.724552154541016% Train Loss 0.6179586052894592 Val Loss 1.6032123565673828
Trainable Parameters : 198660
Epoch 19 Train Acc 45.95121765136719% Val Acc 24.532934188842773% Train Loss 0.6115033030509949 Val Loss 1.618958830833435
Trainable Parameters : 198660
Epoch 20 Train Acc 45.432926177978516% Val Acc 23.04790496826172% Train Loss 0.6038573980331421 Val Loss 1.6963225603103638
Trainable Parameters : 198660
Epoch 21 Train Acc 46.96950912475586% Val Acc 24.347307205200195% Train Loss 0.5948755741119385 Val Loss 1.689875841140747
Trainable Parameters : 198660
Epoch 22 Train Acc 50.01219177246094% Val Acc 25.083833694458008% Train Loss 0.5831835269927979 Val Loss 1.8228209018707275
Trainable Parameters : 198660
Epoch 23 Train Acc 49.707313537597656% Val Acc 25.742515563964844% Train Loss 0.5816267132759094 Val Loss 1.7265446186065674
Trainable Parameters : 198660
Epoch 24 Train Acc 50.54268264770508% Val Acc 24.712575912475586% Train Loss 0.5765655636787415 Val Loss 1.8174306154251099
Trainable Parameters : 198660
Epoch 25 Train Acc 52.06707000732422% Val Acc 24.700599670410156% Train Loss 0.5659758448600769 Val Loss 1.8368867635726929
Trainable Parameters : 198660
Epoch 26 Train Acc 51.20121765136719% Val Acc 25.59880256652832% Train Loss 0.5642653703689575 Val Loss 2.0251963138580322
Trainable Parameters : 198660
Epoch 27 Train Acc 52.878047943115234% Val Acc 26.275449752807617% Train Loss 0.5561462640762329 Val Loss 1.9836112260818481
Trainable Parameters : 198660
Epoch 28 Train Acc 53.01219177246094% Val Acc 25.62874412536621% Train Loss 0.550701916217804 Val Loss 2.114128589630127
Trainable Parameters : 198660
Epoch 29 Train Acc 55.3841438293457% Val Acc 27.119762420654297% Train Loss 0.5372424721717834 Val Loss 2.027787923812866
Trainable Parameters : 198660
Epoch 30 Train Acc 56.14024353027344% Val Acc 24.712575912475586% Train Loss 0.5344142317771912 Val Loss 2.057913303375244
Trainable Parameters : 198660
Epoch 31 Train Acc 56.054874420166016% Val Acc 24.131736755371094% Train Loss 0.5260032415390015 Val Loss 2.195030927658081
Trainable Parameters : 198660
Epoch 32 Train Acc 57.402435302734375% Val Acc 26.4491024017334% Train Loss 0.518417239189148 Val Loss 2.1611292362213135
Trainable Parameters : 198660
Epoch 33 Train Acc 57.96341323852539% Val Acc 26.520959854125977% Train Loss 0.5176699757575989 Val Loss 2.2717537879943848
Trainable Parameters : 198660
Epoch 34 Train Acc 56.896339416503906% Val Acc 27.46706771850586% Train Loss 0.5085768103599548 Val Loss 2.2527213096618652
Trainable Parameters : 198660
Epoch 35 Train Acc 57.89024353027344% Val Acc 25.676647186279297% Train Loss 0.5066891312599182 Val Loss 2.1048943996429443
Trainable Parameters : 198660
Epoch 36 Train Acc 60.597557067871094% Val Acc 25.850299835205078% Train Loss 0.493841290473938 Val Loss 2.6634178161621094
Trainable Parameters : 198660
Epoch 37 Train Acc 59.46341323852539% Val Acc 26.275449752807617% Train Loss 0.49234434962272644 Val Loss 2.758965015411377
Trainable Parameters : 198660
Epoch 38 Train Acc 61.3841438293457% Val Acc 26.389223098754883% Train Loss 0.481071412563324 Val Loss 2.4960150718688965
Trainable Parameters : 198660
Epoch 39 Train Acc 60.975608825683594% Val Acc 27.2215576171875% Train Loss 0.480131596326828 Val Loss 2.4122252464294434
Trainable Parameters : 198660
Epoch 40 Train Acc 61.432926177978516% Val Acc 25.071857452392578% Train Loss 0.4816591441631317 Val Loss 2.6503074169158936
Trainable Parameters : 198660
Epoch 41 Train Acc 62.77438735961914% Val Acc 25.155689239501953% Train Loss 0.4734172224998474 Val Loss 2.802865982055664
Trainable Parameters : 198660
Epoch 42 Train Acc 61.628047943115234% Val Acc 25.964073181152344% Train Loss 0.47248637676239014 Val Loss 2.881088972091675
Trainable Parameters : 198660
Epoch 43 Train Acc 63.10365676879883% Val Acc 26.143712997436523% Train Loss 0.4611048102378845 Val Loss 2.767660140991211
Trainable Parameters : 198660
Epoch 44 Train Acc 63.01219177246094% Val Acc 25.04191780090332% Train Loss 0.463377445936203 Val Loss 2.9802286624908447
Trainable Parameters : 198660
Epoch 45 Train Acc 63.07316970825195% Val Acc 25.24551010131836% Train Loss 0.4561757743358612 Val Loss 3.009986162185669
Trainable Parameters : 198660
Epoch 46 Train Acc 64.80487823486328% Val Acc 24.23353385925293% Train Loss 0.4558032155036926 Val Loss 2.7618818283081055
Trainable Parameters : 198660
Epoch 47 Train Acc 63.536582946777344% Val Acc 25.107786178588867% Train Loss 0.4510750472545624 Val Loss 2.7553341388702393
Trainable Parameters : 198660
Epoch 48 Train Acc 63.81707000732422% Val Acc 25.2155704498291% Train Loss 0.44825705885887146 Val Loss 3.2168917655944824
Trainable Parameters : 198660
Epoch 49 Train Acc 65.16463470458984% Val Acc 25.263473510742188% Train Loss 0.43770936131477356 Val Loss 3.1492507457733154
Trainable Parameters : 198660
Epoch 50 Train Acc 66.61585235595703% Val Acc 25.85628890991211% Train Loss 0.4388294517993927 Val Loss 3.0051512718200684
Trainable Parameters : 198660
Epoch 51 Train Acc 65.43901824951172% Val Acc 25.40718650817871% Train Loss 0.439218133687973 Val Loss 3.1104636192321777
Trainable Parameters : 198660
Epoch 52 Train Acc 65.25% Val Acc 25.113773345947266% Train Loss 0.4332651197910309 Val Loss 3.243093252182007
Trainable Parameters : 198660
Epoch 53 Train Acc 66.98170471191406% Val Acc 26.592815399169922% Train Loss 0.4334002435207367 Val Loss 3.192807674407959
Trainable Parameters : 198660
Epoch 54 Train Acc 66.20731353759766% Val Acc 25.706586837768555% Train Loss 0.4247153401374817 Val Loss 3.663672924041748
Trainable Parameters : 198660
Epoch 55 Train Acc 65.75609588623047% Val Acc 25.25748634338379% Train Loss 0.43054914474487305 Val Loss 3.1712241172790527
Trainable Parameters : 198660
Epoch 56 Train Acc 66.09146118164062% Val Acc 25.78443145751953% Train Loss 0.41825512051582336 Val Loss 3.1798806190490723
Trainable Parameters : 198660
Epoch 57 Train Acc 66.18901824951172% Val Acc 26.065868377685547% Train Loss 0.4255589544773102 Val Loss 2.816608428955078
Trainable Parameters : 198660
Epoch 58 Train Acc 67.4756088256836% Val Acc 25.526947021484375% Train Loss 0.41996848583221436 Val Loss 3.2224857807159424
Trainable Parameters : 198660
Epoch 59 Train Acc 66.45121765136719% Val Acc 25.479042053222656% Train Loss 0.4269804358482361 Val Loss 3.1208035945892334
Trainable Parameters : 198660
Epoch 60 Train Acc 66.993896484375% Val Acc 26.359281539916992% Train Loss 0.41242799162864685 Val Loss 2.762181043624878
Trainable Parameters : 198660
Epoch 61 Train Acc 66.90853118896484% Val Acc 24.730539321899414% Train Loss 0.4061650037765503 Val Loss 3.5387775897979736
Trainable Parameters : 198660
Epoch 62 Train Acc 67.7256088256836% Val Acc 25.305389404296875% Train Loss 0.40202873945236206 Val Loss 3.348259449005127
Trainable Parameters : 198660
Epoch 63 Train Acc 67.68901824951172% Val Acc 25.371257781982422% Train Loss 0.4069077968597412 Val Loss 3.6750752925872803
Trainable Parameters : 198660
Epoch 64 Train Acc 68.68292236328125% Val Acc 25.2155704498291% Train Loss 0.4017791152000427 Val Loss 4.002503871917725
Trainable Parameters : 198660
Wed Oct 12 17:01:59 AEDT 2022
------------------------------------------------------------------------
                         run_500f.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_500f.py
Started: 12/10/2022 17:02:03

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-500-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.3888,  1.5308,  1.6680,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.7049,  0.6136,  0.3704,  ...,  0.0000,  0.0000,  0.0000],
        [-1.2924, -1.9138, -2.3013,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.3545,  0.5312,  0.9027,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1236, -0.1412, -0.1717,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0983, -0.0841, -0.2036,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 3, 1, 2, 1, 2, 0, 0, 2, 0, 0])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_hid.bias', 'quantizer.weight_proj.bias', 'project_hid.weight', 'project_q.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'projector.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.1872,  0.1594,  0.1450,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0215, -0.0529,  0.1133,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4724,  0.3894,  0.5099,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.9756, -1.1710, -0.9959,  ...,  0.0000,  0.0000,  0.0000],
        [-1.1798, -1.1132, -0.7150,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2076, -0.1465, -0.1323,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 2, 2, 1, 2, 3, 3, 3, 1, 3, 3])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 24.70731544494629% Val Acc 25.365270614624023% Train Loss 0.6940789818763733 Val Loss 1.3913315534591675
Trainable Parameters : 198660
Epoch 1 Train Acc 25.64634132385254% Val Acc 23.43113899230957% Train Loss 0.6922811269760132 Val Loss 1.390116810798645
Trainable Parameters : 198660
Epoch 2 Train Acc 29.26219367980957% Val Acc 22.251497268676758% Train Loss 0.690315842628479 Val Loss 1.3906338214874268
Trainable Parameters : 198660
Epoch 3 Train Acc 31.4939022064209% Val Acc 22.40718650817871% Train Loss 0.6881603598594666 Val Loss 1.3917754888534546
Trainable Parameters : 198660
Epoch 4 Train Acc 32.44512176513672% Val Acc 23.377246856689453% Train Loss 0.6846200823783875 Val Loss 1.3937170505523682
Trainable Parameters : 198660
Epoch 5 Train Acc 33.396339416503906% Val Acc 24.113773345947266% Train Loss 0.6823418140411377 Val Loss 1.3954260349273682
Trainable Parameters : 198660
Epoch 6 Train Acc 34.182926177978516% Val Acc 22.82036018371582% Train Loss 0.6786758303642273 Val Loss 1.405648112297058
Trainable Parameters : 198660
Epoch 7 Train Acc 34.932926177978516% Val Acc 23.347307205200195% Train Loss 0.6748875379562378 Val Loss 1.405472755432129
Trainable Parameters : 198660
Epoch 8 Train Acc 35.689022064208984% Val Acc 23.137725830078125% Train Loss 0.6708202958106995 Val Loss 1.4109772443771362
Trainable Parameters : 198660
Epoch 9 Train Acc 37.56097412109375% Val Acc 22.712575912475586% Train Loss 0.6634277105331421 Val Loss 1.4307551383972168
Trainable Parameters : 198660
Epoch 10 Train Acc 37.67073059082031% Val Acc 22.497007369995117% Train Loss 0.6622492671012878 Val Loss 1.4438620805740356
Trainable Parameters : 198660
Epoch 11 Train Acc 37.42682647705078% Val Acc 23.071857452392578% Train Loss 0.6567049622535706 Val Loss 1.4544694423675537
Trainable Parameters : 198660
Epoch 12 Train Acc 37.45121765136719% Val Acc 23.089820861816406% Train Loss 0.6523279547691345 Val Loss 1.4841948747634888
Trainable Parameters : 198660
Epoch 13 Train Acc 38.0121955871582% Val Acc 23.389223098754883% Train Loss 0.64949631690979 Val Loss 1.487273097038269
Trainable Parameters : 198660
Epoch 14 Train Acc 41.16463088989258% Val Acc 22.86826515197754% Train Loss 0.6392655968666077 Val Loss 1.5366113185882568
Trainable Parameters : 198660
Epoch 15 Train Acc 41.1219482421875% Val Acc 23.706586837768555% Train Loss 0.6343300938606262 Val Loss 1.5490570068359375
Trainable Parameters : 198660
Epoch 16 Train Acc 43.14024353027344% Val Acc 24.335330963134766% Train Loss 0.6282357573509216 Val Loss 1.5847810506820679
Trainable Parameters : 198660
Epoch 17 Train Acc 43.3719482421875% Val Acc 23.305389404296875% Train Loss 0.6223196983337402 Val Loss 1.6418346166610718
Trainable Parameters : 198660
Epoch 18 Train Acc 43.89024353027344% Val Acc 24.652694702148438% Train Loss 0.6144837141036987 Val Loss 1.6481770277023315
Trainable Parameters : 198660
Epoch 19 Train Acc 45.939022064208984% Val Acc 25.101797103881836% Train Loss 0.6069462895393372 Val Loss 1.6673568487167358
Trainable Parameters : 198660
Epoch 20 Train Acc 45.46341323852539% Val Acc 23.62874412536621% Train Loss 0.6031535267829895 Val Loss 1.7268157005310059
Trainable Parameters : 198660
Epoch 21 Train Acc 47.75609588623047% Val Acc 25.688623428344727% Train Loss 0.59195476770401 Val Loss 1.7489303350448608
Trainable Parameters : 198660
Epoch 22 Train Acc 48.77438735961914% Val Acc 25.125749588012695% Train Loss 0.5867231488227844 Val Loss 1.8886864185333252
Trainable Parameters : 198660
Epoch 23 Train Acc 48.31097412109375% Val Acc 25.101797103881836% Train Loss 0.5815775990486145 Val Loss 1.7947348356246948
Trainable Parameters : 198660
Epoch 24 Train Acc 50.939022064208984% Val Acc 25.131736755371094% Train Loss 0.5739635229110718 Val Loss 1.8904736042022705
Trainable Parameters : 198660
Epoch 25 Train Acc 51.82926559448242% Val Acc 24.898204803466797% Train Loss 0.5641365051269531 Val Loss 1.8953797817230225
Trainable Parameters : 198660
Epoch 26 Train Acc 50.682926177978516% Val Acc 25.2155704498291% Train Loss 0.5634478330612183 Val Loss 2.0137014389038086
Trainable Parameters : 198660
Epoch 27 Train Acc 51.86585235595703% Val Acc 24.748504638671875% Train Loss 0.5550052523612976 Val Loss 2.0854873657226562
Trainable Parameters : 198660
Epoch 28 Train Acc 53.39024353027344% Val Acc 24.754491806030273% Train Loss 0.5484708547592163 Val Loss 2.1432530879974365
Trainable Parameters : 198660
Epoch 29 Train Acc 55.26219177246094% Val Acc 27.353294372558594% Train Loss 0.5410987138748169 Val Loss 2.0627782344818115
Trainable Parameters : 198660
Epoch 30 Train Acc 55.67073059082031% Val Acc 24.84431266784668% Train Loss 0.5313444137573242 Val Loss 2.2406837940216064
Trainable Parameters : 198660
Epoch 31 Train Acc 55.6097526550293% Val Acc 24.083833694458008% Train Loss 0.5284227132797241 Val Loss 2.274641513824463
Trainable Parameters : 198660
Epoch 32 Train Acc 55.66463088989258% Val Acc 26.4491024017334% Train Loss 0.5202470421791077 Val Loss 2.268916130065918
Trainable Parameters : 198660
Epoch 33 Train Acc 57.7378044128418% Val Acc 26.311378479003906% Train Loss 0.5140731930732727 Val Loss 2.388221025466919
Trainable Parameters : 198660
Epoch 34 Train Acc 57.04268264770508% Val Acc 26.107786178588867% Train Loss 0.5102168321609497 Val Loss 2.2134156227111816
Trainable Parameters : 198660
Epoch 35 Train Acc 57.707313537597656% Val Acc 25.40718650817871% Train Loss 0.5081125497817993 Val Loss 2.2772843837738037
Trainable Parameters : 198660
Epoch 36 Train Acc 58.45121765136719% Val Acc 25.988025665283203% Train Loss 0.49875786900520325 Val Loss 2.9064157009124756
Trainable Parameters : 198660
Epoch 37 Train Acc 59.44511795043945% Val Acc 26.43113899230957% Train Loss 0.4901878237724304 Val Loss 2.710141897201538
Trainable Parameters : 198660
Epoch 38 Train Acc 59.646339416503906% Val Acc 26.149702072143555% Train Loss 0.48599129915237427 Val Loss 2.7179510593414307
Trainable Parameters : 198660
Epoch 39 Train Acc 61.50609588623047% Val Acc 26.694612503051758% Train Loss 0.48439303040504456 Val Loss 2.7016165256500244
Trainable Parameters : 198660
Epoch 40 Train Acc 60.585365295410156% Val Acc 25.694612503051758% Train Loss 0.4786999821662903 Val Loss 2.8246257305145264
Trainable Parameters : 198660
Epoch 41 Train Acc 61.085365295410156% Val Acc 24.712575912475586% Train Loss 0.47851189970970154 Val Loss 2.8171873092651367
Trainable Parameters : 198660
Epoch 42 Train Acc 62.35365676879883% Val Acc 25.730539321899414% Train Loss 0.4716823101043701 Val Loss 2.9833645820617676
Trainable Parameters : 198660
Epoch 43 Train Acc 62.207313537597656% Val Acc 26.01197624206543% Train Loss 0.4668158292770386 Val Loss 2.73227596282959
Trainable Parameters : 198660
Epoch 44 Train Acc 62.71341323852539% Val Acc 25.538923263549805% Train Loss 0.45818081498146057 Val Loss 3.4614174365997314
Trainable Parameters : 198660
Epoch 45 Train Acc 63.054874420166016% Val Acc 25.550899505615234% Train Loss 0.46134138107299805 Val Loss 3.154217004776001
Trainable Parameters : 198660
Epoch 46 Train Acc 62.31097412109375% Val Acc 24.59880256652832% Train Loss 0.46411922574043274 Val Loss 3.0049266815185547
Trainable Parameters : 198660
Epoch 47 Train Acc 62.26219177246094% Val Acc 25.359281539916992% Train Loss 0.45363444089889526 Val Loss 2.9408648014068604
Trainable Parameters : 198660
Epoch 48 Train Acc 64.41463470458984% Val Acc 25.443115234375% Train Loss 0.45255813002586365 Val Loss 3.3472580909729004
Trainable Parameters : 198660
Epoch 49 Train Acc 63.51219177246094% Val Acc 25.82634735107422% Train Loss 0.4551982283592224 Val Loss 3.0090949535369873
Trainable Parameters : 198660
Epoch 50 Train Acc 64.39024353027344% Val Acc 26.778444290161133% Train Loss 0.44211575388908386 Val Loss 2.769949197769165
Trainable Parameters : 198660
Epoch 51 Train Acc 65.09146118164062% Val Acc 25.479042053222656% Train Loss 0.44479572772979736 Val Loss 2.7967662811279297
Trainable Parameters : 198660
Epoch 52 Train Acc 64.60975646972656% Val Acc 25.25748634338379% Train Loss 0.4409092664718628 Val Loss 3.0253312587738037
Trainable Parameters : 198660
Epoch 53 Train Acc 64.89024353027344% Val Acc 25.910181045532227% Train Loss 0.43930885195732117 Val Loss 3.0331926345825195
Trainable Parameters : 198660
Epoch 54 Train Acc 64.79877471923828% Val Acc 24.964073181152344% Train Loss 0.4369756579399109 Val Loss 3.343668222427368
Trainable Parameters : 198660
Epoch 55 Train Acc 65.18901824951172% Val Acc 25.473054885864258% Train Loss 0.4323759078979492 Val Loss 3.1514272689819336
Trainable Parameters : 198660
Epoch 56 Train Acc 66.32316589355469% Val Acc 25.778444290161133% Train Loss 0.4264618456363678 Val Loss 2.8232669830322266
Trainable Parameters : 198660
Epoch 57 Train Acc 66.40243530273438% Val Acc 27.143712997436523% Train Loss 0.4303915798664093 Val Loss 2.675480842590332
Trainable Parameters : 198660
Epoch 58 Train Acc 64.66463470458984% Val Acc 25.46706771850586% Train Loss 0.42645156383514404 Val Loss 2.96368408203125
Trainable Parameters : 198660
Epoch 59 Train Acc 67.58536529541016% Val Acc 24.9940128326416% Train Loss 0.4140743613243103 Val Loss 3.5480098724365234
Trainable Parameters : 198660
Epoch 60 Train Acc 65.71340942382812% Val Acc 25.85628890991211% Train Loss 0.42035239934921265 Val Loss 3.1242403984069824
Trainable Parameters : 198660
Epoch 61 Train Acc 66.5182876586914% Val Acc 24.65868377685547% Train Loss 0.4160500466823578 Val Loss 3.807090997695923
Trainable Parameters : 198660
Epoch 62 Train Acc 67.06097412109375% Val Acc 25.083833694458008% Train Loss 0.40703579783439636 Val Loss 3.4684653282165527
Trainable Parameters : 198660
Epoch 63 Train Acc 67.62804412841797% Val Acc 24.78443145751953% Train Loss 0.4015863239765167 Val Loss 3.58879017829895
Trainable Parameters : 198660
Epoch 64 Train Acc 66.93901824951172% Val Acc 25.239521026611328% Train Loss 0.4121266305446625 Val Loss 3.336683511734009
Trainable Parameters : 198660
Epoch 65 Train Acc 67.25% Val Acc 25.305389404296875% Train Loss 0.4061641991138458 Val Loss 3.1462512016296387
Trainable Parameters : 198660
Epoch 66 Train Acc 68.20121765136719% Val Acc 25.712575912475586% Train Loss 0.4047222435474396 Val Loss 3.544046640396118
Trainable Parameters : 198660
Epoch 67 Train Acc 68.68901824951172% Val Acc 24.910181045532227% Train Loss 0.39919036626815796 Val Loss 3.289461374282837
Trainable Parameters : 198660
Epoch 68 Train Acc 69.8963394165039% Val Acc 24.760480880737305% Train Loss 0.38850584626197815 Val Loss 3.60349702835083
Trainable Parameters : 198660
Epoch 69 Train Acc 70.35365295410156% Val Acc 25.173654556274414% Train Loss 0.38469231128692627 Val Loss 3.3981032371520996
Trainable Parameters : 198660
Epoch 70 Train Acc 70.56097412109375% Val Acc 24.79640769958496% Train Loss 0.3782109320163727 Val Loss 3.455740451812744
Trainable Parameters : 198660
Epoch 71 Train Acc 70.01219177246094% Val Acc 24.497007369995117% Train Loss 0.3809232711791992 Val Loss 4.300283432006836
Trainable Parameters : 198660
Epoch 72 Train Acc 70.96340942382812% Val Acc 24.688623428344727% Train Loss 0.3718923330307007 Val Loss 4.254358291625977
Trainable Parameters : 198660
Epoch 73 Train Acc 70.31707000732422% Val Acc 24.964073181152344% Train Loss 0.38029175996780396 Val Loss 4.216553211212158
Trainable Parameters : 198660
Epoch 74 Train Acc 70.40853118896484% Val Acc 27.556886672973633% Train Loss 0.3808478116989136 Val Loss 3.3583178520202637
Trainable Parameters : 198660
Epoch 75 Train Acc 72.243896484375% Val Acc 25.904191970825195% Train Loss 0.362289696931839 Val Loss 3.7013142108917236
Trainable Parameters : 198660
Epoch 76 Train Acc 71.18901824951172% Val Acc 25.850299835205078% Train Loss 0.3663952052593231 Val Loss 3.0760769844055176
Trainable Parameters : 198660
Epoch 77 Train Acc 72.26219177246094% Val Acc 26.179641723632812% Train Loss 0.3558119535446167 Val Loss 3.789818525314331
Trainable Parameters : 198660
Epoch 78 Train Acc 71.57926940917969% Val Acc 27.131736755371094% Train Loss 0.36371639370918274 Val Loss 3.6378066539764404
Trainable Parameters : 198660
Epoch 79 Train Acc 72.69512176513672% Val Acc 25.125749588012695% Train Loss 0.35690340399742126 Val Loss 4.166408061981201
Trainable Parameters : 198660
Epoch 80 Train Acc 71.5243911743164% Val Acc 25.85628890991211% Train Loss 0.35974159836769104 Val Loss 3.855952739715576
Trainable Parameters : 198660
Epoch 81 Train Acc 72.29267883300781% Val Acc 26.01197624206543% Train Loss 0.3574647605419159 Val Loss 3.7583274841308594
Trainable Parameters : 198660
Epoch 82 Train Acc 72.16463470458984% Val Acc 25.03592872619629% Train Loss 0.3548943102359772 Val Loss 3.8929359912872314
Trainable Parameters : 198660
Epoch 83 Train Acc 72.2743911743164% Val Acc 26.155689239501953% Train Loss 0.35309934616088867 Val Loss 4.423564434051514
Trainable Parameters : 198660
Epoch 84 Train Acc 73.62804412841797% Val Acc 25.05389404296875% Train Loss 0.347670316696167 Val Loss 4.740151405334473
Trainable Parameters : 198660
Epoch 85 Train Acc 72.09146118164062% Val Acc 25.497007369995117% Train Loss 0.35064059495925903 Val Loss 4.291696071624756
Trainable Parameters : 198660
Epoch 86 Train Acc 73.3475570678711% Val Acc 24.293413162231445% Train Loss 0.34868332743644714 Val Loss 3.845405101776123
Trainable Parameters : 198660
Epoch 87 Train Acc 72.48780059814453% Val Acc 26.7724552154541% Train Loss 0.34937772154808044 Val Loss 4.101627826690674
Trainable Parameters : 198660
Epoch 88 Train Acc 73.10975646972656% Val Acc 25.802396774291992% Train Loss 0.35218340158462524 Val Loss 4.402320384979248
Trainable Parameters : 198660
Epoch 89 Train Acc 73.66463470458984% Val Acc 27.179641723632812% Train Loss 0.34280943870544434 Val Loss 4.254083156585693
Trainable Parameters : 198660
Epoch 90 Train Acc 74.1219482421875% Val Acc 25.341318130493164% Train Loss 0.3431705832481384 Val Loss 4.617430686950684
Trainable Parameters : 198660
Fri Oct 14 10:34:51 AEDT 2022
------------------------------------------------------------------------
                         run_500f.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_500f.py
Started: 14/10/2022 10:34:57

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-500-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 24
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-5.6923e-02,  1.1839e-01,  1.7025e-01,  ...,  9.1203e-03,
          1.1887e-02,  1.2578e-02],
        [ 4.6345e-01, -2.2588e-03, -1.9929e-03,  ..., -2.1174e+00,
         -1.8069e+00, -9.1240e-01],
        [ 3.8893e-02,  4.4604e-02,  4.6291e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 1.6007e-01,  3.4148e-01,  3.7590e-01,  ...,  9.2039e-02,
          1.1836e-01,  1.7222e-01],
        [-4.9999e-03, -8.2401e-02, -9.9915e-02,  ..., -1.7336e-01,
         -2.0952e-01, -2.3890e-01],
        [ 1.7186e+00,  1.6219e+00,  1.4898e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 2, 1, 2, 1, 2, 3, 3, 1, 2, 2, 3, 1])}
Training DataCustom Files: 1963
Training Data Files: 82
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.weight_proj.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.bias', 'project_q.weight', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'projector.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.5760,  0.0090, -0.2569,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2584,  0.2178,  0.1949,  ..., -1.0434, -1.2671, -1.3940],
        [ 0.6211,  0.4301,  0.2577,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.3358,  1.1371,  1.8788,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0062, -0.0234, -0.0257,  ..., -2.3718, -2.3617, -2.3664],
        [ 0.1786, -0.1885, -0.3969,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 2, 3, 0, 0, 1, 0, 0, 2, 3, 1, 0, 0, 1, 2, 2, 0, 0, 2, 2, 1, 3, 0])}
Test CustomData Files: 1997
Test Data Files: 84
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 24.341463088989258% Val Acc 23.845237731933594% Train Loss 0.6974698305130005 Val Loss 1.3907266855239868
Trainable Parameters : 198660
Epoch 1 Train Acc 25.085365295410156% Val Acc 24.059524536132812% Train Loss 0.6961157321929932 Val Loss 1.3892618417739868
Trainable Parameters : 198660
Epoch 2 Train Acc 26.56097412109375% Val Acc 24.7261905670166% Train Loss 0.6932949423789978 Val Loss 1.3881316184997559
Trainable Parameters : 198660
Epoch 3 Train Acc 29.91463279724121% Val Acc 25.702381134033203% Train Loss 0.6903713941574097 Val Loss 1.38850998878479
Trainable Parameters : 198660
Epoch 4 Train Acc 33.57316970825195% Val Acc 23.059524536132812% Train Loss 0.6869473457336426 Val Loss 1.3897291421890259
Trainable Parameters : 198660
Epoch 5 Train Acc 36.182926177978516% Val Acc 23.261905670166016% Train Loss 0.683210551738739 Val Loss 1.391923189163208
Trainable Parameters : 198660
Epoch 6 Train Acc 37.4878044128418% Val Acc 22.785715103149414% Train Loss 0.6790143847465515 Val Loss 1.3946079015731812
Trainable Parameters : 198660
Epoch 7 Train Acc 37.39024353027344% Val Acc 22.892858505249023% Train Loss 0.6750221252441406 Val Loss 1.398633360862732
Trainable Parameters : 198660
Epoch 8 Train Acc 41.15853500366211% Val Acc 22.96428680419922% Train Loss 0.6698898673057556 Val Loss 1.4010920524597168
Trainable Parameters : 198660
Epoch 9 Train Acc 41.71950912475586% Val Acc 23.321428298950195% Train Loss 0.6654024124145508 Val Loss 1.405604362487793
Trainable Parameters : 198660
Epoch 10 Train Acc 41.30487823486328% Val Acc 23.21428680419922% Train Loss 0.6606631278991699 Val Loss 1.411777377128601
Trainable Parameters : 198660
Epoch 11 Train Acc 42.07316970825195% Val Acc 23.595237731933594% Train Loss 0.65625 Val Loss 1.4143377542495728
Trainable Parameters : 198660
Epoch 12 Train Acc 44.280487060546875% Val Acc 23.5% Train Loss 0.6500431895256042 Val Loss 1.4190647602081299
Trainable Parameters : 198660
Epoch 13 Train Acc 44.280487060546875% Val Acc 24.5% Train Loss 0.644832193851471 Val Loss 1.4237899780273438
Trainable Parameters : 198660
Epoch 14 Train Acc 45.75609588623047% Val Acc 24.19047737121582% Train Loss 0.6397088170051575 Val Loss 1.4256997108459473
Trainable Parameters : 198660
Epoch 15 Train Acc 46.15853500366211% Val Acc 24.9761905670166% Train Loss 0.6322906017303467 Val Loss 1.4298025369644165
Trainable Parameters : 198660
Epoch 16 Train Acc 47.01219177246094% Val Acc 27.119049072265625% Train Loss 0.6266411542892456 Val Loss 1.4328041076660156
Trainable Parameters : 198660
Epoch 17 Train Acc 47.92682647705078% Val Acc 26.392858505249023% Train Loss 0.6195204257965088 Val Loss 1.4408923387527466
Trainable Parameters : 198660
Epoch 18 Train Acc 48.4878044128418% Val Acc 28.25% Train Loss 0.6115326285362244 Val Loss 1.4405304193496704
Trainable Parameters : 198660
Epoch 19 Train Acc 50.41463088989258% Val Acc 28.2261905670166% Train Loss 0.604164719581604 Val Loss 1.4473402500152588
Trainable Parameters : 198660
Epoch 20 Train Acc 52.25609588623047% Val Acc 28.166667938232422% Train Loss 0.5951049327850342 Val Loss 1.453379511833191
Trainable Parameters : 198660
Epoch 21 Train Acc 52.499996185302734% Val Acc 29.96428680419922% Train Loss 0.5901045799255371 Val Loss 1.4604073762893677
Trainable Parameters : 198660
Epoch 22 Train Acc 53.92682647705078% Val Acc 29.7738094329834% Train Loss 0.5804372429847717 Val Loss 1.4750570058822632
Trainable Parameters : 198660
Epoch 23 Train Acc 53.91463088989258% Val Acc 29.08333396911621% Train Loss 0.5733235478401184 Val Loss 1.4690542221069336
Trainable Parameters : 198660
Epoch 24 Train Acc 55.01219177246094% Val Acc 30.08333396911621% Train Loss 0.5635512471199036 Val Loss 1.4848698377609253
Trainable Parameters : 198660
Epoch 25 Train Acc 55.52438735961914% Val Acc 30.10714340209961% Train Loss 0.5541772842407227 Val Loss 1.5046448707580566
Trainable Parameters : 198660
Epoch 26 Train Acc 57.085365295410156% Val Acc 30.988096237182617% Train Loss 0.5470027327537537 Val Loss 1.500759243965149
Trainable Parameters : 198660
Epoch 27 Train Acc 56.804874420166016% Val Acc 30.0% Train Loss 0.5416475534439087 Val Loss 1.5208353996276855
Trainable Parameters : 198660
Epoch 28 Train Acc 57.6219482421875% Val Acc 31.071428298950195% Train Loss 0.5336483120918274 Val Loss 1.532717227935791
Trainable Parameters : 198660
Epoch 29 Train Acc 57.82926559448242% Val Acc 31.261905670166016% Train Loss 0.5245963335037231 Val Loss 1.53949773311615
Trainable Parameters : 198660
Epoch 30 Train Acc 59.378047943115234% Val Acc 31.7738094329834% Train Loss 0.5162540674209595 Val Loss 1.53799569606781
Trainable Parameters : 198660
Epoch 31 Train Acc 59.29267883300781% Val Acc 30.60714340209961% Train Loss 0.5064343214035034 Val Loss 1.554734706878662
Trainable Parameters : 198660
Epoch 32 Train Acc 60.1219482421875% Val Acc 31.380952835083008% Train Loss 0.4998614490032196 Val Loss 1.582321047782898
Trainable Parameters : 198660
Epoch 33 Train Acc 59.939022064208984% Val Acc 31.678571701049805% Train Loss 0.49188467860221863 Val Loss 1.5723706483840942
Trainable Parameters : 198660
Epoch 34 Train Acc 62.07316970825195% Val Acc 30.892858505249023% Train Loss 0.48437976837158203 Val Loss 1.647871494293213
Trainable Parameters : 198660
Epoch 35 Train Acc 62.86585235595703% Val Acc 31.285715103149414% Train Loss 0.47699010372161865 Val Loss 1.6085859537124634
Trainable Parameters : 198660
Epoch 36 Train Acc 63.01219177246094% Val Acc 32.32143020629883% Train Loss 0.4687460660934448 Val Loss 1.6350277662277222
Trainable Parameters : 198660
Epoch 37 Train Acc 64.15853118896484% Val Acc 31.7261905670166% Train Loss 0.4614679515361786 Val Loss 1.6309477090835571
Trainable Parameters : 198660
Epoch 38 Train Acc 65.39024353027344% Val Acc 31.535715103149414% Train Loss 0.4537142515182495 Val Loss 1.6968127489089966
Trainable Parameters : 198660
Epoch 39 Train Acc 66.1219482421875% Val Acc 31.69047737121582% Train Loss 0.4458391070365906 Val Loss 1.6726659536361694
Trainable Parameters : 198660
Epoch 40 Train Acc 66.46340942382812% Val Acc 31.761905670166016% Train Loss 0.44026508927345276 Val Loss 1.674773097038269
Trainable Parameters : 198660
Epoch 41 Train Acc 67.04877471923828% Val Acc 32.46428680419922% Train Loss 0.42470410466194153 Val Loss 1.6566095352172852
Trainable Parameters : 198660
Epoch 42 Train Acc 66.82926940917969% Val Acc 31.416667938232422% Train Loss 0.42460551857948303 Val Loss 1.6973716020584106
Trainable Parameters : 198660
Epoch 43 Train Acc 67.51219177246094% Val Acc 33.238094329833984% Train Loss 0.4185865819454193 Val Loss 1.7080572843551636
Trainable Parameters : 198660
Epoch 44 Train Acc 68.63414001464844% Val Acc 32.595237731933594% Train Loss 0.4142776429653168 Val Loss 1.7097315788269043
Trainable Parameters : 198660
Epoch 45 Train Acc 68.95121765136719% Val Acc 33.03571319580078% Train Loss 0.4044502377510071 Val Loss 1.7642661333084106
Trainable Parameters : 198660
Epoch 46 Train Acc 70.15853118896484% Val Acc 31.96428680419922% Train Loss 0.39969122409820557 Val Loss 1.7437764406204224
Trainable Parameters : 198660
Epoch 47 Train Acc 70.35365295410156% Val Acc 32.60714340209961% Train Loss 0.39132338762283325 Val Loss 1.812139630317688
Trainable Parameters : 198660
Epoch 48 Train Acc 70.60975646972656% Val Acc 31.880952835083008% Train Loss 0.3891770839691162 Val Loss 1.7909908294677734
Trainable Parameters : 198660
Epoch 49 Train Acc 71.03658294677734% Val Acc 31.797618865966797% Train Loss 0.3835580348968506 Val Loss 1.8096656799316406
Trainable Parameters : 198660
Epoch 50 Train Acc 71.42682647705078% Val Acc 32.77381134033203% Train Loss 0.3758833408355713 Val Loss 1.9120556116104126
Trainable Parameters : 198660
Epoch 51 Train Acc 71.243896484375% Val Acc 32.345237731933594% Train Loss 0.3744981586933136 Val Loss 1.8958542346954346
Trainable Parameters : 198660
Epoch 52 Train Acc 72.53658294677734% Val Acc 33.64285659790039% Train Loss 0.3650336265563965 Val Loss 1.7625385522842407
Trainable Parameters : 198660
Epoch 53 Train Acc 72.81707000732422% Val Acc 32.02381134033203% Train Loss 0.36814022064208984 Val Loss 1.8286136388778687
Trainable Parameters : 198660
Epoch 54 Train Acc 73.19512176513672% Val Acc 30.809524536132812% Train Loss 0.3603813648223877 Val Loss 1.926239013671875
Trainable Parameters : 198660
Epoch 55 Train Acc 73.1219482421875% Val Acc 31.654762268066406% Train Loss 0.357210636138916 Val Loss 1.9428231716156006
Trainable Parameters : 198660
Epoch 56 Train Acc 73.71951293945312% Val Acc 32.869049072265625% Train Loss 0.3494821786880493 Val Loss 1.8835493326187134
Trainable Parameters : 198660
Epoch 57 Train Acc 73.13414001464844% Val Acc 30.785715103149414% Train Loss 0.35009628534317017 Val Loss 2.0013267993927
Trainable Parameters : 198660
Epoch 58 Train Acc 74.53658294677734% Val Acc 31.96428680419922% Train Loss 0.34263238310813904 Val Loss 1.966658353805542
Trainable Parameters : 198660
Epoch 59 Train Acc 74.95121765136719% Val Acc 32.19047546386719% Train Loss 0.3387119770050049 Val Loss 2.0159528255462646
Trainable Parameters : 198660
Epoch 60 Train Acc 74.80487823486328% Val Acc 31.142858505249023% Train Loss 0.34050452709198 Val Loss 2.0106122493743896
Trainable Parameters : 198660
Epoch 61 Train Acc 75.32926177978516% Val Acc 31.619049072265625% Train Loss 0.32941097021102905 Val Loss 2.0230021476745605
Trainable Parameters : 198660
Epoch 62 Train Acc 73.80487823486328% Val Acc 32.16666793823242% Train Loss 0.33306100964546204 Val Loss 2.0748603343963623
Trainable Parameters : 198660
Epoch 63 Train Acc 76.39024353027344% Val Acc 34.095237731933594% Train Loss 0.3218158185482025 Val Loss 2.071187734603882
Trainable Parameters : 198660
Epoch 64 Train Acc 74.35365295410156% Val Acc 32.46428680419922% Train Loss 0.33632925152778625 Val Loss 2.1193912029266357
Trainable Parameters : 198660
Epoch 65 Train Acc 75.70731353759766% Val Acc 31.678571701049805% Train Loss 0.32398852705955505 Val Loss 2.0721828937530518
Trainable Parameters : 198660
Epoch 66 Train Acc 75.69512176513672% Val Acc 32.404762268066406% Train Loss 0.32121285796165466 Val Loss 2.142482280731201
Trainable Parameters : 198660
Epoch 67 Train Acc 77.43901824951172% Val Acc 31.69047737121582% Train Loss 0.3139195740222931 Val Loss 2.0915298461914062
Trainable Parameters : 198660
Epoch 68 Train Acc 76.21951293945312% Val Acc 32.39285659790039% Train Loss 0.3133772611618042 Val Loss 2.1195313930511475
Trainable Parameters : 198660
Epoch 69 Train Acc 77.0% Val Acc 32.761905670166016% Train Loss 0.29864606261253357 Val Loss 2.081388235092163
Trainable Parameters : 198660
Epoch 70 Train Acc 76.80487823486328% Val Acc 31.119049072265625% Train Loss 0.30366840958595276 Val Loss 2.1453866958618164
Trainable Parameters : 198660
Epoch 71 Train Acc 76.46340942382812% Val Acc 32.88095474243164% Train Loss 0.3053285777568817 Val Loss 2.057924509048462
Trainable Parameters : 198660
Epoch 72 Train Acc 76.0975570678711% Val Acc 31.178571701049805% Train Loss 0.3053067624568939 Val Loss 2.361412286758423
Trainable Parameters : 198660
Epoch 73 Train Acc 77.07316589355469% Val Acc 33.05952453613281% Train Loss 0.2993394136428833 Val Loss 2.0701076984405518
Trainable Parameters : 198660
Epoch 74 Train Acc 76.743896484375% Val Acc 31.404762268066406% Train Loss 0.2960147261619568 Val Loss 2.1833231449127197
Trainable Parameters : 198660
Epoch 75 Train Acc 77.42682647705078% Val Acc 32.726192474365234% Train Loss 0.294341117143631 Val Loss 2.1428112983703613
Trainable Parameters : 198660
Epoch 76 Train Acc 78.743896484375% Val Acc 31.0238094329834% Train Loss 0.2933856248855591 Val Loss 2.2404768466949463
Trainable Parameters : 198660
Epoch 77 Train Acc 78.45121765136719% Val Acc 32.02381134033203% Train Loss 0.2907220125198364 Val Loss 2.272383689880371
Trainable Parameters : 198660
Epoch 78 Train Acc 76.18292236328125% Val Acc 31.9761905670166% Train Loss 0.30227935314178467 Val Loss 2.243292808532715
Trainable Parameters : 198660
Epoch 79 Train Acc 77.54877471923828% Val Acc 33.011905670166016% Train Loss 0.2902752459049225 Val Loss 2.2058215141296387
Trainable Parameters : 198660
Epoch 80 Train Acc 77.25609588623047% Val Acc 32.91666793823242% Train Loss 0.2895204722881317 Val Loss 2.2094740867614746
Trainable Parameters : 198660
Epoch 81 Train Acc 78.01219177246094% Val Acc 33.08333206176758% Train Loss 0.2813699543476105 Val Loss 2.1138250827789307
Trainable Parameters : 198660
Epoch 82 Train Acc 77.54877471923828% Val Acc 30.559524536132812% Train Loss 0.28819817304611206 Val Loss 2.5290164947509766
Trainable Parameters : 198660
Epoch 83 Train Acc 77.5% Val Acc 30.94047737121582% Train Loss 0.29302361607551575 Val Loss 2.3961873054504395
Trainable Parameters : 198660
Epoch 84 Train Acc 78.73170471191406% Val Acc 30.845237731933594% Train Loss 0.2854540944099426 Val Loss 2.477977991104126
Trainable Parameters : 198660
Epoch 85 Train Acc 78.34146118164062% Val Acc 34.2976188659668% Train Loss 0.2834297716617584 Val Loss 2.1662228107452393
Trainable Parameters : 198660
Epoch 86 Train Acc 77.9756088256836% Val Acc 31.142858505249023% Train Loss 0.28479528427124023 Val Loss 2.4203922748565674
Trainable Parameters : 198660
Epoch 87 Train Acc 77.65853118896484% Val Acc 30.880952835083008% Train Loss 0.288251131772995 Val Loss 2.227123260498047
Trainable Parameters : 198660
Epoch 88 Train Acc 77.73170471191406% Val Acc 33.0% Train Loss 0.28711390495300293 Val Loss 2.1856753826141357
Trainable Parameters : 198660
Epoch 89 Train Acc 78.75609588623047% Val Acc 32.21428680419922% Train Loss 0.2766965925693512 Val Loss 2.4477150440216064
Trainable Parameters : 198660
Epoch 90 Train Acc 78.23170471191406% Val Acc 33.02381134033203% Train Loss 0.2800031304359436 Val Loss 2.2194416522979736
Trainable Parameters : 198660
Epoch 91 Train Acc 79.19512176513672% Val Acc 31.071428298950195% Train Loss 0.28089264035224915 Val Loss 2.3676910400390625
Trainable Parameters : 198660
Epoch 92 Train Acc 78.06097412109375% Val Acc 31.595237731933594% Train Loss 0.2830827832221985 Val Loss 2.7317793369293213
Trainable Parameters : 198660
Epoch 93 Train Acc 79.243896484375% Val Acc 31.5238094329834% Train Loss 0.267253577709198 Val Loss 2.4610700607299805
Trainable Parameters : 198660
Epoch 94 Train Acc 77.21951293945312% Val Acc 31.2738094329834% Train Loss 0.28205373883247375 Val Loss 2.4444007873535156
Trainable Parameters : 198660
Epoch 95 Train Acc 79.86585235595703% Val Acc 31.96428680419922% Train Loss 0.27007511258125305 Val Loss 2.374856472015381
Trainable Parameters : 198660
Epoch 96 Train Acc 79.75609588623047% Val Acc 32.05952453613281% Train Loss 0.2646177113056183 Val Loss 2.313321590423584
Trainable Parameters : 198660
Epoch 97 Train Acc 79.63414001464844% Val Acc 31.761905670166016% Train Loss 0.2671823799610138 Val Loss 2.5866658687591553
Trainable Parameters : 198660
Epoch 98 Train Acc 78.7682876586914% Val Acc 31.2738094329834% Train Loss 0.274071604013443 Val Loss 2.4590070247650146
Trainable Parameters : 198660
Epoch 99 Train Acc 79.03658294677734% Val Acc 32.41666793823242% Train Loss 0.2705998420715332 Val Loss 2.3062078952789307

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.   0.   0.   0.  ]
 [0.25 0.   0.   0.  ]
 [0.5  0.   0.   0.25]
 [0.   0.   0.   0.  ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
         497       0.00      0.00      0.00       1.0
         500       0.00      0.00      0.00       3.0
        1997       0.00      0.00      0.00       0.0

    accuracy                           0.00       4.0
   macro avg       0.00      0.00      0.00       4.0
weighted avg       0.00      0.00      0.00       4.0


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/10/2022 11:54:48
