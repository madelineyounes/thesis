Thu Oct 13 17:25:45 AEDT 2022
Traceback (most recent call last):
  File "run_extract_debug.py", line 34, in <module>
    from customData import CustomDataset
  File "/home/z5208494/thesis/customData.py", line 11, in <module>
    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained("facebook/wav2vec2-base")
AttributeError: type object 'Wav2Vec2FeatureExtractor' has no attribute 'from_pretrained'
Thu Oct 13 17:30:24 AEDT 2022
Traceback (most recent call last):
  File "run_extract_debug.py", line 34, in <module>
    from customData import CustomDataset
  File "/home/z5208494/thesis/customData.py", line 21, in <module>
    class CustomDataset(Dataset):
  File "/home/z5208494/thesis/customData.py", line 22, in CustomDataset
    def __init__(self, csv_fp, data_fp, labels, transform=None, sampling_rate=16000, model_name="facebook/wav2vec2-base", max_length=0.1, feature_extractor=feature_extractor):
NameError: name 'feature_extractor' is not defined
Thu Oct 13 17:39:38 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_extract_debug.py
Started: 13/10/2022 17:39:42

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-extract-debug
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_100f_devdata
train_filename: dev_u_100f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_100f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0067,  0.3812,  0.4503,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2902,  0.4126,  0.4613,  ...,  0.0000,  0.0000,  0.0000],
        [-1.4332, -1.6084, -1.2776,  ...,  1.1482,  1.4105,  1.3386],
        ...,
        [ 0.1016,  0.1322,  0.0812,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4436,  0.3455,  0.1691,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0570, -0.1672, -0.1316,  ...,  2.4849,  2.4503,  2.6989]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 3, 0, 2, 2, 3, 0, 1, 2, 2, 3, 2])}
Training DataCustom Files: 398
Training Data Files: 34
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_hid.bias', 'quantizer.codevectors', 'quantizer.weight_proj.weight', 'project_q.bias', 'quantizer.weight_proj.bias', 'project_hid.weight', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.weight', 'projector.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.4425, -0.6423, -0.5603,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0570, -0.0956,  0.0032,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4753,  1.0656,  1.5569,  ...,  0.0571,  0.1342,  0.0935],
        ...,
        [-0.1085, -0.0892, -0.0747,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0562,  0.0712,  0.1063,  ...,  1.6317,  1.3883,  1.2421],
        [-0.0740, -0.0610, -0.0502,  ...,  0.4281,  0.2382,  0.0601]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 3, 1, 1, 2, 1, 1, 3, 3, 2, 0, 0])}
Test CustomData Files: 398
Test Data Files: 34
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
features extractedfeatures extractedEpoch 0 Train Acc 26.735294342041016% Val Acc 27.176469802856445% Train Loss 0.6941004395484924 Val Loss 1.3818777799606323
Trainable Parameters : 198660Epoch 1 Train Acc 26.676469802856445% Val Acc 26.47058868408203% Train Loss 0.693774402141571 Val Loss 1.382741093635559
Trainable Parameters : 198660Epoch 2 Train Acc 27.41176414489746% Val Acc 26.941177368164062% Train Loss 0.6929486989974976 Val Loss 1.3827229738235474
Trainable Parameters : 198660Epoch 3 Train Acc 31.352941513061523% Val Acc 29.91176414489746% Train Loss 0.6914154887199402 Val Loss 1.3829065561294556
Trainable Parameters : 198660Epoch 4 Train Acc 29.176469802856445% Val Acc 27.941177368164062% Train Loss 0.6910625100135803 Val Loss 1.3842332363128662
Trainable Parameters : 198660Epoch 5 Train Acc 33.02941131591797% Val Acc 27.5% Train Loss 0.6896205544471741 Val Loss 1.3858047723770142
Trainable Parameters : 198660Epoch 6 Train Acc 39.20588302612305% Val Acc 25.823530197143555% Train Loss 0.6875423789024353 Val Loss 1.387985348701477
Trainable Parameters : 198660Epoch 7 Train Acc 34.79411697387695% Val Acc 22.323530197143555% Train Loss 0.686070442199707 Val Loss 1.3901602029800415
Trainable Parameters : 198660Epoch 8 Train Acc 38.882354736328125% Val Acc 20.117647171020508% Train Loss 0.6837987303733826 Val Loss 1.3936767578125
Trainable Parameters : 198660Epoch 9 Train Acc 42.588233947753906% Val Acc 18.382352828979492% Train Loss 0.6808381080627441 Val Loss 1.396226167678833
Trainable Parameters : 198660Epoch 10 Train Acc 44.11764907836914% Val Acc 17.47058868408203% Train Loss 0.6785421967506409 Val Loss 1.3982208967208862
Trainable Parameters : 198660Epoch 11 Train Acc 42.70588302612305% Val Acc 15.235294342041016% Train Loss 0.6751244068145752 Val Loss 1.4029380083084106
Trainable Parameters : 198660Epoch 12 Train Acc 41.882354736328125% Val Acc 15.382352828979492% Train Loss 0.6730645895004272 Val Loss 1.4067344665527344
Trainable Parameters : 198660Epoch 13 Train Acc 45.02941131591797% Val Acc 16.852941513061523% Train Loss 0.6677408814430237 Val Loss 1.411287784576416
Trainable Parameters : 198660Epoch 14 Train Acc 44.382354736328125% Val Acc 15.647058486938477% Train Loss 0.6665152907371521 Val Loss 1.4169427156448364
Trainable Parameters : 198660Epoch 15 Train Acc 44.35293960571289% Val Acc 15.70588207244873% Train Loss 0.6638274192810059 Val Loss 1.4219627380371094
Trainable Parameters : 198660Epoch 16 Train Acc 46.35293960571289% Val Acc 15.235294342041016% Train Loss 0.6584039926528931 Val Loss 1.4255434274673462
Trainable Parameters : 198660Epoch 17 Train Acc 43.94117736816406% Val Acc 15.470588684082031% Train Loss 0.6542797088623047 Val Loss 1.4302653074264526
Trainable Parameters : 198660Epoch 18 Train Acc 44.382354736328125% Val Acc 15.617647171020508% Train Loss 0.6483295559883118 Val Loss 1.4381812810897827
Trainable Parameters : 198660Epoch 19 Train Acc 49.264705657958984% Val Acc 17.147058486938477% Train Loss 0.6459395289421082 Val Loss 1.4450442790985107
Trainable Parameters : 198660Epoch 20 Train Acc 45.32352828979492% Val Acc 15.647058486938477% Train Loss 0.642457902431488 Val Loss 1.4545871019363403
Trainable Parameters : 198660Epoch 21 Train Acc 49.82352828979492% Val Acc 15.882352828979492% Train Loss 0.6350853443145752 Val Loss 1.4596492052078247
Trainable Parameters : 198660Epoch 22 Train Acc 47.32352828979492% Val Acc 15.941176414489746% Train Loss 0.636110246181488 Val Loss 1.4668649435043335
Trainable Parameters : 198660Epoch 23 Train Acc 47.088233947753906% Val Acc 15.617647171020508% Train Loss 0.62735515832901 Val Loss 1.4793792963027954
Trainable Parameters : 198660Epoch 24 Train Acc 47.735294342041016% Val Acc 18.58823585510254% Train Loss 0.6247339844703674 Val Loss 1.479286551475525
Trainable Parameters : 198660Epoch 25 Train Acc 49.735294342041016% Val Acc 17.05882453918457% Train Loss 0.6205844879150391 Val Loss 1.4974998235702515
Trainable Parameters : 198660Epoch 26 Train Acc 47.61764907836914% Val Acc 16.441177368164062% Train Loss 0.618765652179718 Val Loss 1.5038189888000488
Trainable Parameters : 198660Epoch 27 Train Acc 49.264705657958984% Val Acc 18.176469802856445% Train Loss 0.6133056282997131 Val Loss 1.5129200220108032
Trainable Parameters : 198660Epoch 28 Train Acc 50.44117736816406% Val Acc 18.647058486938477% Train Loss 0.609683632850647 Val Loss 1.5185461044311523
Trainable Parameters : 198660Epoch 29 Train Acc 48.55882263183594% Val Acc 18.147058486938477% Train Loss 0.6065064668655396 Val Loss 1.5253437757492065
Trainable Parameters : 198660Epoch 30 Train Acc 48.82352828979492% Val Acc 19.735294342041016% Train Loss 0.6043727993965149 Val Loss 1.541648030281067
Trainable Parameters : 198660Epoch 31 Train Acc 47.94117736816406% Val Acc 19.55882453918457% Train Loss 0.5975363850593567 Val Loss 1.542214274406433
Trainable Parameters : 198660Epoch 32 Train Acc 51.382354736328125% Val Acc 18.352941513061523% Train Loss 0.5912929177284241 Val Loss 1.5596387386322021
Trainable Parameters : 198660Epoch 33 Train Acc 51.97058868408203% Val Acc 19.55882453918457% Train Loss 0.5921028852462769 Val Loss 1.5628334283828735
Trainable Parameters : 198660Epoch 34 Train Acc 50.97058868408203% Val Acc 18.91176414489746% Train Loss 0.5848707556724548 Val Loss 1.5728753805160522
Trainable Parameters : 198660Epoch 35 Train Acc 50.764705657958984% Val Acc 19.52941131591797% Train Loss 0.5851998329162598 Val Loss 1.582415223121643
Trainable Parameters : 198660Epoch 36 Train Acc 53.61764907836914% Val Acc 18.676469802856445% Train Loss 0.5805627703666687 Val Loss 1.5942182540893555
Trainable Parameters : 198660Epoch 37 Train Acc 51.5% Val Acc 20.02941131591797% Train Loss 0.5773760080337524 Val Loss 1.61542546749115
Trainable Parameters : 198660Epoch 38 Train Acc 55.382354736328125% Val Acc 18.617647171020508% Train Loss 0.570370614528656 Val Loss 1.6235029697418213
Trainable Parameters : 198660Epoch 39 Train Acc 55.17647171020508% Val Acc 19.117647171020508% Train Loss 0.565595805644989 Val Loss 1.6158411502838135
Trainable Parameters : 198660Epoch 40 Train Acc 54.64706039428711% Val Acc 19.91176414489746% Train Loss 0.5668699741363525 Val Loss 1.6508655548095703
Trainable Parameters : 198660Epoch 41 Train Acc 55.44117736816406% Val Acc 21.235294342041016% Train Loss 0.5694385170936584 Val Loss 1.6207324266433716
Trainable Parameters : 198660Epoch 42 Train Acc 54.911766052246094% Val Acc 20.58823585510254% Train Loss 0.5515345931053162 Val Loss 1.6795603036880493
Trainable Parameters : 198660Epoch 43 Train Acc 58.11764907836914% Val Acc 20.147058486938477% Train Loss 0.5487332940101624 Val Loss 1.6419527530670166
Trainable Parameters : 198660Epoch 44 Train Acc 55.11764907836914% Val Acc 21.52941131591797% Train Loss 0.5420185923576355 Val Loss 1.6642789840698242
Trainable Parameters : 198660Epoch 45 Train Acc 56.35293960571289% Val Acc 22.55882453918457% Train Loss 0.5459985136985779 Val Loss 1.6623834371566772
Trainable Parameters : 198660Epoch 46 Train Acc 56.882354736328125% Val Acc 21.147058486938477% Train Loss 0.540831446647644 Val Loss 1.6809512376785278
Trainable Parameters : 198660Epoch 47 Train Acc 56.764705657958984% Val Acc 20.735294342041016% Train Loss 0.5366278290748596 Val Loss 1.6806302070617676
Trainable Parameters : 198660Epoch 48 Train Acc 58.20588302612305% Val Acc 21.05882453918457% Train Loss 0.5300653576850891 Val Loss 1.6805214881896973
Trainable Parameters : 198660Epoch 49 Train Acc 55.94117736816406% Val Acc 21.147058486938477% Train Loss 0.5235353708267212 Val Loss 1.6773253679275513
Trainable Parameters : 198660Epoch 50 Train Acc 60.29411697387695% Val Acc 22.47058868408203% Train Loss 0.5209850072860718 Val Loss 1.6833471059799194
Trainable Parameters : 198660Epoch 51 Train Acc 59.588233947753906% Val Acc 22.735294342041016% Train Loss 0.5174687504768372 Val Loss 1.7003051042556763
Trainable Parameters : 198660Epoch 52 Train Acc 58.11764907836914% Val Acc 21.08823585510254% Train Loss 0.5133529305458069 Val Loss 1.7508667707443237
Trainable Parameters : 198660Epoch 53 Train Acc 60.0% Val Acc 22.0% Train Loss 0.5081117749214172 Val Loss 1.7195860147476196
Trainable Parameters : 198660Epoch 54 Train Acc 58.82352828979492% Val Acc 20.852941513061523% Train Loss 0.5040901899337769 Val Loss 1.7224605083465576
Trainable Parameters : 198660Epoch 55 Train Acc 63.5% Val Acc 21.352941513061523% Train Loss 0.48851698637008667 Val Loss 1.7193535566329956
Trainable Parameters : 198660Epoch 56 Train Acc 63.0% Val Acc 21.352941513061523% Train Loss 0.49266573786735535 Val Loss 1.7389860153198242
Trainable Parameters : 198660Epoch 57 Train Acc 63.5% Val Acc 22.117647171020508% Train Loss 0.48394545912742615 Val Loss 1.7214540243148804
Trainable Parameters : 198660Epoch 58 Train Acc 64.5% Val Acc 23.235294342041016% Train Loss 0.47400176525115967 Val Loss 1.7298306226730347
Trainable Parameters : 198660Epoch 59 Train Acc 63.94117736816406% Val Acc 23.764705657958984% Train Loss 0.46394532918930054 Val Loss 1.7377064228057861
Trainable Parameters : 198660Epoch 60 Train Acc 66.17646789550781% Val Acc 22.235294342041016% Train Loss 0.46356967091560364 Val Loss 1.7488818168640137
Trainable Parameters : 198660Epoch 61 Train Acc 64.4117660522461% Val Acc 22.02941131591797% Train Loss 0.4649803936481476 Val Loss 1.769755482673645
Trainable Parameters : 198660Epoch 62 Train Acc 64.9117660522461% Val Acc 23.264705657958984% Train Loss 0.4635571539402008 Val Loss 1.7826467752456665
Trainable Parameters : 198660Epoch 63 Train Acc 66.44117736816406% Val Acc 20.882352828979492% Train Loss 0.4510883092880249 Val Loss 1.791617751121521
Trainable Parameters : 198660Epoch 64 Train Acc 67.82353210449219% Val Acc 24.05882453918457% Train Loss 0.44616439938545227 Val Loss 1.7815595865249634
Trainable Parameters : 198660Epoch 65 Train Acc 64.73529815673828% Val Acc 21.882352828979492% Train Loss 0.44142571091651917 Val Loss 1.7946261167526245
Trainable Parameters : 198660Epoch 66 Train Acc 68.61764526367188% Val Acc 22.52941131591797% Train Loss 0.4288328289985657 Val Loss 1.81021249294281
Trainable Parameters : 198660Epoch 67 Train Acc 69.14705657958984% Val Acc 22.0% Train Loss 0.43566393852233887 Val Loss 1.8253413438796997
Trainable Parameters : 198660Epoch 68 Train Acc 69.0882339477539% Val Acc 22.47058868408203% Train Loss 0.4345605671405792 Val Loss 1.8402568101882935
Trainable Parameters : 198660Epoch 69 Train Acc 71.23529815673828% Val Acc 22.05882453918457% Train Loss 0.4173165261745453 Val Loss 1.8425549268722534
Trainable Parameters : 198660Epoch 70 Train Acc 70.0882339477539% Val Acc 21.852941513061523% Train Loss 0.41211143136024475 Val Loss 1.8727726936340332
Trainable Parameters : 198660Epoch 71 Train Acc 70.35294342041016% Val Acc 21.58823585510254% Train Loss 0.40908071398735046 Val Loss 1.864184856414795
Trainable Parameters : 198660Epoch 72 Train Acc 68.88235473632812% Val Acc 22.794116973876953% Train Loss 0.4099316895008087 Val Loss 1.8825398683547974
Trainable Parameters : 198660Epoch 73 Train Acc 70.52941131591797% Val Acc 24.205883026123047% Train Loss 0.4017408788204193 Val Loss 1.8507075309753418
Trainable Parameters : 198660Epoch 74 Train Acc 71.26470947265625% Val Acc 21.735294342041016% Train Loss 0.38887423276901245 Val Loss 1.8917269706726074
Trainable Parameters : 198660Epoch 75 Train Acc 69.11764526367188% Val Acc 22.52941131591797% Train Loss 0.390809029340744 Val Loss 1.9069414138793945
Trainable Parameters : 198660Epoch 76 Train Acc 74.0882339477539% Val Acc 21.323530197143555% Train Loss 0.38961178064346313 Val Loss 1.8986564874649048
Trainable Parameters : 198660Epoch 77 Train Acc 73.55882263183594% Val Acc 23.294116973876953% Train Loss 0.3815472424030304 Val Loss 1.9114727973937988
Trainable Parameters : 198660Epoch 78 Train Acc 73.0882339477539% Val Acc 22.58823585510254% Train Loss 0.3658440113067627 Val Loss 1.919618010520935
Trainable Parameters : 198660Epoch 79 Train Acc 75.76470947265625% Val Acc 22.823530197143555% Train Loss 0.356728196144104 Val Loss 2.003310441970825
Trainable Parameters : 198660Epoch 80 Train Acc 76.20587921142578% Val Acc 23.735294342041016% Train Loss 0.35161590576171875 Val Loss 1.9814255237579346
Trainable Parameters : 198660Epoch 81 Train Acc 77.64705657958984% Val Acc 21.05882453918457% Train Loss 0.34325650334358215 Val Loss 1.985625982284546
Trainable Parameters : 198660Epoch 82 Train Acc 76.67646789550781% Val Acc 24.764705657958984% Train Loss 0.3393034338951111 Val Loss 1.9563331604003906
Trainable Parameters : 198660Epoch 83 Train Acc 77.47058868408203% Val Acc 21.382352828979492% Train Loss 0.3380180299282074 Val Loss 2.002467393875122
Trainable Parameters : 198660Epoch 84 Train Acc 74.94117736816406% Val Acc 22.794116973876953% Train Loss 0.34651055932044983 Val Loss 2.017223596572876
Trainable Parameters : 198660Epoch 85 Train Acc 76.88235473632812% Val Acc 21.58823585510254% Train Loss 0.3234698176383972 Val Loss 2.088993549346924
Trainable Parameters : 198660Epoch 86 Train Acc 78.76470947265625% Val Acc 20.91176414489746% Train Loss 0.32131925225257874 Val Loss 2.0528008937835693
Trainable Parameters : 198660Epoch 87 Train Acc 80.35294342041016% Val Acc 21.58823585510254% Train Loss 0.31113356351852417 Val Loss 2.067861795425415
Trainable Parameters : 198660Epoch 88 Train Acc 79.88235473632812% Val Acc 21.823530197143555% Train Loss 0.31173548102378845 Val Loss 2.11141037940979
Trainable Parameters : 198660Epoch 89 Train Acc 79.11764526367188% Val Acc 24.794116973876953% Train Loss 0.2988278865814209 Val Loss 2.051100015640259
Trainable Parameters : 198660Epoch 90 Train Acc 80.11764526367188% Val Acc 19.823530197143555% Train Loss 0.29669666290283203 Val Loss 2.1578598022460938
Trainable Parameters : 198660Epoch 91 Train Acc 81.9117660522461% Val Acc 23.08823585510254% Train Loss 0.2883376479148865 Val Loss 2.122358560562134
Trainable Parameters : 198660Epoch 92 Train Acc 80.32353210449219% Val Acc 24.5% Train Loss 0.29111504554748535 Val Loss 2.114452838897705
Trainable Parameters : 198660Epoch 93 Train Acc 83.61764526367188% Val Acc 22.294116973876953% Train Loss 0.27578315138816833 Val Loss 2.157013177871704
Trainable Parameters : 198660Epoch 94 Train Acc 81.32353210449219% Val Acc 22.55882453918457% Train Loss 0.2905009090900421 Val Loss 2.1394314765930176
Trainable Parameters : 198660Epoch 95 Train Acc 85.5882339477539% Val Acc 23.47058868408203% Train Loss 0.2746807634830475 Val Loss 2.2803361415863037
Trainable Parameters : 198660Epoch 96 Train Acc 85.55882263183594% Val Acc 24.235294342041016% Train Loss 0.2637978792190552 Val Loss 2.2273993492126465
Trainable Parameters : 198660Epoch 97 Train Acc 83.05882263183594% Val Acc 24.235294342041016% Train Loss 0.26315855979919434 Val Loss 2.1770856380462646
Trainable Parameters : 198660Epoch 98 Train Acc 85.5882339477539% Val Acc 24.02941131591797% Train Loss 0.25507116317749023 Val Loss 2.257598638534546
Trainable Parameters : 198660


features extracted
Configuration saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug/config.json
Model weights saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug/pytorch_model.bin
Epoch 99 Train Acc 84.47058868408203% Val Acc 23.617647171020508% Train Loss 0.2619721293449402 Val Loss 2.446624994277954

------> EVALUATING MODEL... ------------------------------------------ 

features extracted/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.25125628 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]
 [0.24623116 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40       100
           1       0.00      0.00      0.00       100
           2       0.00      0.00      0.00        98
           3       0.00      0.00      0.00       100

    accuracy                           0.25       398
   macro avg       0.06      0.25      0.10       398
weighted avg       0.06      0.25      0.10       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 13/10/2022 17:52:18
Thu Oct 13 19:32:51 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_extract_debug.py
Started: 13/10/2022 19:32:55

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-extract-debug
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_100f_devdata
train_filename: dev_u_100f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_100f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.6236, -0.6436, -0.6484,  ...,  0.4023,  0.3356,  0.3005],
        [ 0.0588,  0.0271,  0.0471,  ...,  0.1821,  0.1573,  0.0976],
        [ 0.1445,  0.2412,  0.3007,  ...,  0.0358,  0.2127,  0.3861],
        ...,
        [-0.8749, -0.5432,  0.2489,  ...,  0.0095,  0.0088,  0.0060],
        [ 0.4276, -0.5919,  0.7526,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.8563,  0.1170, -0.2756,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 3, 2, 2, 3, 0, 1, 1, 2, 2, 0])}
Training DataCustom Files: 398
Training Data Files: 34
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.bias', 'project_hid.weight', 'quantizer.weight_proj.bias', 'project_q.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.bias', 'projector.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.3886, -0.1772, -0.0769,  ...,  0.1529,  0.1480,  0.1578],
        [ 1.0273,  1.2847,  1.8203,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.7782,  0.7331,  0.6194,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1336, -0.5650,  0.2561,  ...,  0.3502,  0.3502,  0.3476],
        [ 0.0622, -0.0588, -0.4113,  ..., -2.9705, -1.2415, -0.0357],
        [-0.6690, -0.1195,  0.3500,  ...,  1.9603,  2.3485,  2.3915]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 0, 0, 3, 3, 0, 0, 0, 0, 1, 2, 0])}
Test CustomData Files: 398
Test Data Files: 34
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 21.05882453918457% Val Acc 32.14706039428711% Train Loss 0.6953603029251099 Val Loss 1.3818354606628418
Trainable Parameters : 198660
Epoch 1 Train Acc 21.617647171020508% Val Acc 28.441177368164062% Train Loss 0.6953346133232117 Val Loss 1.3851613998413086
Trainable Parameters : 198660
Epoch 2 Train Acc 22.794116973876953% Val Acc 28.205883026123047% Train Loss 0.6938522458076477 Val Loss 1.3836863040924072
Trainable Parameters : 198660
Epoch 3 Train Acc 22.294116973876953% Val Acc 26.205883026123047% Train Loss 0.6935803294181824 Val Loss 1.3845480680465698
Trainable Parameters : 198660
Epoch 4 Train Acc 25.441177368164062% Val Acc 21.852941513061523% Train Loss 0.6912909150123596 Val Loss 1.3867915868759155
Trainable Parameters : 198660
Epoch 5 Train Acc 26.5% Val Acc 21.58823585510254% Train Loss 0.6903377175331116 Val Loss 1.3868367671966553
Trainable Parameters : 198660
Epoch 6 Train Acc 30.323530197143555% Val Acc 17.91176414489746% Train Loss 0.6888530254364014 Val Loss 1.3895115852355957
Trainable Parameters : 198660
Epoch 7 Train Acc 34.52941131591797% Val Acc 18.176469802856445% Train Loss 0.6866421103477478 Val Loss 1.391175389289856
Trainable Parameters : 198660
Epoch 8 Train Acc 38.264705657958984% Val Acc 14.941176414489746% Train Loss 0.6848811507225037 Val Loss 1.3949151039123535
Trainable Parameters : 198660
Epoch 9 Train Acc 39.20588302612305% Val Acc 14.441176414489746% Train Loss 0.6818104386329651 Val Loss 1.3971736431121826
Trainable Parameters : 198660
Epoch 10 Train Acc 41.44117736816406% Val Acc 14.617647171020508% Train Loss 0.6797066926956177 Val Loss 1.3996095657348633
Trainable Parameters : 198660
Epoch 11 Train Acc 44.85293960571289% Val Acc 14.676470756530762% Train Loss 0.6758856177330017 Val Loss 1.4028561115264893
Trainable Parameters : 198660
Epoch 12 Train Acc 44.64706039428711% Val Acc 14.617647171020508% Train Loss 0.6732451915740967 Val Loss 1.4066120386123657
Trainable Parameters : 198660
Epoch 13 Train Acc 44.82352828979492% Val Acc 14.941176414489746% Train Loss 0.6688348054885864 Val Loss 1.4114595651626587
Trainable Parameters : 198660
Epoch 14 Train Acc 47.05882263183594% Val Acc 16.91176414489746% Train Loss 0.666238009929657 Val Loss 1.4161972999572754
Trainable Parameters : 198660
Epoch 15 Train Acc 45.088233947753906% Val Acc 17.294116973876953% Train Loss 0.663569450378418 Val Loss 1.4200160503387451
Trainable Parameters : 198660
Epoch 16 Train Acc 47.55882263183594% Val Acc 18.147058486938477% Train Loss 0.6583333611488342 Val Loss 1.4269773960113525
Trainable Parameters : 198660
Epoch 17 Train Acc 47.61764907836914% Val Acc 17.705883026123047% Train Loss 0.654350757598877 Val Loss 1.4301739931106567
Trainable Parameters : 198660
Epoch 18 Train Acc 47.52941131591797% Val Acc 18.323530197143555% Train Loss 0.649882435798645 Val Loss 1.437490463256836
Trainable Parameters : 198660
Epoch 19 Train Acc 49.0% Val Acc 18.617647171020508% Train Loss 0.6476002335548401 Val Loss 1.4453898668289185
Trainable Parameters : 198660
Epoch 20 Train Acc 46.0% Val Acc 19.882352828979492% Train Loss 0.6430946588516235 Val Loss 1.4530322551727295
Trainable Parameters : 198660
Epoch 21 Train Acc 51.47058868408203% Val Acc 19.617647171020508% Train Loss 0.63605797290802 Val Loss 1.4574178457260132
Trainable Parameters : 198660
Epoch 22 Train Acc 49.29411697387695% Val Acc 18.647058486938477% Train Loss 0.6359174251556396 Val Loss 1.4658974409103394
Trainable Parameters : 198660
Epoch 23 Train Acc 48.52941131591797% Val Acc 18.58823585510254% Train Loss 0.6292263269424438 Val Loss 1.4766496419906616
Trainable Parameters : 198660
Epoch 24 Train Acc 51.20588302612305% Val Acc 20.382352828979492% Train Loss 0.6239501237869263 Val Loss 1.4775031805038452
Trainable Parameters : 198660
Epoch 25 Train Acc 52.35293960571289% Val Acc 18.852941513061523% Train Loss 0.6205781102180481 Val Loss 1.4967118501663208
Trainable Parameters : 198660
Epoch 26 Train Acc 50.97058868408203% Val Acc 18.882352828979492% Train Loss 0.6174160838127136 Val Loss 1.5030196905136108
Trainable Parameters : 198660
Epoch 27 Train Acc 50.64706039428711% Val Acc 18.676469802856445% Train Loss 0.6138690710067749 Val Loss 1.512839436531067
Trainable Parameters : 198660
Epoch 28 Train Acc 52.235294342041016% Val Acc 19.02941131591797% Train Loss 0.6081590056419373 Val Loss 1.5182749032974243
Trainable Parameters : 198660
Epoch 29 Train Acc 50.911766052246094% Val Acc 18.735294342041016% Train Loss 0.6051040291786194 Val Loss 1.5248336791992188
Trainable Parameters : 198660
Epoch 30 Train Acc 49.32352828979492% Val Acc 20.41176414489746% Train Loss 0.6061630845069885 Val Loss 1.5411505699157715
Trainable Parameters : 198660
Epoch 31 Train Acc 51.20588302612305% Val Acc 22.52941131591797% Train Loss 0.5968033075332642 Val Loss 1.54116690158844
Trainable Parameters : 198660
Epoch 32 Train Acc 55.61764907836914% Val Acc 20.352941513061523% Train Loss 0.5892097353935242 Val Loss 1.5612800121307373
Trainable Parameters : 198660
Epoch 33 Train Acc 53.94117736816406% Val Acc 21.294116973876953% Train Loss 0.5936163663864136 Val Loss 1.5646013021469116
Trainable Parameters : 198660
Epoch 34 Train Acc 52.97058868408203% Val Acc 20.647058486938477% Train Loss 0.5839852094650269 Val Loss 1.5742900371551514
Trainable Parameters : 198660
Epoch 35 Train Acc 51.44117736816406% Val Acc 22.235294342041016% Train Loss 0.58844393491745 Val Loss 1.5826332569122314
Trainable Parameters : 198660
Epoch 36 Train Acc 54.85293960571289% Val Acc 19.91176414489746% Train Loss 0.5779899954795837 Val Loss 1.5950511693954468
Trainable Parameters : 198660
Epoch 37 Train Acc 51.67647171020508% Val Acc 21.323530197143555% Train Loss 0.5743662118911743 Val Loss 1.6185293197631836
Trainable Parameters : 198660
Epoch 38 Train Acc 54.94117736816406% Val Acc 20.08823585510254% Train Loss 0.5686637163162231 Val Loss 1.6284091472625732
Trainable Parameters : 198660
Epoch 39 Train Acc 57.17647171020508% Val Acc 20.117647171020508% Train Loss 0.563686192035675 Val Loss 1.6193684339523315
Trainable Parameters : 198660
Epoch 40 Train Acc 55.088233947753906% Val Acc 20.617647171020508% Train Loss 0.5640369057655334 Val Loss 1.6567373275756836
Trainable Parameters : 198660
Epoch 41 Train Acc 55.11764907836914% Val Acc 22.05882453918457% Train Loss 0.5694730281829834 Val Loss 1.6248255968093872
Trainable Parameters : 198660
Epoch 42 Train Acc 55.588233947753906% Val Acc 21.352941513061523% Train Loss 0.5505557060241699 Val Loss 1.6854478120803833
Trainable Parameters : 198660
Epoch 43 Train Acc 58.382354736328125% Val Acc 21.882352828979492% Train Loss 0.5454115271568298 Val Loss 1.64705491065979
Trainable Parameters : 198660
Epoch 44 Train Acc 57.14706039428711% Val Acc 21.97058868408203% Train Loss 0.5404795408248901 Val Loss 1.673785924911499
Trainable Parameters : 198660
Epoch 45 Train Acc 56.29411697387695% Val Acc 22.05882453918457% Train Loss 0.5449071526527405 Val Loss 1.6701403856277466
Trainable Parameters : 198660
Epoch 46 Train Acc 57.79411697387695% Val Acc 21.647058486938477% Train Loss 0.5381066203117371 Val Loss 1.6897910833358765
Trainable Parameters : 198660
Epoch 47 Train Acc 59.47058868408203% Val Acc 20.852941513061523% Train Loss 0.535754919052124 Val Loss 1.6932501792907715
Trainable Parameters : 198660
Epoch 48 Train Acc 57.85293960571289% Val Acc 21.58823585510254% Train Loss 0.5305957794189453 Val Loss 1.690590739250183
Trainable Parameters : 198660
Epoch 49 Train Acc 60.02941131591797% Val Acc 21.823530197143555% Train Loss 0.5197063088417053 Val Loss 1.6917119026184082
Trainable Parameters : 198660
Epoch 50 Train Acc 58.32352828979492% Val Acc 22.735294342041016% Train Loss 0.5181859731674194 Val Loss 1.696714997291565
Trainable Parameters : 198660
Epoch 51 Train Acc 58.764705657958984% Val Acc 21.52941131591797% Train Loss 0.5128726959228516 Val Loss 1.7137068510055542
Trainable Parameters : 198660
Epoch 52 Train Acc 59.79411697387695% Val Acc 22.08823585510254% Train Loss 0.5133148431777954 Val Loss 1.763171911239624
Trainable Parameters : 198660
Epoch 53 Train Acc 58.61764907836914% Val Acc 21.58823585510254% Train Loss 0.5094755291938782 Val Loss 1.7335474491119385
Trainable Parameters : 198660
Epoch 54 Train Acc 61.0% Val Acc 21.823530197143555% Train Loss 0.5004566311836243 Val Loss 1.7395999431610107
Trainable Parameters : 198660
Epoch 55 Train Acc 62.088233947753906% Val Acc 22.352941513061523% Train Loss 0.4894430935382843 Val Loss 1.7352774143218994
Trainable Parameters : 198660
Epoch 56 Train Acc 63.02941131591797% Val Acc 21.264705657958984% Train Loss 0.48704567551612854 Val Loss 1.7585816383361816
Trainable Parameters : 198660
Epoch 57 Train Acc 64.17646789550781% Val Acc 23.294116973876953% Train Loss 0.4788113236427307 Val Loss 1.7412328720092773
Trainable Parameters : 198660
Epoch 58 Train Acc 64.0% Val Acc 22.735294342041016% Train Loss 0.4703989624977112 Val Loss 1.7495286464691162
Trainable Parameters : 198660
Epoch 59 Train Acc 64.9117660522461% Val Acc 24.294116973876953% Train Loss 0.4672130048274994 Val Loss 1.7544043064117432
Trainable Parameters : 198660
Epoch 60 Train Acc 65.17646789550781% Val Acc 22.5% Train Loss 0.46064189076423645 Val Loss 1.7671501636505127
Trainable Parameters : 198660
Epoch 61 Train Acc 64.97058868408203% Val Acc 22.52941131591797% Train Loss 0.4614703357219696 Val Loss 1.7903589010238647
Trainable Parameters : 198660
Epoch 62 Train Acc 64.4117660522461% Val Acc 22.205883026123047% Train Loss 0.4611111581325531 Val Loss 1.8063974380493164
Trainable Parameters : 198660
Epoch 63 Train Acc 64.02941131591797% Val Acc 21.647058486938477% Train Loss 0.44869011640548706 Val Loss 1.8076815605163574
Trainable Parameters : 198660
Epoch 64 Train Acc 67.35294342041016% Val Acc 22.55882453918457% Train Loss 0.4432082176208496 Val Loss 1.7985665798187256
Trainable Parameters : 198660
Epoch 65 Train Acc 67.20587921142578% Val Acc 21.97058868408203% Train Loss 0.44559600949287415 Val Loss 1.8086669445037842
Trainable Parameters : 198660
Epoch 66 Train Acc 69.05882263183594% Val Acc 22.55882453918457% Train Loss 0.4311297535896301 Val Loss 1.8275142908096313
Trainable Parameters : 198660
Epoch 67 Train Acc 67.17646789550781% Val Acc 21.05882453918457% Train Loss 0.43471789360046387 Val Loss 1.844983696937561
Trainable Parameters : 198660
Epoch 68 Train Acc 68.4117660522461% Val Acc 20.794116973876953% Train Loss 0.432012677192688 Val Loss 1.856724500656128
Trainable Parameters : 198660
Epoch 69 Train Acc 70.61764526367188% Val Acc 21.323530197143555% Train Loss 0.4144544303417206 Val Loss 1.8631389141082764
Trainable Parameters : 198660
Epoch 70 Train Acc 70.52941131591797% Val Acc 22.117647171020508% Train Loss 0.41556623578071594 Val Loss 1.8954945802688599
Trainable Parameters : 198660
Epoch 71 Train Acc 72.64705657958984% Val Acc 21.352941513061523% Train Loss 0.4048455059528351 Val Loss 1.8863435983657837
Trainable Parameters : 198660
Epoch 72 Train Acc 70.5882339477539% Val Acc 22.794116973876953% Train Loss 0.4124084413051605 Val Loss 1.906267523765564
Trainable Parameters : 198660
Epoch 73 Train Acc 71.76470947265625% Val Acc 23.0% Train Loss 0.397727906703949 Val Loss 1.877545714378357
Trainable Parameters : 198660
Epoch 74 Train Acc 72.47058868408203% Val Acc 21.5% Train Loss 0.38677147030830383 Val Loss 1.9209027290344238
Trainable Parameters : 198660
Epoch 75 Train Acc 67.94117736816406% Val Acc 22.235294342041016% Train Loss 0.39728453755378723 Val Loss 1.9263743162155151
Trainable Parameters : 198660
Epoch 76 Train Acc 72.55882263183594% Val Acc 22.117647171020508% Train Loss 0.3953831195831299 Val Loss 1.9129867553710938
Trainable Parameters : 198660
Epoch 77 Train Acc 75.02941131591797% Val Acc 23.52941131591797% Train Loss 0.3807693123817444 Val Loss 1.9262208938598633
Trainable Parameters : 198660
Epoch 78 Train Acc 74.02941131591797% Val Acc 21.382352828979492% Train Loss 0.3676924705505371 Val Loss 1.9334981441497803
Trainable Parameters : 198660
Epoch 79 Train Acc 77.20587921142578% Val Acc 21.852941513061523% Train Loss 0.3571166694164276 Val Loss 2.0078535079956055
Trainable Parameters : 198660
Epoch 80 Train Acc 74.67646789550781% Val Acc 22.617647171020508% Train Loss 0.3557971119880676 Val Loss 1.9803924560546875
Trainable Parameters : 198660
Epoch 81 Train Acc 76.94117736816406% Val Acc 21.05882453918457% Train Loss 0.34986311197280884 Val Loss 1.9904909133911133
Trainable Parameters : 198660
Epoch 82 Train Acc 77.67646789550781% Val Acc 23.05882453918457% Train Loss 0.341335266828537 Val Loss 1.9682031869888306
Trainable Parameters : 198660
Epoch 83 Train Acc 77.14705657958984% Val Acc 21.117647171020508% Train Loss 0.34536218643188477 Val Loss 2.018275260925293
Trainable Parameters : 198660
Epoch 84 Train Acc 76.82353210449219% Val Acc 21.323530197143555% Train Loss 0.34551987051963806 Val Loss 2.025613307952881
Trainable Parameters : 198660
Epoch 85 Train Acc 78.44117736816406% Val Acc 21.617647171020508% Train Loss 0.3228229880332947 Val Loss 2.092351198196411
Trainable Parameters : 198660
Epoch 86 Train Acc 75.76470947265625% Val Acc 21.617647171020508% Train Loss 0.3211720287799835 Val Loss 2.068542957305908
Trainable Parameters : 198660
Epoch 87 Train Acc 80.32353210449219% Val Acc 22.117647171020508% Train Loss 0.31487002968788147 Val Loss 2.082277774810791
Trainable Parameters : 198660
Epoch 88 Train Acc 78.70587921142578% Val Acc 21.617647171020508% Train Loss 0.3163038194179535 Val Loss 2.1351029872894287
Trainable Parameters : 198660
Epoch 89 Train Acc 80.61764526367188% Val Acc 24.794116973876953% Train Loss 0.3009706735610962 Val Loss 2.0527801513671875
Trainable Parameters : 198660
Epoch 90 Train Acc 81.4117660522461% Val Acc 21.323530197143555% Train Loss 0.291291743516922 Val Loss 2.1636061668395996
Trainable Parameters : 198660
Epoch 91 Train Acc 81.67646789550781% Val Acc 24.52941131591797% Train Loss 0.2877480387687683 Val Loss 2.1425325870513916
Trainable Parameters : 198660
Epoch 92 Train Acc 79.0882339477539% Val Acc 23.97058868408203% Train Loss 0.2891733646392822 Val Loss 2.147989273071289
Trainable Parameters : 198660
Epoch 93 Train Acc 81.38235473632812% Val Acc 22.55882453918457% Train Loss 0.2864491641521454 Val Loss 2.1824934482574463
Trainable Parameters : 198660
Epoch 94 Train Acc 80.0882339477539% Val Acc 22.823530197143555% Train Loss 0.28094446659088135 Val Loss 2.1795523166656494
Trainable Parameters : 198660
Epoch 95 Train Acc 82.02941131591797% Val Acc 23.264705657958984% Train Loss 0.2750495672225952 Val Loss 2.2866170406341553
Trainable Parameters : 198660
Epoch 96 Train Acc 82.5882339477539% Val Acc 23.5% Train Loss 0.2691367268562317 Val Loss 2.2713475227355957
Trainable Parameters : 198660
Epoch 97 Train Acc 83.05882263183594% Val Acc 23.676469802856445% Train Loss 0.26582735776901245 Val Loss 2.225236177444458
Trainable Parameters : 198660
Epoch 98 Train Acc 84.11764526367188% Val Acc 23.941177368164062% Train Loss 0.2526143789291382 Val Loss 2.2812018394470215
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug/config.json
Model weights saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug/pytorch_model.bin
Epoch 99 Train Acc 84.5% Val Acc 22.55882453918457% Train Loss 0.25091326236724854 Val Loss 2.4298079013824463

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.25125628 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]
 [0.24623116 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40       100
           1       0.00      0.00      0.00       100
           2       0.00      0.00      0.00        98
           3       0.00      0.00      0.00       100

    accuracy                           0.25       398
   macro avg       0.06      0.25      0.10       398
weighted avg       0.06      0.25      0.10       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 13/10/2022 19:44:48
Thu Oct 13 19:54:09 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_extract_debug.py
Started: 13/10/2022 19:54:12

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-extract-debug
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_100f_devdata
train_filename: dev_u_100f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_100f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-6.3700e-02, -7.4516e-02, -2.9630e-03,  ..., -2.1097e-01,
         -2.0903e-01, -1.8074e-01],
        [-1.7240e+00, -2.2819e+00, -2.5591e+00,  ...,  1.3203e+00,
          1.4016e+00,  1.5269e+00],
        [ 2.9961e-04, -1.1613e-03, -1.1613e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 4.7113e-02,  6.2695e-02,  1.1695e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.7049e-01,  4.9348e-01,  3.9636e-01,  ...,  1.4859e+00,
          9.8194e-01,  1.0417e+00],
        [ 3.6920e-01,  5.1949e-01,  6.6236e-01,  ...,  9.3131e-03,
          1.0796e-02,  1.4034e-03]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 2, 1, 2, 3, 2, 3, 0, 1, 1, 0, 0])}
Training DataCustom Files: 398
Training Data Files: 34
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.bias', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_q.weight', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.bias', 'projector.weight', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.3278,  0.4798,  0.6488,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8974, -0.7318, -0.5734,  ...,  0.8264,  0.6168,  0.3516],
        [ 0.0688,  0.0602,  0.0615,  ..., -1.1414, -1.0860, -0.8914],
        ...,
        [ 0.6000,  0.5477,  0.7080,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0142,  0.0532, -0.0064,  ..., -0.0398, -0.0377, -0.0245],
        [ 1.5680,  1.5692,  1.4990,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 3, 3, 2, 3, 1, 2, 0, 3, 3, 1])}
Test CustomData Files: 398
Test Data Files: 34
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 23.235294342041016% Val Acc 28.147058486938477% Train Loss 0.7008424401283264 Val Loss 1.3809239864349365
Trainable Parameters : 198660
Epoch 1 Train Acc 22.852941513061523% Val Acc 26.235294342041016% Train Loss 0.7011228799819946 Val Loss 1.3858951330184937
Trainable Parameters : 198660
Epoch 2 Train Acc 24.941177368164062% Val Acc 25.764705657958984% Train Loss 0.6988415122032166 Val Loss 1.3847901821136475
Trainable Parameters : 198660
Epoch 3 Train Acc 24.294116973876953% Val Acc 25.235294342041016% Train Loss 0.6998066902160645 Val Loss 1.3840186595916748
Trainable Parameters : 198660
Epoch 4 Train Acc 24.794116973876953% Val Acc 26.941177368164062% Train Loss 0.698047399520874 Val Loss 1.384347677230835
Trainable Parameters : 198660
Epoch 5 Train Acc 25.941177368164062% Val Acc 26.205883026123047% Train Loss 0.6953616738319397 Val Loss 1.38462495803833
Trainable Parameters : 198660
Epoch 6 Train Acc 24.205883026123047% Val Acc 24.705883026123047% Train Loss 0.6940454244613647 Val Loss 1.3875523805618286
Trainable Parameters : 198660
Epoch 7 Train Acc 27.147058486938477% Val Acc 24.617647171020508% Train Loss 0.6919151544570923 Val Loss 1.3888591527938843
Trainable Parameters : 198660
Epoch 8 Train Acc 27.0% Val Acc 24.294116973876953% Train Loss 0.6890248656272888 Val Loss 1.3909789323806763
Trainable Parameters : 198660
Epoch 9 Train Acc 26.147058486938477% Val Acc 22.617647171020508% Train Loss 0.6875308156013489 Val Loss 1.3939201831817627
Trainable Parameters : 198660
Epoch 10 Train Acc 32.55882263183594% Val Acc 21.08823585510254% Train Loss 0.6840944886207581 Val Loss 1.3941495418548584
Trainable Parameters : 198660
Epoch 11 Train Acc 32.55882263183594% Val Acc 16.647058486938477% Train Loss 0.681268036365509 Val Loss 1.3993666172027588
Trainable Parameters : 198660
Epoch 12 Train Acc 36.0% Val Acc 17.58823585510254% Train Loss 0.6789708733558655 Val Loss 1.4032126665115356
Trainable Parameters : 198660
Epoch 13 Train Acc 41.17647171020508% Val Acc 18.647058486938477% Train Loss 0.6740301251411438 Val Loss 1.4064607620239258
Trainable Parameters : 198660
Epoch 14 Train Acc 41.382354736328125% Val Acc 19.176469802856445% Train Loss 0.6715677380561829 Val Loss 1.412034273147583
Trainable Parameters : 198660
Epoch 15 Train Acc 41.235294342041016% Val Acc 20.352941513061523% Train Loss 0.6685699820518494 Val Loss 1.4141881465911865
Trainable Parameters : 198660
Epoch 16 Train Acc 45.264705657958984% Val Acc 18.58823585510254% Train Loss 0.6635574698448181 Val Loss 1.4210807085037231
Trainable Parameters : 198660
Epoch 17 Train Acc 45.52941131591797% Val Acc 19.941177368164062% Train Loss 0.6601436734199524 Val Loss 1.4244650602340698
Trainable Parameters : 198660
Epoch 18 Train Acc 47.05882263183594% Val Acc 19.147058486938477% Train Loss 0.6552063226699829 Val Loss 1.4336289167404175
Trainable Parameters : 198660
Epoch 19 Train Acc 47.5% Val Acc 18.852941513061523% Train Loss 0.6524001359939575 Val Loss 1.4409834146499634
Trainable Parameters : 198660
Epoch 20 Train Acc 43.088233947753906% Val Acc 20.294116973876953% Train Loss 0.6488595604896545 Val Loss 1.4476628303527832
Trainable Parameters : 198660
Epoch 21 Train Acc 51.47058868408203% Val Acc 19.58823585510254% Train Loss 0.6420753598213196 Val Loss 1.452346682548523
Trainable Parameters : 198660
Epoch 22 Train Acc 45.85293960571289% Val Acc 18.176469802856445% Train Loss 0.6421463489532471 Val Loss 1.46006178855896
Trainable Parameters : 198660
Epoch 23 Train Acc 48.82352828979492% Val Acc 18.941177368164062% Train Loss 0.6329154372215271 Val Loss 1.4729355573654175
Trainable Parameters : 198660
Epoch 24 Train Acc 49.735294342041016% Val Acc 21.05882453918457% Train Loss 0.6283652782440186 Val Loss 1.4723197221755981
Trainable Parameters : 198660
Epoch 25 Train Acc 50.32352828979492% Val Acc 21.294116973876953% Train Loss 0.6255250573158264 Val Loss 1.4904124736785889
Trainable Parameters : 198660
Epoch 26 Train Acc 48.764705657958984% Val Acc 20.58823585510254% Train Loss 0.6223754286766052 Val Loss 1.4965544939041138
Trainable Parameters : 198660
Epoch 27 Train Acc 50.79411697387695% Val Acc 19.823530197143555% Train Loss 0.6167986392974854 Val Loss 1.508009672164917
Trainable Parameters : 198660
Epoch 28 Train Acc 50.0% Val Acc 20.794116973876953% Train Loss 0.6154539585113525 Val Loss 1.510875940322876
Trainable Parameters : 198660
Epoch 29 Train Acc 51.235294342041016% Val Acc 20.05882453918457% Train Loss 0.6116997003555298 Val Loss 1.5166404247283936
Trainable Parameters : 198660
Epoch 30 Train Acc 47.85293960571289% Val Acc 21.55882453918457% Train Loss 0.609946072101593 Val Loss 1.5330498218536377
Trainable Parameters : 198660
Epoch 31 Train Acc 50.14706039428711% Val Acc 22.794116973876953% Train Loss 0.6034641265869141 Val Loss 1.533198595046997
Trainable Parameters : 198660
Epoch 32 Train Acc 54.17647171020508% Val Acc 20.55882453918457% Train Loss 0.5944461822509766 Val Loss 1.5515141487121582
Trainable Parameters : 198660
Epoch 33 Train Acc 53.0% Val Acc 21.294116973876953% Train Loss 0.5956129431724548 Val Loss 1.5557529926300049
Trainable Parameters : 198660
Epoch 34 Train Acc 53.97058868408203% Val Acc 21.55882453918457% Train Loss 0.5920740365982056 Val Loss 1.564858317375183
Trainable Parameters : 198660
Epoch 35 Train Acc 51.14706039428711% Val Acc 21.794116973876953% Train Loss 0.5893182754516602 Val Loss 1.5742920637130737
Trainable Parameters : 198660
Epoch 36 Train Acc 53.17647171020508% Val Acc 21.0% Train Loss 0.5830584764480591 Val Loss 1.5882090330123901
Trainable Parameters : 198660
Epoch 37 Train Acc 50.764705657958984% Val Acc 21.735294342041016% Train Loss 0.5784902572631836 Val Loss 1.609074354171753
Trainable Parameters : 198660
Epoch 38 Train Acc 54.235294342041016% Val Acc 20.55882453918457% Train Loss 0.5748671889305115 Val Loss 1.6177551746368408
Trainable Parameters : 198660
Epoch 39 Train Acc 55.411766052246094% Val Acc 20.441177368164062% Train Loss 0.5677888989448547 Val Loss 1.6107823848724365
Trainable Parameters : 198660
Epoch 40 Train Acc 53.61764907836914% Val Acc 21.147058486938477% Train Loss 0.5715709924697876 Val Loss 1.6459323167800903
Trainable Parameters : 198660
Epoch 41 Train Acc 55.70588302612305% Val Acc 22.794116973876953% Train Loss 0.5753241777420044 Val Loss 1.6124502420425415
Trainable Parameters : 198660
Epoch 42 Train Acc 57.67647171020508% Val Acc 23.52941131591797% Train Loss 0.5530429482460022 Val Loss 1.6717561483383179
Trainable Parameters : 198660
Epoch 43 Train Acc 57.64706039428711% Val Acc 23.52941131591797% Train Loss 0.5525580048561096 Val Loss 1.635337471961975
Trainable Parameters : 198660
Epoch 44 Train Acc 54.64706039428711% Val Acc 24.0% Train Loss 0.5477948784828186 Val Loss 1.6577831506729126
Trainable Parameters : 198660
Epoch 45 Train Acc 56.79411697387695% Val Acc 23.97058868408203% Train Loss 0.5491873621940613 Val Loss 1.6547914743423462
Trainable Parameters : 198660
Epoch 46 Train Acc 59.11764907836914% Val Acc 22.08823585510254% Train Loss 0.5427846908569336 Val Loss 1.6738898754119873
Trainable Parameters : 198660
Epoch 47 Train Acc 57.02941131591797% Val Acc 22.264705657958984% Train Loss 0.5381900668144226 Val Loss 1.6746666431427002
Trainable Parameters : 198660
Epoch 48 Train Acc 58.32352828979492% Val Acc 22.617647171020508% Train Loss 0.5327324271202087 Val Loss 1.6752158403396606
Trainable Parameters : 198660
Epoch 49 Train Acc 58.588233947753906% Val Acc 21.55882453918457% Train Loss 0.5277289748191833 Val Loss 1.6756664514541626
Trainable Parameters : 198660
Epoch 50 Train Acc 59.05882263183594% Val Acc 22.47058868408203% Train Loss 0.5234323143959045 Val Loss 1.680103063583374
Trainable Parameters : 198660
Epoch 51 Train Acc 62.5% Val Acc 22.52941131591797% Train Loss 0.5159939527511597 Val Loss 1.6961239576339722
Trainable Parameters : 198660
Epoch 52 Train Acc 58.11764907836914% Val Acc 22.58823585510254% Train Loss 0.5220915079116821 Val Loss 1.7450391054153442
Trainable Parameters : 198660
Epoch 53 Train Acc 59.79411697387695% Val Acc 22.794116973876953% Train Loss 0.5147166848182678 Val Loss 1.715484619140625
Trainable Parameters : 198660
Epoch 54 Train Acc 62.0% Val Acc 22.58823585510254% Train Loss 0.5050370693206787 Val Loss 1.7175647020339966
Trainable Parameters : 198660
Epoch 55 Train Acc 62.20588302612305% Val Acc 22.147058486938477% Train Loss 0.496040016412735 Val Loss 1.7155616283416748
Trainable Parameters : 198660
Epoch 56 Train Acc 61.264705657958984% Val Acc 23.764705657958984% Train Loss 0.49925631284713745 Val Loss 1.7344093322753906
Trainable Parameters : 198660
Epoch 57 Train Acc 63.735294342041016% Val Acc 23.47058868408203% Train Loss 0.4829612672328949 Val Loss 1.7192339897155762
Trainable Parameters : 198660
Epoch 58 Train Acc 65.26470947265625% Val Acc 23.41176414489746% Train Loss 0.4777093231678009 Val Loss 1.7243365049362183
Trainable Parameters : 198660
Epoch 59 Train Acc 64.17646789550781% Val Acc 23.764705657958984% Train Loss 0.4736260771751404 Val Loss 1.7291823625564575
Trainable Parameters : 198660
Epoch 60 Train Acc 63.735294342041016% Val Acc 23.0% Train Loss 0.4670090675354004 Val Loss 1.7421715259552002
Trainable Parameters : 198660
Epoch 61 Train Acc 65.88235473632812% Val Acc 22.47058868408203% Train Loss 0.4607878625392914 Val Loss 1.760115623474121
Trainable Parameters : 198660
Epoch 62 Train Acc 65.23529815673828% Val Acc 23.235294342041016% Train Loss 0.463029682636261 Val Loss 1.7792531251907349
Trainable Parameters : 198660
Epoch 63 Train Acc 67.14705657958984% Val Acc 22.294116973876953% Train Loss 0.451913446187973 Val Loss 1.784852147102356
Trainable Parameters : 198660
Epoch 64 Train Acc 67.17646789550781% Val Acc 24.02941131591797% Train Loss 0.45180967450141907 Val Loss 1.7703402042388916
Trainable Parameters : 198660
Epoch 65 Train Acc 66.94117736816406% Val Acc 23.52941131591797% Train Loss 0.4425205588340759 Val Loss 1.7816731929779053
Trainable Parameters : 198660
Epoch 66 Train Acc 68.14705657958984% Val Acc 23.52941131591797% Train Loss 0.43330132961273193 Val Loss 1.797312617301941
Trainable Parameters : 198660
Epoch 67 Train Acc 69.0882339477539% Val Acc 22.764705657958984% Train Loss 0.4337737560272217 Val Loss 1.8169878721237183
Trainable Parameters : 198660
Epoch 68 Train Acc 68.11764526367188% Val Acc 21.55882453918457% Train Loss 0.43853920698165894 Val Loss 1.828305959701538
Trainable Parameters : 198660
Epoch 69 Train Acc 70.0882339477539% Val Acc 22.323530197143555% Train Loss 0.4196193814277649 Val Loss 1.8314838409423828
Trainable Parameters : 198660
Epoch 70 Train Acc 69.73529815673828% Val Acc 23.05882453918457% Train Loss 0.4145233929157257 Val Loss 1.8598958253860474
Trainable Parameters : 198660
Epoch 71 Train Acc 71.32353210449219% Val Acc 22.852941513061523% Train Loss 0.40923431515693665 Val Loss 1.8507533073425293
Trainable Parameters : 198660
Epoch 72 Train Acc 69.82353210449219% Val Acc 23.97058868408203% Train Loss 0.4151822328567505 Val Loss 1.867006540298462
Trainable Parameters : 198660
Epoch 73 Train Acc 73.29412078857422% Val Acc 24.52941131591797% Train Loss 0.39311742782592773 Val Loss 1.8457690477371216
Trainable Parameters : 198660
Epoch 74 Train Acc 73.76470947265625% Val Acc 23.294116973876953% Train Loss 0.3917858898639679 Val Loss 1.8831138610839844
Trainable Parameters : 198660
Epoch 75 Train Acc 70.82353210449219% Val Acc 23.264705657958984% Train Loss 0.3892788887023926 Val Loss 1.9004135131835938
Trainable Parameters : 198660
Epoch 76 Train Acc 73.29412078857422% Val Acc 22.764705657958984% Train Loss 0.3885485827922821 Val Loss 1.8954081535339355
Trainable Parameters : 198660
Epoch 77 Train Acc 74.47058868408203% Val Acc 24.5% Train Loss 0.38057050108909607 Val Loss 1.9030293226242065
Trainable Parameters : 198660
Epoch 78 Train Acc 74.55882263183594% Val Acc 23.794116973876953% Train Loss 0.36559346318244934 Val Loss 1.9154943227767944
Trainable Parameters : 198660
Epoch 79 Train Acc 76.47058868408203% Val Acc 23.05882453918457% Train Loss 0.36137041449546814 Val Loss 1.9840024709701538
Trainable Parameters : 198660
Epoch 80 Train Acc 74.52941131591797% Val Acc 23.55882453918457% Train Loss 0.3608720302581787 Val Loss 1.9689589738845825
Trainable Parameters : 198660
Epoch 81 Train Acc 78.64705657958984% Val Acc 21.55882453918457% Train Loss 0.34589603543281555 Val Loss 1.9817403554916382
Trainable Parameters : 198660
Epoch 82 Train Acc 77.67646789550781% Val Acc 26.205883026123047% Train Loss 0.3491145968437195 Val Loss 1.948964238166809
Trainable Parameters : 198660
Epoch 83 Train Acc 77.5882339477539% Val Acc 22.323530197143555% Train Loss 0.3443073034286499 Val Loss 1.9975029230117798
Trainable Parameters : 198660
Epoch 84 Train Acc 77.64705657958984% Val Acc 23.735294342041016% Train Loss 0.3372595012187958 Val Loss 2.013963222503662
Trainable Parameters : 198660
Epoch 85 Train Acc 76.9117660522461% Val Acc 22.852941513061523% Train Loss 0.3283066749572754 Val Loss 2.079132080078125
Trainable Parameters : 198660
Epoch 86 Train Acc 77.26470947265625% Val Acc 20.382352828979492% Train Loss 0.3233327567577362 Val Loss 2.068408250808716
Trainable Parameters : 198660
Epoch 87 Train Acc 79.64705657958984% Val Acc 20.823530197143555% Train Loss 0.3229812681674957 Val Loss 2.067781448364258
Trainable Parameters : 198660
Epoch 88 Train Acc 79.85294342041016% Val Acc 21.58823585510254% Train Loss 0.312971293926239 Val Loss 2.1026995182037354
Trainable Parameters : 198660
Epoch 89 Train Acc 80.26470947265625% Val Acc 23.352941513061523% Train Loss 0.3033795654773712 Val Loss 2.0373599529266357
Trainable Parameters : 198660
Epoch 90 Train Acc 79.55882263183594% Val Acc 20.55882453918457% Train Loss 0.29548367857933044 Val Loss 2.160627841949463
Trainable Parameters : 198660
Epoch 91 Train Acc 79.70587921142578% Val Acc 24.5% Train Loss 0.29298365116119385 Val Loss 2.0972707271575928
Trainable Parameters : 198660
Epoch 92 Train Acc 78.70587921142578% Val Acc 24.97058868408203% Train Loss 0.2885096073150635 Val Loss 2.1094231605529785
Trainable Parameters : 198660
Epoch 93 Train Acc 81.82353210449219% Val Acc 23.02941131591797% Train Loss 0.2782195806503296 Val Loss 2.1382176876068115
Trainable Parameters : 198660
Epoch 94 Train Acc 80.11764526367188% Val Acc 22.0% Train Loss 0.2803308963775635 Val Loss 2.1418251991271973
Trainable Parameters : 198660
Epoch 95 Train Acc 85.0882339477539% Val Acc 23.52941131591797% Train Loss 0.2701544165611267 Val Loss 2.225861072540283
Trainable Parameters : 198660
Epoch 96 Train Acc 82.5882339477539% Val Acc 24.323530197143555% Train Loss 0.26963919401168823 Val Loss 2.233355760574341
Trainable Parameters : 198660
Epoch 97 Train Acc 83.85294342041016% Val Acc 24.47058868408203% Train Loss 0.26028576493263245 Val Loss 2.1970293521881104
Trainable Parameters : 198660
Epoch 98 Train Acc 84.0% Val Acc 22.294116973876953% Train Loss 0.2539137601852417 Val Loss 2.254533052444458
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug/config.json
Model weights saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-extract-debug/pytorch_model.bin
Epoch 99 Train Acc 84.47058868408203% Val Acc 24.55882453918457% Train Loss 0.25063520669937134 Val Loss 2.4189507961273193

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.25125628 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]
 [0.24623116 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40       100
           1       0.00      0.00      0.00       100
           2       0.00      0.00      0.00        98
           3       0.00      0.00      0.00       100

    accuracy                           0.25       398
   macro avg       0.06      0.25      0.10       398
weighted avg       0.06      0.25      0.10       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 13/10/2022 20:05:08
