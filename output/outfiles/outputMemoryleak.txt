Tue Oct 11 18:59:11 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_basic.py
Started: 11/10/2022 18:59:20

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-initialtest
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_100f_devdata
train_filename: test_u_100f
evaluation_filename: train_u_50f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 3
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_100f.csv
--> data_test_fp: data/train_u_50f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 9.4734e-01,  5.2855e-01,  6.4928e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.5884e-04, -2.5884e-04, -2.5884e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.9456e-02, -7.3207e-02, -7.1957e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 3.9612e-02,  8.1740e-02, -1.4300e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.6224e+00,  2.1345e+00,  2.2826e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.5046e-03,  1.0439e-02,  1.4693e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 1, 2, 0, 1, 0, 1, 2, 0, 0, 1])}
Training DataCustom Files: 398
Training Data Files: 34
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 0.0902,  0.1379,  0.1532,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6165,  1.6159,  3.0226,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1817, -0.1589, -0.1653,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0383, -0.0074,  0.0863,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3711,  0.1469, -0.1017,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.4178,  1.3911,  1.1996,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 3, 3, 1, 0, 3, 0, 0, 0, 1, 3])}
Test CustomData Files: 195
Test Data Files: 17
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Tesla V100-SXM2-32GB
Memory Usage:
Allocated: 0.4 GB
Cached:    0.4 GB
/home/z5208494/.local/lib/python3.8/site-packages/torch/cuda/memory.py:384: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
  warnings.warn(
Tesla V100-SXM2-32GB
Memory Usage:
Allocated: 0.4 GB
Cached:    28.7 GB
Epoch 0 Train Acc 19.617647171020508% Val Acc 31.0% Train Loss 0.7004960775375366 Val Loss 1.381844401359558
Trainable Parameters : 198660
Tesla V100-SXM2-32GB
Memory Usage:
Allocated: 0.4 GB
Cached:    28.7 GB
Tesla V100-SXM2-32GB
Memory Usage:
Allocated: 0.4 GB
Cached:    28.7 GB
Epoch 1 Train Acc 20.05882453918457% Val Acc 32.235294342041016% Train Loss 0.6980504393577576 Val Loss 1.383486270904541
Trainable Parameters : 198660
Tesla V100-SXM2-32GB
Memory Usage:
Allocated: 0.4 GB
Cached:    28.7 GB
Configuration saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest/config.json
Model weights saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-initialtest/pytorch_model.bin
Tesla V100-SXM2-32GB
Memory Usage:
Allocated: 0.4 GB
Cached:    28.7 GB
Epoch 2 Train Acc 20.647058486938477% Val Acc 30.941177368164062% Train Loss 0.6973825693130493 Val Loss 1.3828496932983398

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.24615385 0.         0.         0.        ]
 [0.25641026 0.         0.         0.        ]
 [0.25128205 0.         0.         0.        ]
 [0.24615385 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40        48
           1       0.00      0.00      0.00        50
           2       0.00      0.00      0.00        49
           3       0.00      0.00      0.00        48

    accuracy                           0.25       195
   macro avg       0.06      0.25      0.10       195
weighted avg       0.06      0.25      0.10       195


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 11/10/2022 19:10:58
