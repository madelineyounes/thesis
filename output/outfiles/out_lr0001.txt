Wed Oct 12 16:31:05 AEDT 2022
------------------------------------------------------------------------
                         run_4s.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_lr0001.py
Started: 12/10/2022 16:31:12

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-lr00001
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 0.0001
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-lr00001
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-lr00001_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 4 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.9484, -1.1058, -1.3741,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2275, -0.8307, -1.0909,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6141, -0.4792, -0.5620,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0579, -0.0262,  0.3486,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0385,  0.1966,  0.2054,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3052, -0.7174, -1.2678,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 3, 2, 2, 2, 2, 2, 1, 3, 3, 1, 2])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.codevectors', 'project_q.weight', 'project_hid.bias', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_q.bias', 'quantizer.weight_proj.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.bias', 'classifier.weight', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.2627, -0.3838, -0.3144,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0337, -0.3342, -0.5714,  ...,  0.0000,  0.0000,  0.0000],
        [-0.4083, -0.3844, -0.3634,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0780,  0.0354, -0.0032,  ...,  0.0000,  0.0000,  0.0000],
        [-1.1076, -1.1066, -1.5257,  ...,  0.0000,  0.0000,  0.0000],
        [-1.6528, -1.7905, -2.0316,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 3, 0, 0, 1, 1, 0, 0, 2, 0, 1])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Traceback (most recent call last):
  File "run_lr0001.py", line 707, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_lr0001.py", line 546, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_lr0001.py", line 573, in _train
    loss.backward()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py", line 146, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 5.49 GiB (GPU 0; 31.75 GiB total capacity; 24.77 GiB already allocated; 2.84 GiB free; 27.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Wed Oct 12 16:36:54 AEDT 2022
------------------------------------------------------------------------
                         run_4s.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_lr0001.py
Started: 12/10/2022 16:36:59

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-lr00001
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 0.0001
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-lr00001
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-lr00001_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 4 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.3140,  0.2479,  0.4141,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1785,  0.1004,  0.0447,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.7420,  1.6975,  1.6609,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1387, -0.1312, -0.0969,  ...,  0.0000,  0.0000,  0.0000],
        [ 3.3225,  3.9283,  3.4831,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2420,  0.4645,  0.6968,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 0, 2, 3, 0, 0, 2, 3, 3, 0, 3, 0])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.codevectors', 'project_q.bias', 'quantizer.weight_proj.weight', 'quantizer.weight_proj.bias', 'project_hid.bias', 'project_hid.weight', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'projector.bias', 'classifier.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.0390, -0.0494, -0.0677,  ...,  1.1650,  0.3819, -0.4024],
        [-0.6140, -0.5101, -0.4103,  ...,  0.0000,  0.0000,  0.0000],
        [-1.1930, -1.0053, -0.5939,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.2226, -0.3799, -0.5945,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1474, -0.0626,  0.1138,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3675, -0.5567, -1.0380,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 3, 2, 1, 3, 3, 2, 3, 2, 1, 1])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 24.542682647705078% Val Acc 25.251497268676758% Train Loss 0.6953743100166321 Val Loss 1.3888310194015503
Trainable Parameters : 198660
Epoch 1 Train Acc 25.189023971557617% Val Acc 26.02994155883789% Train Loss 0.69370037317276 Val Loss 1.3872543573379517
Trainable Parameters : 198660
Epoch 2 Train Acc 29.701217651367188% Val Acc 24.131736755371094% Train Loss 0.6908268332481384 Val Loss 1.3862344026565552
Trainable Parameters : 198660
Epoch 3 Train Acc 30.44512176513672% Val Acc 23.491018295288086% Train Loss 0.6881551742553711 Val Loss 1.3862473964691162
Trainable Parameters : 198660
Epoch 4 Train Acc 34.46950912475586% Val Acc 25.766468048095703% Train Loss 0.6846218109130859 Val Loss 1.3847129344940186
Trainable Parameters : 198660
Epoch 5 Train Acc 34.98170471191406% Val Acc 27.179641723632812% Train Loss 0.6809008121490479 Val Loss 1.3866808414459229
Trainable Parameters : 198660
Epoch 6 Train Acc 35.04877853393555% Val Acc 23.479042053222656% Train Loss 0.6768733859062195 Val Loss 1.3952420949935913
Trainable Parameters : 198660
Epoch 7 Train Acc 36.628047943115234% Val Acc 24.24551010131836% Train Loss 0.6717262268066406 Val Loss 1.3971905708312988
Trainable Parameters : 198660
Epoch 8 Train Acc 36.84756088256836% Val Acc 23.910181045532227% Train Loss 0.6688727140426636 Val Loss 1.4028362035751343
Trainable Parameters : 198660
Epoch 9 Train Acc 37.16463088989258% Val Acc 23.60479164123535% Train Loss 0.6633912920951843 Val Loss 1.4162297248840332
Trainable Parameters : 198660
Epoch 10 Train Acc 37.189022064208984% Val Acc 23.113773345947266% Train Loss 0.6579301357269287 Val Loss 1.4397802352905273
Trainable Parameters : 198660
Epoch 11 Train Acc 38.42073059082031% Val Acc 24.371257781982422% Train Loss 0.6527962684631348 Val Loss 1.4397934675216675
Trainable Parameters : 198660
