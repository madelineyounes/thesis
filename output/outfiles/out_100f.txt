Mon Oct 10 03:01:04 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_100f.py
Started: 10/10/2022 03:01:08

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-100-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_100f_devdata
train_filename: test_u_100f
evaluation_filename: train_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_100f.csv
--> data_test_fp: data/train_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_100f_devdata_local/wav2vec-ADI17-100-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_100f_devdata_local/wav2vec-ADI17-100-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.2043,  1.5767,  1.5630,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.8563,  0.1170, -0.2756,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0181,  0.0232,  0.0181,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.1856,  0.1660,  0.1446,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0944,  0.0706,  0.0488,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0067,  0.3812,  0.4503,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 1, 0, 3, 3, 1, 2, 1, 3, 0, 2])}
Training DataCustom Files: 398
Training Data Files: 34
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_hid.weight', 'project_q.weight', 'quantizer.codevectors', 'project_q.bias', 'quantizer.weight_proj.bias', 'project_hid.bias', 'quantizer.weight_proj.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.weight', 'projector.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 0.2053, -0.1531, -0.3971,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.7227,  0.9496,  1.1298,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0080,  0.0080,  0.0080,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0435,  0.0412,  0.0645,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1674, -0.0682, -0.0856,  ...,  0.0000,  0.0000,  0.0000],
        [ 2.3649,  2.5257,  2.4876,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 0, 2, 0, 0, 2, 2, 3, 2, 0, 1])}
Test CustomData Files: 398
Test Data Files: 34
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 22.52941131591797% Val Acc 32.05882263183594% Train Loss 0.6991620063781738 Val Loss 1.3782832622528076
Trainable Parameters : 198660
Epoch 1 Train Acc 21.852941513061523% Val Acc 29.852941513061523% Train Loss 0.6983426809310913 Val Loss 1.3848347663879395
Trainable Parameters : 198660
Epoch 2 Train Acc 20.617647171020508% Val Acc 31.176469802856445% Train Loss 0.6989508271217346 Val Loss 1.3820112943649292
Trainable Parameters : 198660
Epoch 3 Train Acc 20.05882453918457% Val Acc 31.352941513061523% Train Loss 0.6977789402008057 Val Loss 1.3797358274459839
Trainable Parameters : 198660
Epoch 4 Train Acc 20.823530197143555% Val Acc 30.235294342041016% Train Loss 0.6952949166297913 Val Loss 1.3830177783966064
Trainable Parameters : 198660
Epoch 5 Train Acc 20.852941513061523% Val Acc 30.117647171020508% Train Loss 0.6959790587425232 Val Loss 1.3829118013381958
Trainable Parameters : 198660
Epoch 6 Train Acc 21.882352828979492% Val Acc 27.647058486938477% Train Loss 0.6925852298736572 Val Loss 1.3843677043914795
Trainable Parameters : 198660
Epoch 7 Train Acc 23.52941131591797% Val Acc 23.294116973876953% Train Loss 0.6917508244514465 Val Loss 1.3845676183700562
Trainable Parameters : 198660
Epoch 8 Train Acc 30.323530197143555% Val Acc 23.58823585510254% Train Loss 0.6877410411834717 Val Loss 1.386076807975769
Trainable Parameters : 198660
Epoch 9 Train Acc 27.47058868408203% Val Acc 24.176469802856445% Train Loss 0.6883013248443604 Val Loss 1.387476921081543
Trainable Parameters : 198660
Epoch 10 Train Acc 30.823530197143555% Val Acc 23.764705657958984% Train Loss 0.685643196105957 Val Loss 1.3889247179031372
Trainable Parameters : 198660
Epoch 11 Train Acc 37.97058868408203% Val Acc 21.823530197143555% Train Loss 0.6837294101715088 Val Loss 1.3933935165405273
Trainable Parameters : 198660
Epoch 12 Train Acc 36.05882263183594% Val Acc 24.0% Train Loss 0.6829121112823486 Val Loss 1.3971997499465942
Trainable Parameters : 198660
Epoch 13 Train Acc 37.764705657958984% Val Acc 21.5% Train Loss 0.6811335682868958 Val Loss 1.398744821548462
Trainable Parameters : 198660
Epoch 14 Train Acc 36.52941131591797% Val Acc 24.5% Train Loss 0.6818661093711853 Val Loss 1.4023786783218384
Trainable Parameters : 198660
Epoch 15 Train Acc 38.911766052246094% Val Acc 24.0% Train Loss 0.6748690009117126 Val Loss 1.4102303981781006
Trainable Parameters : 198660
Epoch 16 Train Acc 38.02941131591797% Val Acc 25.323530197143555% Train Loss 0.6765438318252563 Val Loss 1.4101992845535278
Trainable Parameters : 198660
Epoch 17 Train Acc 40.0% Val Acc 24.05882453918457% Train Loss 0.6720545291900635 Val Loss 1.4160979986190796
Trainable Parameters : 198660
Epoch 18 Train Acc 38.97058868408203% Val Acc 26.264705657958984% Train Loss 0.673242449760437 Val Loss 1.4156242609024048
Trainable Parameters : 198660
Epoch 19 Train Acc 40.94117736816406% Val Acc 26.735294342041016% Train Loss 0.6694943904876709 Val Loss 1.411660075187683
Trainable Parameters : 198660
Epoch 20 Train Acc 41.97058868408203% Val Acc 24.735294342041016% Train Loss 0.6684937477111816 Val Loss 1.4243935346603394
Trainable Parameters : 198660
Epoch 21 Train Acc 42.17647171020508% Val Acc 25.264705657958984% Train Loss 0.665162980556488 Val Loss 1.4278408288955688
Trainable Parameters : 198660
Epoch 22 Train Acc 44.382354736328125% Val Acc 21.117647171020508% Train Loss 0.6638634204864502 Val Loss 1.4353851079940796
Trainable Parameters : 198660
Epoch 23 Train Acc 40.29411697387695% Val Acc 19.08823585510254% Train Loss 0.6645396947860718 Val Loss 1.439763069152832
Trainable Parameters : 198660
Epoch 24 Train Acc 42.70588302612305% Val Acc 18.147058486938477% Train Loss 0.6605939269065857 Val Loss 1.4403445720672607
Trainable Parameters : 198660
Epoch 25 Train Acc 44.32352828979492% Val Acc 19.647058486938477% Train Loss 0.6565253734588623 Val Loss 1.4487162828445435
Trainable Parameters : 198660
Epoch 26 Train Acc 43.911766052246094% Val Acc 18.617647171020508% Train Loss 0.6543448567390442 Val Loss 1.4533683061599731
Trainable Parameters : 198660
Epoch 27 Train Acc 45.79411697387695% Val Acc 19.05882453918457% Train Loss 0.6546264886856079 Val Loss 1.4554835557937622
Trainable Parameters : 198660
Epoch 28 Train Acc 48.52941131591797% Val Acc 19.617647171020508% Train Loss 0.6456368565559387 Val Loss 1.4624086618423462
Trainable Parameters : 198660
Epoch 29 Train Acc 45.05882263183594% Val Acc 17.91176414489746% Train Loss 0.6460157036781311 Val Loss 1.4712055921554565
Trainable Parameters : 198660
Epoch 30 Train Acc 46.29411697387695% Val Acc 17.91176414489746% Train Loss 0.646729052066803 Val Loss 1.4839873313903809
Trainable Parameters : 198660
Epoch 31 Train Acc 46.35293960571289% Val Acc 17.352941513061523% Train Loss 0.6395782232284546 Val Loss 1.488438367843628
Trainable Parameters : 198660
Epoch 32 Train Acc 46.61764907836914% Val Acc 17.41176414489746% Train Loss 0.635644793510437 Val Loss 1.4906115531921387
Trainable Parameters : 198660
Epoch 33 Train Acc 46.32352828979492% Val Acc 18.617647171020508% Train Loss 0.6426240801811218 Val Loss 1.4890567064285278
Trainable Parameters : 198660
Epoch 34 Train Acc 47.0% Val Acc 17.08823585510254% Train Loss 0.6353121399879456 Val Loss 1.4977489709854126
Trainable Parameters : 198660
Epoch 35 Train Acc 44.02941131591797% Val Acc 17.617647171020508% Train Loss 0.6360374093055725 Val Loss 1.5015650987625122
Trainable Parameters : 198660
Epoch 36 Train Acc 46.79411697387695% Val Acc 17.676469802856445% Train Loss 0.6284468770027161 Val Loss 1.5145883560180664
Trainable Parameters : 198660
Epoch 37 Train Acc 46.264705657958984% Val Acc 18.147058486938477% Train Loss 0.6326660513877869 Val Loss 1.5085248947143555
Trainable Parameters : 198660
Epoch 38 Train Acc 48.588233947753906% Val Acc 17.617647171020508% Train Loss 0.62094646692276 Val Loss 1.5180038213729858
Trainable Parameters : 198660
Epoch 39 Train Acc 50.44117736816406% Val Acc 18.147058486938477% Train Loss 0.6191156506538391 Val Loss 1.532397985458374
Trainable Parameters : 198660
Epoch 40 Train Acc 48.764705657958984% Val Acc 18.323530197143555% Train Loss 0.6207210421562195 Val Loss 1.5503116846084595
Trainable Parameters : 198660
Epoch 41 Train Acc 49.20588302612305% Val Acc 19.323530197143555% Train Loss 0.6173328757286072 Val Loss 1.5293062925338745
Trainable Parameters : 198660
Epoch 42 Train Acc 46.35293960571289% Val Acc 19.647058486938477% Train Loss 0.6168319582939148 Val Loss 1.5494253635406494
Trainable Parameters : 198660
Epoch 43 Train Acc 53.44117736816406% Val Acc 19.05882453918457% Train Loss 0.5996469259262085 Val Loss 1.5415308475494385
Trainable Parameters : 198660
Epoch 44 Train Acc 51.97058868408203% Val Acc 18.47058868408203% Train Loss 0.60772305727005 Val Loss 1.553774118423462
Trainable Parameters : 198660
Epoch 45 Train Acc 51.94117736816406% Val Acc 17.882352828979492% Train Loss 0.605322003364563 Val Loss 1.5788521766662598
Trainable Parameters : 198660
Epoch 46 Train Acc 50.764705657958984% Val Acc 17.58823585510254% Train Loss 0.5999935865402222 Val Loss 1.5815272331237793
Trainable Parameters : 198660
Epoch 47 Train Acc 51.70588302612305% Val Acc 18.823530197143555% Train Loss 0.5963873267173767 Val Loss 1.5840449333190918
Trainable Parameters : 198660
Epoch 48 Train Acc 52.764705657958984% Val Acc 17.852941513061523% Train Loss 0.5887241363525391 Val Loss 1.6077440977096558
Trainable Parameters : 198660
Epoch 49 Train Acc 50.911766052246094% Val Acc 19.117647171020508% Train Loss 0.5907442569732666 Val Loss 1.581984043121338
Trainable Parameters : 198660
Epoch 50 Train Acc 52.411766052246094% Val Acc 18.41176414489746% Train Loss 0.5915617346763611 Val Loss 1.6209354400634766
Trainable Parameters : 198660
Epoch 51 Train Acc 51.94117736816406% Val Acc 17.676469802856445% Train Loss 0.598976194858551 Val Loss 1.6048799753189087
Trainable Parameters : 198660
Epoch 52 Train Acc 50.02941131591797% Val Acc 18.382352828979492% Train Loss 0.5873798727989197 Val Loss 1.6065208911895752
Trainable Parameters : 198660
Epoch 53 Train Acc 52.94117736816406% Val Acc 18.617647171020508% Train Loss 0.5793480277061462 Val Loss 1.6326889991760254
Trainable Parameters : 198660
Epoch 54 Train Acc 51.735294342041016% Val Acc 18.91176414489746% Train Loss 0.575897753238678 Val Loss 1.6675978899002075
Trainable Parameters : 198660
Epoch 55 Train Acc 55.64706039428711% Val Acc 19.294116973876953% Train Loss 0.5620204210281372 Val Loss 1.6751128435134888
Trainable Parameters : 198660
Epoch 56 Train Acc 52.17647171020508% Val Acc 18.676469802856445% Train Loss 0.5679306983947754 Val Loss 1.6885114908218384
Trainable Parameters : 198660
Epoch 57 Train Acc 53.97058868408203% Val Acc 18.823530197143555% Train Loss 0.5715883374214172 Val Loss 1.689140796661377
Trainable Parameters : 198660
Epoch 58 Train Acc 57.64706039428711% Val Acc 20.08823585510254% Train Loss 0.5586714744567871 Val Loss 1.7295682430267334
Trainable Parameters : 198660
Epoch 59 Train Acc 57.82352828979492% Val Acc 19.647058486938477% Train Loss 0.551852285861969 Val Loss 1.7406752109527588
Trainable Parameters : 198660
Epoch 60 Train Acc 55.882354736328125% Val Acc 18.117647171020508% Train Loss 0.5477092266082764 Val Loss 1.738160252571106
Trainable Parameters : 198660
Epoch 61 Train Acc 51.17647171020508% Val Acc 19.823530197143555% Train Loss 0.5513463616371155 Val Loss 1.757034420967102
Trainable Parameters : 198660
Epoch 62 Train Acc 55.11764907836914% Val Acc 20.617647171020508% Train Loss 0.5479033589363098 Val Loss 1.7791721820831299
Trainable Parameters : 198660
Epoch 63 Train Acc 55.20588302612305% Val Acc 20.852941513061523% Train Loss 0.5447377562522888 Val Loss 1.7756898403167725
Trainable Parameters : 198660
Epoch 64 Train Acc 54.11764907836914% Val Acc 20.617647171020508% Train Loss 0.5418713092803955 Val Loss 1.7607030868530273
Trainable Parameters : 198660
Epoch 65 Train Acc 58.11764907836914% Val Acc 19.823530197143555% Train Loss 0.5293635725975037 Val Loss 1.8245813846588135
Trainable Parameters : 198660
Epoch 66 Train Acc 56.882354736328125% Val Acc 20.47058868408203% Train Loss 0.5391368865966797 Val Loss 1.81099271774292
Trainable Parameters : 198660
Epoch 67 Train Acc 55.70588302612305% Val Acc 19.58823585510254% Train Loss 0.5317822694778442 Val Loss 1.78778874874115
Trainable Parameters : 198660
Epoch 68 Train Acc 55.911766052246094% Val Acc 20.323530197143555% Train Loss 0.5365614295005798 Val Loss 1.7981058359146118
Trainable Parameters : 198660
Epoch 69 Train Acc 59.05882263183594% Val Acc 20.117647171020508% Train Loss 0.5276477336883545 Val Loss 1.8243199586868286
Trainable Parameters : 198660
Epoch 70 Train Acc 60.82352828979492% Val Acc 19.705883026123047% Train Loss 0.5267103314399719 Val Loss 1.8773270845413208
Trainable Parameters : 198660
Epoch 71 Train Acc 60.882354736328125% Val Acc 20.52941131591797% Train Loss 0.5130665898323059 Val Loss 1.874077558517456
Trainable Parameters : 198660
Epoch 72 Train Acc 58.14706039428711% Val Acc 20.176469802856445% Train Loss 0.5108250379562378 Val Loss 1.9506993293762207
Trainable Parameters : 198660
Epoch 73 Train Acc 58.82352828979492% Val Acc 21.323530197143555% Train Loss 0.5109540224075317 Val Loss 1.9318598508834839
Trainable Parameters : 198660
Epoch 74 Train Acc 62.02941131591797% Val Acc 19.882352828979492% Train Loss 0.5010622143745422 Val Loss 1.9576667547225952
Trainable Parameters : 198660
Epoch 75 Train Acc 60.264705657958984% Val Acc 20.58823585510254% Train Loss 0.5028709769248962 Val Loss 1.9630200862884521
Trainable Parameters : 198660
Epoch 76 Train Acc 58.85293960571289% Val Acc 20.52941131591797% Train Loss 0.5078526735305786 Val Loss 1.939458966255188
Trainable Parameters : 198660
Epoch 77 Train Acc 59.61764907836914% Val Acc 20.382352828979492% Train Loss 0.5025879740715027 Val Loss 2.0257575511932373
Trainable Parameters : 198660
Epoch 78 Train Acc 62.05882263183594% Val Acc 21.294116973876953% Train Loss 0.5005577802658081 Val Loss 1.969451665878296
Trainable Parameters : 198660
Epoch 79 Train Acc 60.55882263183594% Val Acc 22.617647171020508% Train Loss 0.49347808957099915 Val Loss 2.0694997310638428
Trainable Parameters : 198660
Epoch 80 Train Acc 61.52941131591797% Val Acc 21.382352828979492% Train Loss 0.5005899667739868 Val Loss 2.0731201171875
Trainable Parameters : 198660
Epoch 81 Train Acc 62.02941131591797% Val Acc 21.323530197143555% Train Loss 0.47892728447914124 Val Loss 2.092205047607422
Trainable Parameters : 198660
Epoch 82 Train Acc 60.0% Val Acc 24.55882453918457% Train Loss 0.4829106628894806 Val Loss 2.0794472694396973
Trainable Parameters : 198660
Epoch 83 Train Acc 63.764705657958984% Val Acc 20.55882453918457% Train Loss 0.4889657199382782 Val Loss 2.050511598587036
Trainable Parameters : 198660
Epoch 84 Train Acc 64.20587921142578% Val Acc 22.764705657958984% Train Loss 0.47770956158638 Val Loss 2.149266481399536
Trainable Parameters : 198660
Epoch 85 Train Acc 63.94117736816406% Val Acc 20.352941513061523% Train Loss 0.47395700216293335 Val Loss 2.13521409034729
Trainable Parameters : 198660
Epoch 86 Train Acc 64.88235473632812% Val Acc 20.323530197143555% Train Loss 0.46924978494644165 Val Loss 2.177800178527832
Trainable Parameters : 198660
Epoch 87 Train Acc 60.32352828979492% Val Acc 23.08823585510254% Train Loss 0.47833481431007385 Val Loss 2.1276488304138184
Trainable Parameters : 198660
Epoch 88 Train Acc 64.17646789550781% Val Acc 22.55882453918457% Train Loss 0.4533517062664032 Val Loss 2.3450565338134766
Trainable Parameters : 198660
Epoch 89 Train Acc 62.79411697387695% Val Acc 23.735294342041016% Train Loss 0.46189242601394653 Val Loss 2.262868881225586
Trainable Parameters : 198660
Epoch 90 Train Acc 65.64705657958984% Val Acc 21.58823585510254% Train Loss 0.4473894536495209 Val Loss 2.258237361907959
Trainable Parameters : 198660
Epoch 91 Train Acc 63.79411697387695% Val Acc 23.5% Train Loss 0.442605584859848 Val Loss 2.277287721633911
Trainable Parameters : 198660
Epoch 92 Train Acc 67.14705657958984% Val Acc 22.882352828979492% Train Loss 0.4491886794567108 Val Loss 2.272043228149414
Trainable Parameters : 198660
Epoch 93 Train Acc 65.97058868408203% Val Acc 22.0% Train Loss 0.4355664849281311 Val Loss 2.310499429702759
Trainable Parameters : 198660
Epoch 94 Train Acc 63.52941131591797% Val Acc 23.05882453918457% Train Loss 0.4633176624774933 Val Loss 2.2496304512023926
Trainable Parameters : 198660
Epoch 95 Train Acc 66.4117660522461% Val Acc 23.323530197143555% Train Loss 0.4512128233909607 Val Loss 2.4583446979522705
Trainable Parameters : 198660
Epoch 96 Train Acc 68.5% Val Acc 23.52941131591797% Train Loss 0.4407910406589508 Val Loss 2.3242156505584717
Trainable Parameters : 198660
Epoch 97 Train Acc 65.85294342041016% Val Acc 21.91176414489746% Train Loss 0.43569377064704895 Val Loss 2.3559746742248535
Trainable Parameters : 198660
Epoch 98 Train Acc 65.70587921142578% Val Acc 21.235294342041016% Train Loss 0.4360053539276123 Val Loss 2.341581106185913
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-100-files/config.json
Model weights saved in ../output/umbrella_100f_devdata_local/wav2vec-ADI17-100-files/pytorch_model.bin
Epoch 99 Train Acc 66.94117736816406% Val Acc 20.823530197143555% Train Loss 0.4359022080898285 Val Loss 2.5253753662109375

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.25125628 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]
 [0.24623116 0.         0.         0.        ]
 [0.25125628 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40       100
           1       0.00      0.00      0.00       100
           2       0.00      0.00      0.00        98
           3       0.00      0.00      0.00       100

    accuracy                           0.25       398
   macro avg       0.06      0.25      0.10       398
weighted avg       0.06      0.25      0.10       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 10/10/2022 05:57:52
