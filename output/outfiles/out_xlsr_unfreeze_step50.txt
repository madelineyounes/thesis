Sat Nov 5 18:49:59 AEDT 2022
2022-11-05 18:50:01.804466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-05 18:50:02.223355: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-05 18:50:02.379038: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-05 18:50:03.893490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-05 18:50:03.895732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-05 18:50:03.895741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_unfreezestep50.py
Started: 05/11/2022 18:50:15

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-araic-unfreeze-step50
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 50
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step50
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step50_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.1436,  0.1665,  0.2106,  ...,  0.6395,  0.6588,  0.6846],
        [-0.3399, -0.2992, -0.2528,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0203,  0.6096,  0.1190,  ...,  0.3064,  0.4433,  0.5910],
        ...,
        [ 0.6666,  0.6227,  0.5657,  ...,  0.0000,  0.0000,  0.0000],
        [-1.5236, -1.2011,  0.2556,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3023, -0.2546, -0.2586,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 0, 3, 3, 3, 0, 3, 1, 0, 3, 0, 0, 3, 3, 3, 1, 3, 2, 3, 0, 0, 2, 3,
        3, 2, 0, 0, 3, 1, 2, 1, 3, 2, 3, 2, 3, 0, 2, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-0.9666, -0.8888, -0.8663,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1866, -0.2453, -0.2470,  ...,  0.1692,  0.1082, -0.0073],
        [ 0.5748,  0.6773,  0.5441,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.3766, -0.3857, -0.3947,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0763, -0.0827, -0.0816,  ..., -1.2423, -1.2498, -1.2029],
        [ 0.5306,  0.2476,  0.3834,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 3, 2, 0, 1, 0, 3, 1, 1, 3, 0, 2, 2, 0, 1, 3, 2, 0, 1, 2, 1, 1, 1, 1,
        2, 0, 3, 3, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 3, 1])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.weight', 'classifier.weight', 'classifier.bias', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.9518, -1.2243, -1.4265,  ...,  0.0000,  0.0000,  0.0000],
        [-2.2727, -2.8250, -3.4539,  ...,  0.0000,  0.0000,  0.0000],
        [-2.9606, -3.0739, -2.6681,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0897,  0.1176,  0.1415,  ...,  0.5721,  0.6490,  0.4760],
        [ 0.2601,  0.8723,  1.0315,  ..., -0.6052, -0.5835, -0.0195],
        [-1.1076, -1.1066, -1.5257,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 3, 1, 0, 3, 2, 1, 0, 0, 2, 3, 1, 1, 3, 0, 1, 0, 3, 2, 1, 1, 1, 1,
        0, 0, 3, 3, 1, 3, 3, 2, 2, 1, 1, 1, 1, 3, 3, 0])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 0 Train Acc 36.83650207519531% Val Acc 25.5% Train Loss 0.6666994690895081 Val Loss 1.439935326576233
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 1 Train Acc 46.338401794433594% Val Acc 33.0% Train Loss 0.6025509834289551 Val Loss 1.4693621397018433
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 2 Train Acc 58.20912551879883% Val Acc 51.400001525878906% Train Loss 0.509811520576477 Val Loss 1.1623330116271973
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 3 Train Acc 71.08744812011719% Val Acc 56.900001525878906% Train Loss 0.3807500898838043 Val Loss 1.1607264280319214
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 4 Train Acc 78.22053527832031% Val Acc 62.70000076293945% Train Loss 0.29518336057662964 Val Loss 1.1264482736587524
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 5 Train Acc 83.55133056640625% Val Acc 71.0% Train Loss 0.22682902216911316 Val Loss 0.8516530394554138
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 6 Train Acc 87.22813415527344% Val Acc 72.0% Train Loss 0.1802043616771698 Val Loss 0.9422345161437988
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 7 Train Acc 89.94296264648438% Val Acc 72.0% Train Loss 0.14020080864429474 Val Loss 1.02073335647583
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 8 Train Acc 92.47148132324219% Val Acc 71.9000015258789% Train Loss 0.10958030819892883 Val Loss 0.9904466867446899
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 9 Train Acc 93.15969848632812% Val Acc 73.80000305175781% Train Loss 0.09819716215133667 Val Loss 0.9631056189537048
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 10 Train Acc 94.25855255126953% Val Acc 79.5% Train Loss 0.08219370245933533 Val Loss 0.892359733581543
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 11 Train Acc 94.4144515991211% Val Acc 60.29999923706055% Train Loss 0.07863259315490723 Val Loss 2.306159734725952
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 12 Train Acc 94.99239349365234% Val Acc 76.5% Train Loss 0.07229958474636078 Val Loss 0.9995118975639343
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 13 Train Acc 95.384033203125% Val Acc 74.4000015258789% Train Loss 0.06655590981245041 Val Loss 1.0646761655807495
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 14 Train Acc 95.68441009521484% Val Acc 67.5999984741211% Train Loss 0.06338706612586975 Val Loss 1.3742214441299438
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 15 Train Acc 95.74524688720703% Val Acc 68.5% Train Loss 0.062443722039461136 Val Loss 1.3320602178573608
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 16 Train Acc 95.14068603515625% Val Acc 61.10000228881836% Train Loss 0.0710097998380661 Val Loss 1.7860416173934937
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 17 Train Acc 95.8973388671875% Val Acc 71.70000457763672% Train Loss 0.0605027973651886 Val Loss 1.3329758644104004
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 18 Train Acc 95.90113830566406% Val Acc 72.0% Train Loss 0.06229180097579956 Val Loss 0.9692036509513855
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 19 Train Acc 95.90113830566406% Val Acc 64.9000015258789% Train Loss 0.06115317344665527 Val Loss 1.6772171258926392
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 20 Train Acc 95.85931396484375% Val Acc 63.70000076293945% Train Loss 0.06319630146026611 Val Loss 1.7257622480392456
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 21 Train Acc 95.4828872680664% Val Acc 71.20000457763672% Train Loss 0.06577203422784805 Val Loss 1.4900480508804321
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 22 Train Acc 95.6615982055664% Val Acc 59.70000076293945% Train Loss 0.06435390561819077 Val Loss 1.8096227645874023
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 23 Train Acc 95.3079833984375% Val Acc 73.0% Train Loss 0.06727700680494308 Val Loss 1.152875304222107
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 24 Train Acc 96.37261962890625% Val Acc 66.0999984741211% Train Loss 0.05802462622523308 Val Loss 1.4960130453109741
EPOCH unfeeze : 25
Trainable Parameters : 151419140
Epoch 25 Train Acc 95.31938934326172% Val Acc 65.4000015258789% Train Loss 0.06933528184890747 Val Loss 1.505348563194275
EPOCH unfeeze : 26
Trainable Parameters : 151419140
Epoch 26 Train Acc 94.95817565917969% Val Acc 70.30000305175781% Train Loss 0.07079297304153442 Val Loss 1.2506719827651978
EPOCH unfeeze : 27
Trainable Parameters : 151419140
Epoch 27 Train Acc 95.6615982055664% Val Acc 65.80000305175781% Train Loss 0.06404829770326614 Val Loss 1.909096121788025
EPOCH unfeeze : 28
Trainable Parameters : 151419140
Epoch 28 Train Acc 94.80988311767578% Val Acc 65.80000305175781% Train Loss 0.07473231106996536 Val Loss 1.5464285612106323
EPOCH unfeeze : 29
Trainable Parameters : 151419140
Epoch 29 Train Acc 95.26615905761719% Val Acc 67.0999984741211% Train Loss 0.07293569296598434 Val Loss 1.6461546421051025
EPOCH unfeeze : 30
Trainable Parameters : 151419140
Epoch 30 Train Acc 94.80228424072266% Val Acc 66.70000457763672% Train Loss 0.07479161024093628 Val Loss 1.443650722503662
EPOCH unfeeze : 31
Trainable Parameters : 151419140
Epoch 31 Train Acc 95.06083679199219% Val Acc 67.20000457763672% Train Loss 0.0740884318947792 Val Loss 1.3889576196670532
EPOCH unfeeze : 32
Trainable Parameters : 151419140
Epoch 32 Train Acc 94.80988311767578% Val Acc 69.5% Train Loss 0.07550511509180069 Val Loss 1.2734971046447754
EPOCH unfeeze : 33
Trainable Parameters : 151419140
Epoch 33 Train Acc 94.76045227050781% Val Acc 62.10000228881836% Train Loss 0.07506166398525238 Val Loss 1.4935872554779053
EPOCH unfeeze : 34
Trainable Parameters : 151419140
Epoch 34 Train Acc 94.57414245605469% Val Acc 69.4000015258789% Train Loss 0.0812780037522316 Val Loss 1.5149307250976562
EPOCH unfeeze : 35
Trainable Parameters : 151419140
Epoch 35 Train Acc 94.49429321289062% Val Acc 64.0999984741211% Train Loss 0.08140897005796432 Val Loss 1.6769905090332031
EPOCH unfeeze : 36
Trainable Parameters : 151419140
Epoch 36 Train Acc 94.13687896728516% Val Acc 69.0999984741211% Train Loss 0.08601781725883484 Val Loss 1.1133326292037964
EPOCH unfeeze : 37
Trainable Parameters : 151419140
Epoch 37 Train Acc 94.19391632080078% Val Acc 70.70000457763672% Train Loss 0.0840255618095398 Val Loss 0.9413349032402039
EPOCH unfeeze : 38
Trainable Parameters : 151419140
Epoch 38 Train Acc 94.6463851928711% Val Acc 67.80000305175781% Train Loss 0.07758808135986328 Val Loss 1.2353250980377197
EPOCH unfeeze : 39
Trainable Parameters : 151419140
Epoch 39 Train Acc 94.80988311767578% Val Acc 60.400001525878906% Train Loss 0.0742015466094017 Val Loss 1.8796501159667969
EPOCH unfeeze : 40
Trainable Parameters : 151419140
Epoch 40 Train Acc 95.04182434082031% Val Acc 68.0999984741211% Train Loss 0.07186809927225113 Val Loss 1.380095362663269
EPOCH unfeeze : 41
Trainable Parameters : 151419140
Epoch 41 Train Acc 95.41064453125% Val Acc 66.5% Train Loss 0.07056856155395508 Val Loss 1.2157405614852905
EPOCH unfeeze : 42
Trainable Parameters : 151419140
Epoch 42 Train Acc 95.8212890625% Val Acc 68.9000015258789% Train Loss 0.06360295414924622 Val Loss 1.3468354940414429
EPOCH unfeeze : 43
Trainable Parameters : 151419140
Epoch 43 Train Acc 96.57034301757812% Val Acc 61.70000076293945% Train Loss 0.053291890770196915 Val Loss 1.7139291763305664
EPOCH unfeeze : 44
Trainable Parameters : 151419140
Epoch 44 Train Acc 95.6920166015625% Val Acc 68.0999984741211% Train Loss 0.06471087783575058 Val Loss 1.5102391242980957
EPOCH unfeeze : 45
Trainable Parameters : 151419140
Epoch 45 Train Acc 96.53992462158203% Val Acc 63.900001525878906% Train Loss 0.05103558301925659 Val Loss 1.5663381814956665
EPOCH unfeeze : 46
Trainable Parameters : 151419140
Epoch 46 Train Acc 96.46007537841797% Val Acc 63.10000228881836% Train Loss 0.05078643560409546 Val Loss 1.6256989240646362
EPOCH unfeeze : 47
Trainable Parameters : 151419140
Epoch 47 Train Acc 96.63497924804688% Val Acc 68.20000457763672% Train Loss 0.052967920899391174 Val Loss 1.284741759300232
EPOCH unfeeze : 48
Trainable Parameters : 151419140
Epoch 48 Train Acc 96.60456085205078% Val Acc 66.5999984741211% Train Loss 0.050829049199819565 Val Loss 1.5043123960494995
EPOCH unfeeze : 49
Trainable Parameters : 151419140
Epoch 49 Train Acc 97.03421783447266% Val Acc 67.80000305175781% Train Loss 0.04460388794541359 Val Loss 1.6288608312606812
EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 50 Train Acc 97.22053527832031% Val Acc 59.400001525878906% Train Loss 0.04442134127020836 Val Loss 2.3222196102142334
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 51 Train Acc 97.28897094726562% Val Acc 67.0% Train Loss 0.042414288967847824 Val Loss 1.617242693901062
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 52 Train Acc 97.34600830078125% Val Acc 72.30000305175781% Train Loss 0.04120791330933571 Val Loss 1.346714735031128
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 53 Train Acc 97.14068603515625% Val Acc 72.5% Train Loss 0.0438498817384243 Val Loss 1.2582823038101196
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 54 Train Acc 97.36882019042969% Val Acc 64.80000305175781% Train Loss 0.040940508246421814 Val Loss 1.7094172239303589
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 55 Train Acc 97.04562377929688% Val Acc 72.9000015258789% Train Loss 0.04337384179234505 Val Loss 1.4165184497833252
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 56 Train Acc 97.2775650024414% Val Acc 64.5999984741211% Train Loss 0.040662731975317 Val Loss 1.7923978567123413
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 57 Train Acc 98.17110443115234% Val Acc 69.4000015258789% Train Loss 0.028491949662566185 Val Loss 2.0022237300872803
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 58 Train Acc 97.27376556396484% Val Acc 67.30000305175781% Train Loss 0.04034242033958435 Val Loss 1.5622256994247437
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 59 Train Acc 97.59695434570312% Val Acc 69.70000457763672% Train Loss 0.03570890054106712 Val Loss 1.4852970838546753
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 60 Train Acc 97.76805877685547% Val Acc 73.30000305175781% Train Loss 0.03257155045866966 Val Loss 1.3088105916976929
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 61 Train Acc 98.16729736328125% Val Acc 68.5% Train Loss 0.03022477962076664 Val Loss 1.6010693311691284
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 62 Train Acc 97.8212890625% Val Acc 73.20000457763672% Train Loss 0.03462129458785057 Val Loss 1.296787977218628
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 63 Train Acc 98.39923858642578% Val Acc 68.4000015258789% Train Loss 0.0233517587184906 Val Loss 2.0623276233673096
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 64 Train Acc 97.99239349365234% Val Acc 68.80000305175781% Train Loss 0.029834292829036713 Val Loss 1.6715627908706665
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 65 Train Acc 98.30418395996094% Val Acc 70.0999984741211% Train Loss 0.028363561257719994 Val Loss 1.651902198791504
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 66 Train Acc 97.87452697753906% Val Acc 71.0% Train Loss 0.03240717202425003 Val Loss 1.910880446434021
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 67 Train Acc 98.24334716796875% Val Acc 68.70000457763672% Train Loss 0.025944996625185013 Val Loss 1.9944486618041992
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 68 Train Acc 98.33079528808594% Val Acc 65.9000015258789% Train Loss 0.02552110329270363 Val Loss 2.007352113723755
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 69 Train Acc 98.36121368408203% Val Acc 70.70000457763672% Train Loss 0.026844922453165054 Val Loss 1.828741431236267
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 70 Train Acc 98.53992462158203% Val Acc 65.80000305175781% Train Loss 0.024382108822464943 Val Loss 2.107228994369507
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 71 Train Acc 98.31558990478516% Val Acc 69.4000015258789% Train Loss 0.027145884931087494 Val Loss 1.8928993940353394
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 72 Train Acc 98.44486236572266% Val Acc 64.30000305175781% Train Loss 0.02473549358546734 Val Loss 1.9714359045028687
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 73 Train Acc 98.5589370727539% Val Acc 68.5% Train Loss 0.023503614589571953 Val Loss 1.9024591445922852
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 74 Train Acc 98.6197738647461% Val Acc 68.80000305175781% Train Loss 0.021627822890877724 Val Loss 1.9488414525985718
EPOCH unfeeze : 25
Trainable Parameters : 151419140
Epoch 75 Train Acc 98.6615982055664% Val Acc 73.0% Train Loss 0.021189909428358078 Val Loss 1.7672208547592163
EPOCH unfeeze : 26
Trainable Parameters : 151419140
Epoch 76 Train Acc 99.03802490234375% Val Acc 69.5% Train Loss 0.017619026824831963 Val Loss 1.67671799659729
EPOCH unfeeze : 27
Trainable Parameters : 151419140
Epoch 77 Train Acc 98.7642593383789% Val Acc 57.60000228881836% Train Loss 0.021090980619192123 Val Loss 2.87028169631958
EPOCH unfeeze : 28
Trainable Parameters : 151419140
Epoch 78 Train Acc 98.41064453125% Val Acc 67.80000305175781% Train Loss 0.02454386278986931 Val Loss 1.7837752103805542
EPOCH unfeeze : 29
Trainable Parameters : 151419140
Epoch 79 Train Acc 98.88212585449219% Val Acc 67.20000457763672% Train Loss 0.01900581642985344 Val Loss 2.1429390907287598
EPOCH unfeeze : 30
Trainable Parameters : 151419140
Epoch 80 Train Acc 98.7490463256836% Val Acc 60.5% Train Loss 0.019922146573662758 Val Loss 3.048236846923828
EPOCH unfeeze : 31
Trainable Parameters : 151419140
Epoch 81 Train Acc 98.58935546875% Val Acc 70.9000015258789% Train Loss 0.0232579056173563 Val Loss 1.8922748565673828
EPOCH unfeeze : 32
Trainable Parameters : 151419140
Epoch 82 Train Acc 98.84790802001953% Val Acc 73.0999984741211% Train Loss 0.01742955483496189 Val Loss 1.7854803800582886
EPOCH unfeeze : 33
Trainable Parameters : 151419140
Epoch 83 Train Acc 98.9695816040039% Val Acc 73.5999984741211% Train Loss 0.01729762926697731 Val Loss 2.034893751144409
EPOCH unfeeze : 34
Trainable Parameters : 151419140
Epoch 84 Train Acc 98.93155670166016% Val Acc 68.5% Train Loss 0.019494805485010147 Val Loss 1.8646421432495117
EPOCH unfeeze : 35
Trainable Parameters : 151419140
Epoch 85 Train Acc 98.75285339355469% Val Acc 69.30000305175781% Train Loss 0.01997584104537964 Val Loss 1.9327306747436523
EPOCH unfeeze : 36
Trainable Parameters : 151419140
Epoch 86 Train Acc 98.91254425048828% Val Acc 65.9000015258789% Train Loss 0.015812432393431664 Val Loss 2.5902621746063232
EPOCH unfeeze : 37
Trainable Parameters : 151419140
Epoch 87 Train Acc 98.7642593383789% Val Acc 68.5999984741211% Train Loss 0.019744008779525757 Val Loss 2.4170923233032227
EPOCH unfeeze : 38
Trainable Parameters : 151419140
Epoch 88 Train Acc 98.88593292236328% Val Acc 71.30000305175781% Train Loss 0.01735513284802437 Val Loss 1.7553484439849854
EPOCH unfeeze : 39
Trainable Parameters : 151419140
Epoch 89 Train Acc 99.07604217529297% Val Acc 68.80000305175781% Train Loss 0.012951892800629139 Val Loss 2.163435935974121
EPOCH unfeeze : 40
Trainable Parameters : 151419140
Epoch 90 Train Acc 98.9277572631836% Val Acc 64.30000305175781% Train Loss 0.017390253022313118 Val Loss 2.1408097743988037
EPOCH unfeeze : 41
Trainable Parameters : 151419140
Epoch 91 Train Acc 98.82889556884766% Val Acc 67.4000015258789% Train Loss 0.01792321912944317 Val Loss 1.8799551725387573
EPOCH unfeeze : 42
Trainable Parameters : 151419140
Epoch 92 Train Acc 99.03802490234375% Val Acc 67.20000457763672% Train Loss 0.01548000518232584 Val Loss 2.296881675720215
EPOCH unfeeze : 43
Trainable Parameters : 151419140
Epoch 93 Train Acc 99.30418395996094% Val Acc 66.70000457763672% Train Loss 0.012795781716704369 Val Loss 2.033027410507202
EPOCH unfeeze : 44
Trainable Parameters : 151419140
Epoch 94 Train Acc 99.07984924316406% Val Acc 63.60000228881836% Train Loss 0.014934748411178589 Val Loss 2.340930700302124
EPOCH unfeeze : 45
Trainable Parameters : 151419140
Epoch 95 Train Acc 98.99620056152344% Val Acc 65.20000457763672% Train Loss 0.014273818582296371 Val Loss 2.314946413040161
EPOCH unfeeze : 46
Trainable Parameters : 151419140
Epoch 96 Train Acc 98.9277572631836% Val Acc 65.30000305175781% Train Loss 0.017919739708304405 Val Loss 1.9328489303588867
EPOCH unfeeze : 47
Trainable Parameters : 151419140
Epoch 97 Train Acc 99.22813415527344% Val Acc 66.5999984741211% Train Loss 0.011182381771504879 Val Loss 2.505963087081909
EPOCH unfeeze : 48
Trainable Parameters : 151419140
Epoch 98 Train Acc 99.14068603515625% Val Acc 67.5999984741211% Train Loss 0.014282009564340115 Val Loss 2.249530076980591
EPOCH unfeeze : 49
Trainable Parameters : 151419140
Configuration saved in /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step50/config.json
Model weights saved in /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step50/pytorch_model.bin
Epoch 99 Train Acc 99.00760650634766% Val Acc 68.70000457763672% Train Loss 0.015320737846195698 Val Loss 2.0815036296844482

------> EVALUATING MODEL... ------------------------------------------ 

Final Test Acc:76.80000305175781% Loss:1.5165202617645264
CONFUSION MATRIX
[[84  6  6  4]
 [ 8 52 24 16]
 [ 3  4 84  7]
 [ 3  4  7 86]]
CONFUSION MATRIX NORMALISED
[[0.21105528 0.01507538 0.01507538 0.01005025]
 [0.0201005  0.13065327 0.06030151 0.04020101]
 [0.00753769 0.01005025 0.21105528 0.01758794]
 [0.00753769 0.01005025 0.01758794 0.2160804 ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       100
           1       0.79      0.52      0.63       100
           2       0.69      0.86      0.77        98
           3       0.76      0.86      0.81       100

    accuracy                           0.77       398
   macro avg       0.78      0.77      0.76       398
weighted avg       0.78      0.77      0.76       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 05/11/2022 23:58:16
