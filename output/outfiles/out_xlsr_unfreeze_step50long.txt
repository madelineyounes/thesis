Mon Nov 7 18:37:26 AEDT 2022
2022-11-07 18:37:28.459196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-07 18:37:28.835038: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-07 18:37:28.972093: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-07 18:37:30.672491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-07 18:37:30.674249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-07 18:37:30.674260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_unfreezestep50long.py
Started: 07/11/2022 18:37:43

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-araic-unfreeze-step50-long
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: train_u_20s
train_filename: train_u_20s
validation_filename: dev_u_20s
evaluation_filename: test_u_20s
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 8
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 50
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/train_u_20s.csv
--> data_test_fp: data/dev_u_20s.csv
--> data_test_fp: data/test_u_20s.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: /srv/scratch/z5208494/output/train_u_20s_local/ADI17-xlsr-araic-unfreeze-step50-long
--> finetuned_results_fp: /srv/scratch/z5208494/output/train_u_20s_local/ADI17-xlsr-araic-unfreeze-step50-long_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.2249, -0.0653,  0.1445,  ..., -0.5289, -0.5860, -0.6841],
        [-0.5172, -0.8342, -0.6627,  ...,  0.7283,  0.9588,  0.8894],
        [-0.3691,  0.0564,  0.1591,  ...,  1.0432,  0.9342,  0.7722],
        ...,
        [ 0.0298,  0.0249,  0.0242,  ...,  0.6006,  0.5104,  0.3925],
        [-1.0217, -1.3089, -1.2761,  ..., -1.7689, -1.0885, -0.3890],
        [-3.0872, -3.0965, -2.8468,  ...,  0.0581,  0.0687,  0.0616]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([3, 0, 1, 2, 2, 2, 2, 0])}
Training DataCustom Files: 1672
Training Data Files: 209
Val Data Sample
{'input_values': tensor([[-0.7897, -1.1104, -0.6881,  ..., -0.4127, -0.2548, -0.0527],
        [ 0.0934, -0.0309,  0.0142,  ..., -1.9084, -1.7849, -2.1448],
        [ 0.3321,  0.3067,  0.2754,  ..., -0.1645, -0.1158, -0.0684],
        ...,
        [-0.6134, -0.6999, -0.7026,  ...,  0.1451, -0.0817, -0.2331],
        [-0.0324, -0.0225, -0.0096,  ...,  0.6486,  0.6409,  0.6229],
        [ 0.5878,  0.4407,  0.2602,  ...,  0.3241,  0.3466,  0.3241]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([3, 0, 0, 2, 3, 2, 2, 3])}
Test CustomData Files: 1673
Test Data Files: 210
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.weight', 'classifier.weight', 'classifier.bias', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.0343, -0.0618, -0.1149,  ..., -0.6536, -0.4973, -0.4148],
        [ 2.7603,  2.3471,  1.4840,  ..., -0.0784,  0.0315,  0.1249],
        [ 0.4305,  0.4204,  0.4308,  ..., -1.1167, -1.2796, -1.5709],
        ...,
        [ 0.0881,  0.2596,  0.1356,  ..., -0.0658, -0.0332, -0.0290],
        [-0.0840, -0.0596, -0.0808,  ...,  0.3442,  0.2983,  0.2718],
        [-0.0160, -0.0600,  0.0238,  ...,  0.9506,  0.8772,  0.3111]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 3, 3, 2, 0, 0, 0, 2])}
Test CustomData Files: 1922
Test Data Files: 241
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 0 Train Acc 26.645931243896484% Val Acc 26.190872192382812% Train Loss 0.6919957399368286 Val Loss 1.197311282157898
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 1 Train Acc 33.16746139526367% Val Acc 27.30705451965332% Train Loss 0.6844083070755005 Val Loss 1.177133321762085
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 2 Train Acc 37.54545211791992% Val Acc 38.25726318359375% Train Loss 0.655461847782135 Val Loss 1.0762412548065186
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 3 Train Acc 52.023921966552734% Val Acc 47.79668426513672% Train Loss 0.5725677013397217 Val Loss 0.9095040559768677
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 4 Train Acc 64.4354019165039% Val Acc 54.273860931396484% Train Loss 0.46364858746528625 Val Loss 0.8439598679542542
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 5 Train Acc 74.62200927734375% Val Acc 62.62240982055664% Train Loss 0.3484475314617157 Val Loss 0.6862480640411377
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 6 Train Acc 81.7129135131836% Val Acc 57.5601692199707% Train Loss 0.2587372362613678 Val Loss 0.999588131904602
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 7 Train Acc 87.29186248779297% Val Acc 61.40249252319336% Train Loss 0.18828490376472473 Val Loss 0.867674708366394
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 8 Train Acc 91.56459045410156% Val Acc 65.75103759765625% Train Loss 0.12124413996934891 Val Loss 0.8140730857849121
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 9 Train Acc 93.55023956298828% Val Acc 62.896270751953125% Train Loss 0.09662621468305588 Val Loss 0.9103524088859558
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 10 Train Acc 94.52153015136719% Val Acc 66.74274444580078% Train Loss 0.0870538279414177 Val Loss 0.7952755689620972
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 11 Train Acc 95.55023193359375% Val Acc 63.19502258300781% Train Loss 0.07131992280483246 Val Loss 1.019466757774353
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 12 Train Acc 94.82295989990234% Val Acc 63.23651885986328% Train Loss 0.0816069021821022 Val Loss 0.9971996545791626
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 13 Train Acc 95.39234161376953% Val Acc 61.97510528564453% Train Loss 0.07415229082107544 Val Loss 1.1178470849990845
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 14 Train Acc 96.15310668945312% Val Acc 61.892120361328125% Train Loss 0.05904858931899071 Val Loss 1.2493646144866943
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 15 Train Acc 95.85645294189453% Val Acc 67.4232406616211% Train Loss 0.0645802915096283 Val Loss 0.8710002899169922
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 16 Train Acc 95.74162292480469% Val Acc 63.47718048095703% Train Loss 0.06909331679344177 Val Loss 1.033276915550232
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 17 Train Acc 95.78946685791016% Val Acc 63.68465042114258% Train Loss 0.06249797344207764 Val Loss 1.0324032306671143
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 18 Train Acc 97.02870178222656% Val Acc 66.16597747802734% Train Loss 0.049590419977903366 Val Loss 1.0345159769058228
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 19 Train Acc 95.68899536132812% Val Acc 63.12863540649414% Train Loss 0.07206254452466965 Val Loss 0.9285195469856262
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 20 Train Acc 94.99520874023438% Val Acc 63.020751953125% Train Loss 0.07815694063901901 Val Loss 1.039302110671997
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 21 Train Acc 96.52631378173828% Val Acc 62.34855270385742% Train Loss 0.05784297734498978 Val Loss 1.196638584136963
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 22 Train Acc 95.86124420166016% Val Acc 49.32365417480469% Train Loss 0.06606628000736237 Val Loss 1.9853847026824951
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 23 Train Acc 96.27272033691406% Val Acc 62.21577072143555% Train Loss 0.053641386330127716 Val Loss 1.213911533355713
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 24 Train Acc 96.90908813476562% Val Acc 46.921165466308594% Train Loss 0.051688797771930695 Val Loss 1.9989534616470337
EPOCH unfeeze : 25
Trainable Parameters : 151419140
Epoch 25 Train Acc 94.43061828613281% Val Acc 59.107887268066406% Train Loss 0.08502770215272903 Val Loss 1.2879977226257324
EPOCH unfeeze : 26
Trainable Parameters : 151419140
Epoch 26 Train Acc 96.74162292480469% Val Acc 61.62240982055664% Train Loss 0.050116270780563354 Val Loss 1.2797285318374634
EPOCH unfeeze : 27
Trainable Parameters : 151419140
Epoch 27 Train Acc 95.07176971435547% Val Acc 55.20746994018555% Train Loss 0.07750918716192245 Val Loss 1.606160044670105
EPOCH unfeeze : 28
Trainable Parameters : 151419140
Epoch 28 Train Acc 95.85645294189453% Val Acc 65.78423309326172% Train Loss 0.06232639402151108 Val Loss 0.9844024181365967
EPOCH unfeeze : 29
Trainable Parameters : 151419140
Epoch 29 Train Acc 96.2248764038086% Val Acc 62.029048919677734% Train Loss 0.06559363752603531 Val Loss 0.8593950867652893
EPOCH unfeeze : 30
Trainable Parameters : 151419140
Epoch 30 Train Acc 94.80382537841797% Val Acc 65.4273910522461% Train Loss 0.08669542521238327 Val Loss 0.8341944813728333
EPOCH unfeeze : 31
Trainable Parameters : 151419140
Epoch 31 Train Acc 96.44976043701172% Val Acc 61.36514663696289% Train Loss 0.06167391315102577 Val Loss 1.184619665145874
EPOCH unfeeze : 32
Trainable Parameters : 151419140
Epoch 32 Train Acc 95.83731842041016% Val Acc 63.34855270385742% Train Loss 0.08039654791355133 Val Loss 0.9643959403038025
EPOCH unfeeze : 33
Trainable Parameters : 151419140
Epoch 33 Train Acc 96.74640655517578% Val Acc 63.86722183227539% Train Loss 0.058328986167907715 Val Loss 1.0549774169921875
EPOCH unfeeze : 34
Trainable Parameters : 151419140
Epoch 34 Train Acc 96.56937408447266% Val Acc 58.69709777832031% Train Loss 0.06454307585954666 Val Loss 1.246103286743164
EPOCH unfeeze : 35
Trainable Parameters : 151419140
Epoch 35 Train Acc 96.03349304199219% Val Acc 60.95021057128906% Train Loss 0.0714670792222023 Val Loss 1.2258187532424927
EPOCH unfeeze : 36
Trainable Parameters : 151419140
Epoch 36 Train Acc 94.74162292480469% Val Acc 51.497928619384766% Train Loss 0.09510975331068039 Val Loss 1.8278028964996338
EPOCH unfeeze : 37
Trainable Parameters : 151419140
Epoch 37 Train Acc 93.96650695800781% Val Acc 59.82572937011719% Train Loss 0.10215803980827332 Val Loss 1.1789534091949463
EPOCH unfeeze : 38
Trainable Parameters : 151419140
Epoch 38 Train Acc 94.74640655517578% Val Acc 55.004150390625% Train Loss 0.09050831943750381 Val Loss 1.4541813135147095
EPOCH unfeeze : 39
Trainable Parameters : 151419140
Epoch 39 Train Acc 95.26315307617188% Val Acc 51.858924865722656% Train Loss 0.08353566378355026 Val Loss 2.0274832248687744
EPOCH unfeeze : 40
Trainable Parameters : 151419140
Epoch 40 Train Acc 93.4593276977539% Val Acc 58.5103759765625% Train Loss 0.09658045321702957 Val Loss 1.3119637966156006
EPOCH unfeeze : 41
Trainable Parameters : 151419140
Epoch 41 Train Acc 94.01913452148438% Val Acc 58.37344741821289% Train Loss 0.08957505971193314 Val Loss 1.3763041496276855
EPOCH unfeeze : 42
Trainable Parameters : 151419140
Epoch 42 Train Acc 95.5167465209961% Val Acc 56.11618423461914% Train Loss 0.0730665922164917 Val Loss 1.399515151977539
EPOCH unfeeze : 43
Trainable Parameters : 151419140
Epoch 43 Train Acc 94.7607650756836% Val Acc 35.98340606689453% Train Loss 0.09029974043369293 Val Loss 2.5821585655212402
EPOCH unfeeze : 44
Trainable Parameters : 151419140
Epoch 44 Train Acc 94.57415771484375% Val Acc 56.81328201293945% Train Loss 0.089150071144104 Val Loss 1.3358938694000244
EPOCH unfeeze : 45
Trainable Parameters : 151419140
Epoch 45 Train Acc 94.67463684082031% Val Acc 59.95436096191406% Train Loss 0.08596734702587128 Val Loss 1.3175747394561768
EPOCH unfeeze : 46
Trainable Parameters : 151419140
Epoch 46 Train Acc 92.96650695800781% Val Acc 49.36929702758789% Train Loss 0.11521000415086746 Val Loss 1.4910340309143066
EPOCH unfeeze : 47
Trainable Parameters : 151419140
Epoch 47 Train Acc 94.9521484375% Val Acc 53.95021057128906% Train Loss 0.081471286714077 Val Loss 1.3162709474563599
EPOCH unfeeze : 48
Trainable Parameters : 151419140
Epoch 48 Train Acc 94.05741119384766% Val Acc 61.136932373046875% Train Loss 0.10053197294473648 Val Loss 0.9471248388290405
EPOCH unfeeze : 49
Trainable Parameters : 151419140
Epoch 49 Train Acc 94.31578826904297% Val Acc 60.98340606689453% Train Loss 0.09162476658821106 Val Loss 1.0985783338546753
EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 50 Train Acc 94.27272033691406% Val Acc 52.161827087402344% Train Loss 0.08609183877706528 Val Loss 1.6783493757247925
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 51 Train Acc 95.2009506225586% Val Acc 53.165977478027344% Train Loss 0.07955540716648102 Val Loss 1.4301822185516357
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 52 Train Acc 95.83731842041016% Val Acc 60.22821807861328% Train Loss 0.06619413197040558 Val Loss 1.1376196146011353
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 53 Train Acc 96.67463684082031% Val Acc 55.09128952026367% Train Loss 0.05925000458955765 Val Loss 1.2584922313690186
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 54 Train Acc 95.9521484375% Val Acc 56.68880081176758% Train Loss 0.06746896356344223 Val Loss 1.538848876953125
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 55 Train Acc 96.55502319335938% Val Acc 56.4647331237793% Train Loss 0.05477285757660866 Val Loss 1.3100186586380005
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 56 Train Acc 96.68899536132812% Val Acc 61.40249252319336% Train Loss 0.055573247373104095 Val Loss 0.9861616492271423
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 57 Train Acc 96.69856262207031% Val Acc 47.58091354370117% Train Loss 0.05256902799010277 Val Loss 2.2907018661499023
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 58 Train Acc 96.33013916015625% Val Acc 58.92946243286133% Train Loss 0.052879586815834045 Val Loss 1.0958428382873535
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 59 Train Acc 98.26793670654297% Val Acc 60.32780456542969% Train Loss 0.029140356928110123 Val Loss 1.493325114250183
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 60 Train Acc 97.83253479003906% Val Acc 58.850624084472656% Train Loss 0.035330697894096375 Val Loss 1.551595687866211
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 61 Train Acc 97.33013916015625% Val Acc 53.19087600708008% Train Loss 0.038771193474531174 Val Loss 1.9882473945617676
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 62 Train Acc 97.55980682373047% Val Acc 58.145233154296875% Train Loss 0.04146632179617882 Val Loss 1.656479001045227
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 63 Train Acc 98.4928207397461% Val Acc 61.04979705810547% Train Loss 0.03241582587361336 Val Loss 1.6775314807891846
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 64 Train Acc 98.27272033691406% Val Acc 59.244815826416016% Train Loss 0.030392026528716087 Val Loss 1.471121907234192
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 65 Train Acc 98.20573425292969% Val Acc 59.92946243286133% Train Loss 0.027150418609380722 Val Loss 1.4853630065917969
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 66 Train Acc 98.67463684082031% Val Acc 58.921165466308594% Train Loss 0.019942229613661766 Val Loss 2.0042827129364014
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 67 Train Acc 97.14832305908203% Val Acc 54.9626579284668% Train Loss 0.04222039878368378 Val Loss 2.0595779418945312
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 68 Train Acc 97.15310668945312% Val Acc 59.742740631103516% Train Loss 0.04689433053135872 Val Loss 1.6112595796585083
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 69 Train Acc 97.33492279052734% Val Acc 59.174278259277344% Train Loss 0.041604697704315186 Val Loss 1.4409598112106323
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 70 Train Acc 97.91387176513672% Val Acc 60.863075256347656% Train Loss 0.034226253628730774 Val Loss 1.4664051532745361
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 71 Train Acc 98.4928207397461% Val Acc 59.47718048095703% Train Loss 0.0266741830855608 Val Loss 1.825247883796692
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 72 Train Acc 98.77989959716797% Val Acc 62.14937973022461% Train Loss 0.017581654712557793 Val Loss 1.7399239540100098
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 73 Train Acc 97.88994598388672% Val Acc 61.19502258300781% Train Loss 0.03858586773276329 Val Loss 1.3579025268554688
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 74 Train Acc 98.14832305908203% Val Acc 60.26141357421875% Train Loss 0.0324922539293766 Val Loss 1.378562331199646
EPOCH unfeeze : 25
Trainable Parameters : 151419140
Epoch 75 Train Acc 98.32057189941406% Val Acc 59.04979705810547% Train Loss 0.023559443652629852 Val Loss 2.056753158569336
EPOCH unfeeze : 26
Trainable Parameters : 151419140
Epoch 76 Train Acc 99.1913833618164% Val Acc 59.630706787109375% Train Loss 0.013315502554178238 Val Loss 1.9559770822525024
EPOCH unfeeze : 27
Trainable Parameters : 151419140
Epoch 77 Train Acc 98.96171569824219% Val Acc 59.9585075378418% Train Loss 0.022188320755958557 Val Loss 1.805668830871582
EPOCH unfeeze : 28
Trainable Parameters : 151419140
Epoch 78 Train Acc 98.26315307617188% Val Acc 58.92946243286133% Train Loss 0.027420448139309883 Val Loss 1.8279231786727905
EPOCH unfeeze : 29
Trainable Parameters : 151419140
Epoch 79 Train Acc 98.54066467285156% Val Acc 56.991703033447266% Train Loss 0.02599487453699112 Val Loss 1.7291085720062256
EPOCH unfeeze : 30
Trainable Parameters : 151419140
Epoch 80 Train Acc 98.42105102539062% Val Acc 59.86722183227539% Train Loss 0.025690587237477303 Val Loss 1.8894951343536377
EPOCH unfeeze : 31
Trainable Parameters : 151419140
Epoch 81 Train Acc 99.30621337890625% Val Acc 56.5643196105957% Train Loss 0.013221241533756256 Val Loss 2.8813183307647705
EPOCH unfeeze : 32
Trainable Parameters : 151419140
Epoch 82 Train Acc 98.26793670654297% Val Acc 58.29460906982422% Train Loss 0.02537788823246956 Val Loss 2.464163303375244
EPOCH unfeeze : 33
Trainable Parameters : 151419140
Epoch 83 Train Acc 99.2488021850586% Val Acc 60.57261657714844% Train Loss 0.017167415469884872 Val Loss 2.4500882625579834
EPOCH unfeeze : 34
Trainable Parameters : 151419140
Epoch 84 Train Acc 98.77033233642578% Val Acc 58.36514663696289% Train Loss 0.022647982463240623 Val Loss 2.277331829071045
EPOCH unfeeze : 35
Trainable Parameters : 151419140
Epoch 85 Train Acc 99.35884857177734% Val Acc 59.742740631103516% Train Loss 0.014073369093239307 Val Loss 2.0231871604919434
EPOCH unfeeze : 36
Trainable Parameters : 151419140
Epoch 86 Train Acc 98.488037109375% Val Acc 59.004154205322266% Train Loss 0.02589430846273899 Val Loss 2.2924413681030273
EPOCH unfeeze : 37
Trainable Parameters : 151419140
Epoch 87 Train Acc 99.07655334472656% Val Acc 58.39834213256836% Train Loss 0.01899617910385132 Val Loss 2.43271541595459
EPOCH unfeeze : 38
Trainable Parameters : 151419140
Epoch 88 Train Acc 98.66506958007812% Val Acc 59.132781982421875% Train Loss 0.017544448375701904 Val Loss 2.229912281036377
EPOCH unfeeze : 39
Trainable Parameters : 151419140
Epoch 89 Train Acc 99.1913833618164% Val Acc 60.854774475097656% Train Loss 0.017574289813637733 Val Loss 2.5405311584472656
EPOCH unfeeze : 40
Trainable Parameters : 151419140
Epoch 90 Train Acc 98.83731842041016% Val Acc 59.09128952026367% Train Loss 0.022983010858297348 Val Loss 2.022488832473755
EPOCH unfeeze : 41
Trainable Parameters : 151419140
Epoch 91 Train Acc 99.01913452148438% Val Acc 57.95021057128906% Train Loss 0.02000248245894909 Val Loss 2.1481711864471436
EPOCH unfeeze : 42
Trainable Parameters : 151419140
Epoch 92 Train Acc 98.42105102539062% Val Acc 56.08713912963867% Train Loss 0.026849526911973953 Val Loss 2.4371888637542725
EPOCH unfeeze : 43
Trainable Parameters : 151419140
Epoch 93 Train Acc 98.30621337890625% Val Acc 59.170127868652344% Train Loss 0.02496190555393696 Val Loss 2.1591708660125732
EPOCH unfeeze : 44
Trainable Parameters : 151419140
Epoch 94 Train Acc 98.9473648071289% Val Acc 59.90456771850586% Train Loss 0.017022885382175446 Val Loss 2.3782036304473877
EPOCH unfeeze : 45
Trainable Parameters : 151419140
Epoch 95 Train Acc 98.77989959716797% Val Acc 60.45228576660156% Train Loss 0.01856464147567749 Val Loss 1.7331780195236206
EPOCH unfeeze : 46
Trainable Parameters : 151419140
Epoch 96 Train Acc 99.1913833618164% Val Acc 60.493778228759766% Train Loss 0.0126565583050251 Val Loss 1.8357840776443481
EPOCH unfeeze : 47
Trainable Parameters : 151419140
Epoch 97 Train Acc 99.13396453857422% Val Acc 61.80498123168945% Train Loss 0.013928474858403206 Val Loss 2.559377670288086
EPOCH unfeeze : 48
Trainable Parameters : 151419140
Epoch 98 Train Acc 99.4832534790039% Val Acc 61.23236846923828% Train Loss 0.010853160172700882 Val Loss 2.014456033706665
EPOCH unfeeze : 49
Trainable Parameters : 151419140
Configuration saved in /srv/scratch/z5208494/output/train_u_20s_local/ADI17-xlsr-araic-unfreeze-step50-long/config.json
Model weights saved in /srv/scratch/z5208494/output/train_u_20s_local/ADI17-xlsr-araic-unfreeze-step50-long/pytorch_model.bin
Epoch 99 Train Acc 99.1913833618164% Val Acc 59.93361282348633% Train Loss 0.015636811032891273 Val Loss 2.7270729541778564

------> EVALUATING MODEL... ------------------------------------------ 

Final Test Acc:68.21577453613281% Loss:3.029292583465576
CONFUSION MATRIX
[[301  44  51 104]
 [ 15 270  62  78]
 [ 36  29 363  69]
 [ 15  35  75 375]]
CONFUSION MATRIX NORMALISED
[[0.1566077  0.02289282 0.02653486 0.0541103 ]
 [0.00780437 0.14047867 0.03225806 0.04058273]
 [0.01873049 0.01508845 0.18886576 0.0359001 ]
 [0.00780437 0.0182102  0.03902185 0.19510926]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.82      0.60      0.69       500
           1       0.71      0.64      0.67       425
           2       0.66      0.73      0.69       497
           3       0.60      0.75      0.67       500

    accuracy                           0.68      1922
   macro avg       0.70      0.68      0.68      1922
weighted avg       0.70      0.68      0.68      1922


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 07/11/2022 22:17:16
