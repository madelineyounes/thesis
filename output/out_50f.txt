Mon Oct 10 03:01:06 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_50f.py
Started: 10/10/2022 03:01:10

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-50-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_50f_devdata
train_filename: test_u_50f
evaluation_filename: train_u_50f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_50f.csv
--> data_test_fp: data/train_u_50f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_50f_devdata_local/wav2vec-ADI17-50-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_50f_devdata_local/wav2vec-ADI17-50-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0932, -0.1160, -0.1244,  ...,  0.0000,  0.0000,  0.0000],
        [-3.2774, -3.6419, -5.1684,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2356,  0.8698,  1.8955,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-1.1517, -1.1561, -1.2006,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3968,  0.3609,  0.3379,  ...,  0.0000,  0.0000,  0.0000],
        [-0.5130, -0.0931,  0.2229,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 3, 2, 0, 1, 2, 0, 3, 2, 2, 3])}
Training DataCustom Files: 195
Training Data Files: 17
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.bias', 'project_q.weight', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_hid.bias', 'quantizer.codevectors']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.bias', 'projector.weight', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.5043, -1.2952, -2.2415,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3273,  0.6732,  1.0873,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.7998,  0.9084,  0.9134,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.3123, -0.3339, -0.3686,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0037,  0.0027,  0.0056,  ...,  0.0000,  0.0000,  0.0000],
        [-1.2596, -1.0344, -1.3819,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 0, 1, 3, 0, 1, 1, 1, 3, 0, 3])}
Test CustomData Files: 195
Test Data Files: 17
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 25.41176414489746% Val Acc 26.47058868408203% Train Loss 0.6976045966148376 Val Loss 1.3809393644332886
Trainable Parameters : 198660
Epoch 1 Train Acc 26.882352828979492% Val Acc 23.0% Train Loss 0.696212649345398 Val Loss 1.388782262802124
Trainable Parameters : 198660
Epoch 2 Train Acc 26.47058868408203% Val Acc 22.647058486938477% Train Loss 0.6947932839393616 Val Loss 1.391231656074524
Trainable Parameters : 198660
Epoch 3 Train Acc 25.0% Val Acc 24.05882453918457% Train Loss 0.6961104869842529 Val Loss 1.3867378234863281
Trainable Parameters : 198660
Epoch 4 Train Acc 26.41176414489746% Val Acc 22.705883026123047% Train Loss 0.6945766806602478 Val Loss 1.3866629600524902
Trainable Parameters : 198660
Epoch 5 Train Acc 23.941177368164062% Val Acc 24.941177368164062% Train Loss 0.6952090859413147 Val Loss 1.3869597911834717
Trainable Parameters : 198660
Epoch 6 Train Acc 28.823530197143555% Val Acc 25.0% Train Loss 0.6939954161643982 Val Loss 1.388267159461975
Trainable Parameters : 198660
Epoch 7 Train Acc 27.0% Val Acc 23.58823585510254% Train Loss 0.695465624332428 Val Loss 1.389281988143921
Trainable Parameters : 198660
Epoch 8 Train Acc 27.0% Val Acc 25.52941131591797% Train Loss 0.6939864754676819 Val Loss 1.387660026550293
Trainable Parameters : 198660
Epoch 9 Train Acc 24.47058868408203% Val Acc 25.58823585510254% Train Loss 0.6933971047401428 Val Loss 1.387772798538208
Trainable Parameters : 198660
Epoch 10 Train Acc 27.41176414489746% Val Acc 27.294116973876953% Train Loss 0.6926341652870178 Val Loss 1.388297200202942
Trainable Parameters : 198660
Epoch 11 Train Acc 29.52941131591797% Val Acc 25.47058868408203% Train Loss 0.6918726563453674 Val Loss 1.3885515928268433
Trainable Parameters : 198660
Epoch 12 Train Acc 28.941177368164062% Val Acc 25.47058868408203% Train Loss 0.6905142664909363 Val Loss 1.3863173723220825
Trainable Parameters : 198660
Epoch 13 Train Acc 31.352941513061523% Val Acc 23.41176414489746% Train Loss 0.6898208856582642 Val Loss 1.3881757259368896
Trainable Parameters : 198660
Epoch 14 Train Acc 32.82352828979492% Val Acc 20.117647171020508% Train Loss 0.68851238489151 Val Loss 1.3910281658172607
Trainable Parameters : 198660
Epoch 15 Train Acc 33.764705657958984% Val Acc 20.58823585510254% Train Loss 0.6867743134498596 Val Loss 1.3916523456573486
Trainable Parameters : 198660
Epoch 16 Train Acc 32.882354736328125% Val Acc 20.117647171020508% Train Loss 0.6875655651092529 Val Loss 1.3947306871414185
Trainable Parameters : 198660
Epoch 17 Train Acc 39.64706039428711% Val Acc 20.117647171020508% Train Loss 0.685084879398346 Val Loss 1.3964484930038452
Trainable Parameters : 198660
Epoch 18 Train Acc 34.235294342041016% Val Acc 19.58823585510254% Train Loss 0.6857542395591736 Val Loss 1.3947025537490845
Trainable Parameters : 198660
Epoch 19 Train Acc 34.235294342041016% Val Acc 19.117647171020508% Train Loss 0.68461012840271 Val Loss 1.398950219154358
Trainable Parameters : 198660
Epoch 20 Train Acc 39.17647171020508% Val Acc 20.58823585510254% Train Loss 0.6813254952430725 Val Loss 1.3978246450424194
Trainable Parameters : 198660
Epoch 21 Train Acc 41.235294342041016% Val Acc 24.117647171020508% Train Loss 0.6812940239906311 Val Loss 1.3953715562820435
Trainable Parameters : 198660
Epoch 22 Train Acc 42.588233947753906% Val Acc 21.05882453918457% Train Loss 0.6775606870651245 Val Loss 1.4030566215515137
Trainable Parameters : 198660
Epoch 23 Train Acc 42.17647171020508% Val Acc 23.58823585510254% Train Loss 0.6782098412513733 Val Loss 1.398411750793457
Trainable Parameters : 198660
Epoch 24 Train Acc 38.70588302612305% Val Acc 23.176469802856445% Train Loss 0.6805433034896851 Val Loss 1.3959070444107056
Trainable Parameters : 198660
Epoch 25 Train Acc 43.64706039428711% Val Acc 20.0% Train Loss 0.6742467880249023 Val Loss 1.4066381454467773
Trainable Parameters : 198660
Epoch 26 Train Acc 45.05882263183594% Val Acc 20.176469802856445% Train Loss 0.6720261573791504 Val Loss 1.407963514328003
Trainable Parameters : 198660
Epoch 27 Train Acc 42.11764907836914% Val Acc 21.647058486938477% Train Loss 0.6753383278846741 Val Loss 1.4098012447357178
Trainable Parameters : 198660
Epoch 28 Train Acc 44.17647171020508% Val Acc 19.52941131591797% Train Loss 0.6717101335525513 Val Loss 1.4121884107589722
Trainable Parameters : 198660
Epoch 29 Train Acc 42.70588302612305% Val Acc 22.52941131591797% Train Loss 0.6711878180503845 Val Loss 1.4143375158309937
Trainable Parameters : 198660
Epoch 30 Train Acc 40.11764907836914% Val Acc 22.0% Train Loss 0.6725565195083618 Val Loss 1.4229151010513306
Trainable Parameters : 198660
Epoch 31 Train Acc 41.235294342041016% Val Acc 23.58823585510254% Train Loss 0.6681726574897766 Val Loss 1.4129548072814941
Trainable Parameters : 198660
Epoch 32 Train Acc 41.70588302612305% Val Acc 22.0% Train Loss 0.6727569699287415 Val Loss 1.430487036705017
Trainable Parameters : 198660
Epoch 33 Train Acc 43.64706039428711% Val Acc 21.0% Train Loss 0.6639888286590576 Val Loss 1.430095911026001
Trainable Parameters : 198660
Epoch 34 Train Acc 42.17647171020508% Val Acc 23.941177368164062% Train Loss 0.6674589514732361 Val Loss 1.4188737869262695
Trainable Parameters : 198660
Epoch 35 Train Acc 40.70588302612305% Val Acc 20.117647171020508% Train Loss 0.6679825186729431 Val Loss 1.4353567361831665
Trainable Parameters : 198660
Epoch 36 Train Acc 39.235294342041016% Val Acc 19.705883026123047% Train Loss 0.6687057018280029 Val Loss 1.4410275220870972
Trainable Parameters : 198660
Epoch 37 Train Acc 38.17647171020508% Val Acc 19.647058486938477% Train Loss 0.6687102317810059 Val Loss 1.4400336742401123
Trainable Parameters : 198660
Epoch 38 Train Acc 39.64706039428711% Val Acc 19.52941131591797% Train Loss 0.6624617576599121 Val Loss 1.4399017095565796
Trainable Parameters : 198660
Epoch 39 Train Acc 43.05882263183594% Val Acc 22.58823585510254% Train Loss 0.6633751392364502 Val Loss 1.4334039688110352
Trainable Parameters : 198660
Epoch 40 Train Acc 38.235294342041016% Val Acc 18.705883026123047% Train Loss 0.6651440858840942 Val Loss 1.441168189048767
Trainable Parameters : 198660
Epoch 41 Train Acc 43.70588302612305% Val Acc 19.58823585510254% Train Loss 0.6603521704673767 Val Loss 1.441928744316101
Trainable Parameters : 198660
Epoch 42 Train Acc 43.47058868408203% Val Acc 18.05882453918457% Train Loss 0.6585764288902283 Val Loss 1.4556360244750977
Trainable Parameters : 198660
Epoch 43 Train Acc 43.17647171020508% Val Acc 20.58823585510254% Train Loss 0.657500147819519 Val Loss 1.451593041419983
Trainable Parameters : 198660
Epoch 44 Train Acc 43.70588302612305% Val Acc 18.235294342041016% Train Loss 0.652063250541687 Val Loss 1.4636059999465942
Trainable Parameters : 198660
Epoch 45 Train Acc 41.17647171020508% Val Acc 18.05882453918457% Train Loss 0.6604565382003784 Val Loss 1.4613999128341675
Trainable Parameters : 198660
Epoch 46 Train Acc 46.05882263183594% Val Acc 19.176469802856445% Train Loss 0.6486599445343018 Val Loss 1.4743201732635498
Trainable Parameters : 198660
Epoch 47 Train Acc 42.588233947753906% Val Acc 21.117647171020508% Train Loss 0.6510234475135803 Val Loss 1.4753111600875854
Trainable Parameters : 198660
Epoch 48 Train Acc 43.17647171020508% Val Acc 21.0% Train Loss 0.6460848450660706 Val Loss 1.4671350717544556
Trainable Parameters : 198660
Epoch 49 Train Acc 41.11764907836914% Val Acc 19.117647171020508% Train Loss 0.6472158432006836 Val Loss 1.4828177690505981
Trainable Parameters : 198660
Epoch 50 Train Acc 45.64706039428711% Val Acc 20.52941131591797% Train Loss 0.6451248526573181 Val Loss 1.476848840713501
Trainable Parameters : 198660
Epoch 51 Train Acc 46.588233947753906% Val Acc 22.52941131591797% Train Loss 0.64873868227005 Val Loss 1.4695663452148438
Trainable Parameters : 198660
Epoch 52 Train Acc 45.64706039428711% Val Acc 21.05882453918457% Train Loss 0.6452545523643494 Val Loss 1.4907280206680298
Trainable Parameters : 198660
Epoch 53 Train Acc 48.05882263183594% Val Acc 21.117647171020508% Train Loss 0.6423975825309753 Val Loss 1.495692491531372
Trainable Parameters : 198660
Epoch 54 Train Acc 45.11764907836914% Val Acc 23.117647171020508% Train Loss 0.6445842981338501 Val Loss 1.4927780628204346
Trainable Parameters : 198660
Epoch 55 Train Acc 46.11764907836914% Val Acc 20.05882453918457% Train Loss 0.6390863060951233 Val Loss 1.5086525678634644
Trainable Parameters : 198660
Epoch 56 Train Acc 45.05882263183594% Val Acc 19.705883026123047% Train Loss 0.6357616186141968 Val Loss 1.5119279623031616
Trainable Parameters : 198660
Epoch 57 Train Acc 47.05882263183594% Val Acc 21.41176414489746% Train Loss 0.6431813836097717 Val Loss 1.5050665140151978
Trainable Parameters : 198660
Epoch 58 Train Acc 48.47058868408203% Val Acc 21.58823585510254% Train Loss 0.6334322094917297 Val Loss 1.514513611793518
Trainable Parameters : 198660
Epoch 59 Train Acc 44.70588302612305% Val Acc 20.235294342041016% Train Loss 0.6377418041229248 Val Loss 1.5082379579544067
Trainable Parameters : 198660
Epoch 60 Train Acc 45.70588302612305% Val Acc 20.58823585510254% Train Loss 0.6472760438919067 Val Loss 1.5283125638961792
Trainable Parameters : 198660
Epoch 61 Train Acc 48.0% Val Acc 21.47058868408203% Train Loss 0.634850263595581 Val Loss 1.5210322141647339
Trainable Parameters : 198660
Epoch 62 Train Acc 50.0% Val Acc 18.647058486938477% Train Loss 0.6307833790779114 Val Loss 1.5225284099578857
Trainable Parameters : 198660
Epoch 63 Train Acc 45.05882263183594% Val Acc 21.117647171020508% Train Loss 0.6313076615333557 Val Loss 1.5352596044540405
Trainable Parameters : 198660
Epoch 64 Train Acc 51.882354736328125% Val Acc 24.05882453918457% Train Loss 0.6251548528671265 Val Loss 1.5220112800598145
Trainable Parameters : 198660
Epoch 65 Train Acc 44.588233947753906% Val Acc 19.647058486938477% Train Loss 0.6341255903244019 Val Loss 1.5381298065185547
Trainable Parameters : 198660
Epoch 66 Train Acc 48.52941131591797% Val Acc 19.647058486938477% Train Loss 0.6224576830863953 Val Loss 1.5648272037506104
Trainable Parameters : 198660
Epoch 67 Train Acc 49.52941131591797% Val Acc 19.52941131591797% Train Loss 0.6214470863342285 Val Loss 1.5506643056869507
Trainable Parameters : 198660
Epoch 68 Train Acc 52.11764907836914% Val Acc 19.58823585510254% Train Loss 0.6257280707359314 Val Loss 1.5545060634613037
Trainable Parameters : 198660
Epoch 69 Train Acc 48.47058868408203% Val Acc 22.176469802856445% Train Loss 0.6197423338890076 Val Loss 1.5376996994018555
Trainable Parameters : 198660
Epoch 70 Train Acc 52.52941131591797% Val Acc 21.05882453918457% Train Loss 0.6133179068565369 Val Loss 1.55739164352417
Trainable Parameters : 198660
Epoch 71 Train Acc 46.05882263183594% Val Acc 21.52941131591797% Train Loss 0.6218124032020569 Val Loss 1.5549020767211914
Trainable Parameters : 198660
Epoch 72 Train Acc 51.05882263183594% Val Acc 19.58823585510254% Train Loss 0.6235291957855225 Val Loss 1.5598803758621216
Trainable Parameters : 198660
Epoch 73 Train Acc 43.82352828979492% Val Acc 19.117647171020508% Train Loss 0.6259356737136841 Val Loss 1.5533143281936646
Trainable Parameters : 198660
Epoch 74 Train Acc 46.64706039428711% Val Acc 22.58823585510254% Train Loss 0.6287685036659241 Val Loss 1.5324182510375977
Trainable Parameters : 198660
Epoch 75 Train Acc 47.05882263183594% Val Acc 18.58823585510254% Train Loss 0.6209608316421509 Val Loss 1.5452709197998047
Trainable Parameters : 198660
Epoch 76 Train Acc 53.35293960571289% Val Acc 18.117647171020508% Train Loss 0.6077282428741455 Val Loss 1.5750967264175415
Trainable Parameters : 198660
Epoch 77 Train Acc 45.11764907836914% Val Acc 19.647058486938477% Train Loss 0.6198536157608032 Val Loss 1.5677788257598877
Trainable Parameters : 198660
Epoch 78 Train Acc 50.0% Val Acc 17.647058486938477% Train Loss 0.6021953225135803 Val Loss 1.6016954183578491
Trainable Parameters : 198660
Epoch 79 Train Acc 47.64706039428711% Val Acc 20.0% Train Loss 0.6193377375602722 Val Loss 1.5635097026824951
Trainable Parameters : 198660
Epoch 80 Train Acc 46.52941131591797% Val Acc 17.05882453918457% Train Loss 0.6025723814964294 Val Loss 1.5966160297393799
Trainable Parameters : 198660
Epoch 81 Train Acc 48.64706039428711% Val Acc 17.294116973876953% Train Loss 0.6028528213500977 Val Loss 1.5903960466384888
Trainable Parameters : 198660
Epoch 82 Train Acc 51.882354736328125% Val Acc 19.58823585510254% Train Loss 0.601525068283081 Val Loss 1.575060248374939
Trainable Parameters : 198660
Epoch 83 Train Acc 54.94117736816406% Val Acc 18.117647171020508% Train Loss 0.5999000072479248 Val Loss 1.5984221696853638
Trainable Parameters : 198660
Epoch 84 Train Acc 44.588233947753906% Val Acc 18.117647171020508% Train Loss 0.6196483373641968 Val Loss 1.6076256036758423
Trainable Parameters : 198660
Epoch 85 Train Acc 47.47058868408203% Val Acc 17.05882453918457% Train Loss 0.6125948429107666 Val Loss 1.6004250049591064
Trainable Parameters : 198660
Epoch 86 Train Acc 48.11764907836914% Val Acc 18.0% Train Loss 0.6003736853599548 Val Loss 1.5941331386566162
Trainable Parameters : 198660
Epoch 87 Train Acc 48.05882263183594% Val Acc 19.58823585510254% Train Loss 0.6117400527000427 Val Loss 1.6204349994659424
Trainable Parameters : 198660
Epoch 88 Train Acc 48.411766052246094% Val Acc 19.05882453918457% Train Loss 0.5962980389595032 Val Loss 1.6285632848739624
Trainable Parameters : 198660
Epoch 89 Train Acc 54.82352828979492% Val Acc 21.52941131591797% Train Loss 0.5837250351905823 Val Loss 1.6030375957489014
Trainable Parameters : 198660
Epoch 90 Train Acc 50.52941131591797% Val Acc 19.176469802856445% Train Loss 0.5995444059371948 Val Loss 1.6124681234359741
Trainable Parameters : 198660
Epoch 91 Train Acc 49.47058868408203% Val Acc 22.647058486938477% Train Loss 0.5949153900146484 Val Loss 1.6041094064712524
Trainable Parameters : 198660
Epoch 92 Train Acc 52.411766052246094% Val Acc 18.58823585510254% Train Loss 0.5930001735687256 Val Loss 1.6250182390213013
Trainable Parameters : 198660
Epoch 93 Train Acc 50.0% Val Acc 18.117647171020508% Train Loss 0.5964155197143555 Val Loss 1.6376616954803467
Trainable Parameters : 198660
Epoch 94 Train Acc 51.0% Val Acc 19.05882453918457% Train Loss 0.5988768339157104 Val Loss 1.6381944417953491
Trainable Parameters : 198660
Epoch 95 Train Acc 54.05882263183594% Val Acc 20.05882453918457% Train Loss 0.5744324326515198 Val Loss 1.636779546737671
Trainable Parameters : 198660
Epoch 96 Train Acc 51.35293960571289% Val Acc 19.05882453918457% Train Loss 0.5808234214782715 Val Loss 1.6424304246902466
Trainable Parameters : 198660
Epoch 97 Train Acc 51.47058868408203% Val Acc 19.58823585510254% Train Loss 0.5840481519699097 Val Loss 1.6513117551803589
Trainable Parameters : 198660
Epoch 98 Train Acc 51.882354736328125% Val Acc 18.52941131591797% Train Loss 0.5969860553741455 Val Loss 1.649971842765808
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_50f_devdata_local/wav2vec-ADI17-50-files/config.json
Model weights saved in ../output/umbrella_50f_devdata_local/wav2vec-ADI17-50-files/pytorch_model.bin
Epoch 99 Train Acc 54.882354736328125% Val Acc 19.05882453918457% Train Loss 0.5742263793945312 Val Loss 1.6748017072677612

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.24615385 0.         0.         0.        ]
 [0.25641026 0.         0.         0.        ]
 [0.25128205 0.         0.         0.        ]
 [0.24615385 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40        48
           1       0.00      0.00      0.00        50
           2       0.00      0.00      0.00        49
           3       0.00      0.00      0.00        48

    accuracy                           0.25       195
   macro avg       0.06      0.25      0.10       195
weighted avg       0.06      0.25      0.10       195


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 10/10/2022 04:30:04
