Fri Oct 14 09:08:44 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_unfreeze.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_unfreeze.py
Started: 14/10/2022 09:08:51

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-xlsr_unfreeze
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 2
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 24
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-xlsr_unfreeze
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-xlsr_unfreeze_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.0548,  0.0370,  0.0237,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0067,  0.0947,  0.0259,  ...,  0.0000,  0.0000,  0.0000],
        [-0.5320, -0.1354, -0.4098,  ..., -0.0109, -0.0351, -0.1135],
        ...,
        [ 2.1417,  1.8671,  1.5625,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3712, -0.3310, -0.7927,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0813,  0.0588, -0.0084,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 1, 2, 0, 1, 2, 0, 3, 2, 0, 3, 2, 1, 0, 3, 1, 2, 2, 2, 3, 2, 3, 1])}
Training DataCustom Files: 1963
Training Data Files: 82
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.3648, -0.4012, -0.4619,  ...,  1.5256,  1.3818,  1.2115],
        [-0.0126, -0.0077, -0.1224,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0435,  0.0412,  0.0645,  ..., -1.9810, -2.0289, -1.9405],
        ...,
        [ 0.2824,  0.3876,  0.5103,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3625,  0.3642,  0.3509,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0855, -0.3353, -0.2214,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 2, 0, 3, 3, 3, 3, 0, 1, 0, 0, 0, 0, 2, 2, 3, 2, 1, 2, 0, 1, 2, 2])}
Test CustomData Files: 1997
Test Data Files: 84
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
Traceback (most recent call last):
  File "run_xlsr_unfreeze.py", line 489, in <module>
    for param in model.wav2vec2.encoder.layers[i].parameters():
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1185, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'DataParallel' object has no attribute 'wav2vec2'
Fri Oct 14 09:18:23 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_unfreeze.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_unfreeze.py
Started: 14/10/2022 09:18:28

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-xlsr_unfreeze
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 2
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 24
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-xlsr_unfreeze
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-xlsr_unfreeze_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-1.2788, -1.5465, -1.2889,  ...,  0.4713,  0.5452,  0.6300],
        [-0.0250, -0.0123, -0.0023,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0757, -0.0487, -0.0189,  ...,  1.7278,  1.6927,  1.3724],
        ...,
        [ 1.1206,  1.3413,  1.5873,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0377, -0.0106,  0.0270,  ...,  0.0000,  0.0000,  0.0000],
        [-0.9508, -0.7034, -0.4974,  ...,  0.2884,  0.3976,  0.4751]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 2, 2, 1, 3, 3, 0, 0, 3, 0, 3, 1, 3, 2, 1, 3, 0, 0, 2, 2, 1, 1, 3, 3])}
Training DataCustom Files: 1963
Training Data Files: 82
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.bias', 'projector.bias', 'projector.weight', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.4482, -0.5700, -0.6391,  ...,  0.1453, -0.3222, -0.3616],
        [-0.0393, -0.0419, -0.0437,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0195, -0.0325, -0.0445,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.7462,  0.7623,  0.7219,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.5507, -0.4395, -1.2716,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2580,  0.4882,  0.6497,  ...,  0.7428,  0.3031, -0.0239]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 3, 3, 2, 2, 1, 0, 1, 0, 3, 3, 1, 3, 1, 1, 1, 1, 1, 0, 2, 3, 2, 2, 1])}
Test CustomData Files: 1997
Test Data Files: 84
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 0 Train Acc 25.86585235595703% Val Acc 28.0% Train Loss 0.6930496096611023 Val Loss 1.3860976696014404
EPOCH unfeeze : 1
Trainable Parameters : 151419140
