Sun Nov 6 12:57:57 AEDT 2022
2022-11-06 12:58:00.072787: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-06 12:58:00.500674: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-06 12:58:00.634440: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-06 12:58:02.629721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-06 12:58:02.631364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-06 12:58:02.631376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_unfreezestep75.py
Started: 06/11/2022 12:58:18

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-araic-unfreeze-step75
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 75
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step75
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step75_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.1510,  0.1391,  0.1228,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0354,  0.0343,  0.0301,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2006,  0.0058,  0.1052,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.2048, -0.2403, -0.2145,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6167, -0.6727, -0.6862,  ..., -0.9480, -0.9839, -0.8879],
        [ 0.0271,  0.0281,  0.0530,  ...,  1.9312,  1.4804,  0.7022]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 2, 3, 2, 2, 0, 1, 3, 3, 1, 3, 0, 2, 0, 3, 0, 3, 1, 1, 1, 2, 2, 3, 2,
        2, 3, 3, 2, 2, 3, 0, 1, 2, 2, 0, 2, 1, 3, 0, 0])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[ 0.5489, -0.0541, -0.3617,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.6716,  1.0834,  0.6854,  ...,  0.0000,  0.0000,  0.0000],
        [-0.4294, -0.4822, -0.6599,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.9666, -0.8888, -0.8663,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.5272,  0.3530,  0.2039,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1508,  0.2175,  0.2246,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 0, 2, 3, 0, 3, 1, 1, 1, 2, 1, 3, 3, 2, 0, 3, 0, 1, 1, 3, 3, 1, 0,
        1, 2, 1, 2, 2, 2, 0, 3, 2, 1, 0, 0, 2, 1, 2, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'classifier.bias', 'projector.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.8915, -0.7216,  0.5245,  ...,  0.2021,  0.1842,  0.1600],
        [ 0.1736,  0.2113,  0.1601,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0677, -0.0702, -0.0585,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0073, -0.0065,  0.0042,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3832,  0.7052,  0.6135,  ..., -0.1732, -0.2441, -0.2638],
        [ 2.1312, -0.1947,  0.3136,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 2, 1, 2, 3, 3, 1, 1, 3, 2, 1, 0, 3, 2, 3, 1, 3, 3, 3, 0, 0, 2, 1,
        2, 0, 0, 1, 0, 0, 3, 0, 3, 0, 3, 3, 0, 2, 0, 0])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 0 Train Acc 34.31178665161133% Val Acc 25.5% Train Loss 0.6694324016571045 Val Loss 1.4396188259124756
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 1 Train Acc 47.916351318359375% Val Acc 38.400001525878906% Train Loss 0.5970561504364014 Val Loss 1.3911031484603882
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 2 Train Acc 61.35361099243164% Val Acc 54.29999923706055% Train Loss 0.48357439041137695 Val Loss 1.1072804927825928
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 3 Train Acc 72.2509536743164% Val Acc 59.0% Train Loss 0.3691859543323517 Val Loss 1.0386995077133179
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 4 Train Acc 78.39543914794922% Val Acc 63.29999923706055% Train Loss 0.290507048368454 Val Loss 1.0390914678573608
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 5 Train Acc 82.93916320800781% Val Acc 69.20000457763672% Train Loss 0.2318446785211563 Val Loss 0.8180449604988098
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 6 Train Acc 87.49810028076172% Val Acc 67.5% Train Loss 0.17675352096557617 Val Loss 1.0409740209579468
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 7 Train Acc 89.54753112792969% Val Acc 66.4000015258789% Train Loss 0.14410048723220825 Val Loss 1.1308568716049194
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 8 Train Acc 92.09505462646484% Val Acc 65.5999984741211% Train Loss 0.11345497518777847 Val Loss 1.3308604955673218
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 9 Train Acc 93.6615982055664% Val Acc 68.4000015258789% Train Loss 0.09424149990081787 Val Loss 1.211739420890808
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 10 Train Acc 94.21292877197266% Val Acc 71.0999984741211% Train Loss 0.08080212026834488 Val Loss 1.1973131895065308
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 11 Train Acc 94.88212585449219% Val Acc 70.9000015258789% Train Loss 0.0771125927567482 Val Loss 1.252576231956482
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 12 Train Acc 95.23194122314453% Val Acc 69.5999984741211% Train Loss 0.07032758742570877 Val Loss 1.3336451053619385
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 13 Train Acc 95.11786651611328% Val Acc 76.4000015258789% Train Loss 0.0724576786160469 Val Loss 1.0279685258865356
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 14 Train Acc 95.18251037597656% Val Acc 73.80000305175781% Train Loss 0.07081841677427292 Val Loss 1.1021493673324585
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 15 Train Acc 95.72623443603516% Val Acc 71.0999984741211% Train Loss 0.06385045498609543 Val Loss 1.1777628660202026
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 16 Train Acc 96.00379943847656% Val Acc 69.20000457763672% Train Loss 0.06119987741112709 Val Loss 1.3680434226989746
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 17 Train Acc 95.5171127319336% Val Acc 72.5999984741211% Train Loss 0.06757654249668121 Val Loss 1.1928671598434448
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 18 Train Acc 95.93536376953125% Val Acc 68.20000457763672% Train Loss 0.061820048838853836 Val Loss 1.3579844236373901
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 19 Train Acc 95.6197738647461% Val Acc 66.80000305175781% Train Loss 0.06673239916563034 Val Loss 1.7307319641113281
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 20 Train Acc 95.74524688720703% Val Acc 73.20000457763672% Train Loss 0.06617645174264908 Val Loss 1.3275882005691528
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 21 Train Acc 95.26995849609375% Val Acc 67.9000015258789% Train Loss 0.07205501198768616 Val Loss 1.329649567604065
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 22 Train Acc 95.9277572631836% Val Acc 72.9000015258789% Train Loss 0.05956790968775749 Val Loss 1.0522091388702393
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 23 Train Acc 95.49049377441406% Val Acc 68.30000305175781% Train Loss 0.06686202436685562 Val Loss 1.6077269315719604
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 24 Train Acc 95.17870330810547% Val Acc 61.5% Train Loss 0.06793142110109329 Val Loss 1.9160864353179932
EPOCH unfeeze : 25
Trainable Parameters : 151419140
Epoch 25 Train Acc 95.87832641601562% Val Acc 69.70000457763672% Train Loss 0.06225959211587906 Val Loss 1.2792232036590576
EPOCH unfeeze : 26
Trainable Parameters : 151419140
Epoch 26 Train Acc 94.43726348876953% Val Acc 66.5% Train Loss 0.07979952543973923 Val Loss 1.33144211769104
EPOCH unfeeze : 27
Trainable Parameters : 151419140
Epoch 27 Train Acc 95.26235961914062% Val Acc 61.0% Train Loss 0.07102952152490616 Val Loss 1.5070246458053589
EPOCH unfeeze : 28
Trainable Parameters : 151419140
Epoch 28 Train Acc 95.50569915771484% Val Acc 66.80000305175781% Train Loss 0.06717316806316376 Val Loss 1.3068571090698242
EPOCH unfeeze : 29
Trainable Parameters : 151419140
Epoch 29 Train Acc 95.57794952392578% Val Acc 67.9000015258789% Train Loss 0.06862564384937286 Val Loss 1.300854206085205
EPOCH unfeeze : 30
Trainable Parameters : 151419140
Epoch 30 Train Acc 94.81369018554688% Val Acc 68.70000457763672% Train Loss 0.07710880041122437 Val Loss 1.242729663848877
EPOCH unfeeze : 31
Trainable Parameters : 151419140
Epoch 31 Train Acc 94.98478698730469% Val Acc 64.5999984741211% Train Loss 0.07638620585203171 Val Loss 1.8358625173568726
EPOCH unfeeze : 32
Trainable Parameters : 151419140
Epoch 32 Train Acc 95.15589141845703% Val Acc 74.4000015258789% Train Loss 0.07628036290407181 Val Loss 1.103422999382019
EPOCH unfeeze : 33
Trainable Parameters : 151419140
Epoch 33 Train Acc 94.47908782958984% Val Acc 66.5999984741211% Train Loss 0.07870577275753021 Val Loss 1.2551969289779663
EPOCH unfeeze : 34
Trainable Parameters : 151419140
Epoch 34 Train Acc 94.24714660644531% Val Acc 70.5999984741211% Train Loss 0.081314317882061 Val Loss 1.0964634418487549
EPOCH unfeeze : 35
Trainable Parameters : 151419140
Epoch 35 Train Acc 95.50569915771484% Val Acc 68.30000305175781% Train Loss 0.06923295557498932 Val Loss 1.592050552368164
EPOCH unfeeze : 36
Trainable Parameters : 151419140
Epoch 36 Train Acc 94.14448547363281% Val Acc 66.0999984741211% Train Loss 0.08945979177951813 Val Loss 1.3565740585327148
EPOCH unfeeze : 37
Trainable Parameters : 151419140
Epoch 37 Train Acc 94.20152282714844% Val Acc 71.70000457763672% Train Loss 0.08576797693967819 Val Loss 1.0296571254730225
EPOCH unfeeze : 38
Trainable Parameters : 151419140
Epoch 38 Train Acc 93.6463851928711% Val Acc 61.400001525878906% Train Loss 0.08972373604774475 Val Loss 1.4905859231948853
EPOCH unfeeze : 39
Trainable Parameters : 151419140
Epoch 39 Train Acc 93.56653594970703% Val Acc 65.20000457763672% Train Loss 0.09144371002912521 Val Loss 1.5318790674209595
EPOCH unfeeze : 40
Trainable Parameters : 151419140
Epoch 40 Train Acc 95.65779113769531% Val Acc 73.5% Train Loss 0.06311413645744324 Val Loss 1.0829648971557617
EPOCH unfeeze : 41
Trainable Parameters : 151419140
Epoch 41 Train Acc 95.14448547363281% Val Acc 64.30000305175781% Train Loss 0.06987310200929642 Val Loss 1.404339075088501
EPOCH unfeeze : 42
Trainable Parameters : 151419140
Epoch 42 Train Acc 95.46007537841797% Val Acc 70.80000305175781% Train Loss 0.06618201732635498 Val Loss 1.190975308418274
EPOCH unfeeze : 43
Trainable Parameters : 151419140
Epoch 43 Train Acc 95.98859405517578% Val Acc 68.9000015258789% Train Loss 0.0582008920609951 Val Loss 1.474220871925354
EPOCH unfeeze : 44
Trainable Parameters : 151419140
Epoch 44 Train Acc 95.86311340332031% Val Acc 67.0% Train Loss 0.05954565852880478 Val Loss 1.3831090927124023
EPOCH unfeeze : 45
Trainable Parameters : 151419140
Epoch 45 Train Acc 96.39543914794922% Val Acc 73.5% Train Loss 0.05444508418440819 Val Loss 1.1402519941329956
EPOCH unfeeze : 46
Trainable Parameters : 151419140
Epoch 46 Train Acc 96.47148132324219% Val Acc 62.29999923706055% Train Loss 0.053077928721904755 Val Loss 1.7495596408843994
EPOCH unfeeze : 47
Trainable Parameters : 151419140
Epoch 47 Train Acc 96.76805877685547% Val Acc 70.20000457763672% Train Loss 0.050434719771146774 Val Loss 1.4162733554840088
EPOCH unfeeze : 48
Trainable Parameters : 151419140
Epoch 48 Train Acc 96.83270263671875% Val Acc 65.30000305175781% Train Loss 0.04743821173906326 Val Loss 1.7367565631866455
EPOCH unfeeze : 49
Trainable Parameters : 151419140
Epoch 49 Train Acc 96.70342254638672% Val Acc 68.0999984741211% Train Loss 0.046747125685214996 Val Loss 1.4545453786849976
EPOCH unfeeze : 50
Trainable Parameters : 151419140
Epoch 50 Train Acc 97.49810028076172% Val Acc 66.0% Train Loss 0.03981362283229828 Val Loss 1.5734314918518066
EPOCH unfeeze : 51
Trainable Parameters : 151419140
Epoch 51 Train Acc 97.31178283691406% Val Acc 65.80000305175781% Train Loss 0.040751319378614426 Val Loss 1.9840878248214722
EPOCH unfeeze : 52
Trainable Parameters : 151419140
Epoch 52 Train Acc 96.66919708251953% Val Acc 67.80000305175781% Train Loss 0.048215679824352264 Val Loss 1.4513787031173706
EPOCH unfeeze : 53
Trainable Parameters : 151419140
Epoch 53 Train Acc 97.42205047607422% Val Acc 74.5999984741211% Train Loss 0.04149264097213745 Val Loss 1.1859779357910156
EPOCH unfeeze : 54
Trainable Parameters : 151419140
Epoch 54 Train Acc 96.98478698730469% Val Acc 66.9000015258789% Train Loss 0.04440104961395264 Val Loss 1.718149185180664
EPOCH unfeeze : 55
Trainable Parameters : 151419140
Epoch 55 Train Acc 97.8212890625% Val Acc 69.5999984741211% Train Loss 0.03567470237612724 Val Loss 1.5601426362991333
EPOCH unfeeze : 56
Trainable Parameters : 151419140
Epoch 56 Train Acc 97.26995849609375% Val Acc 65.70000457763672% Train Loss 0.04240157827734947 Val Loss 1.833563208580017
EPOCH unfeeze : 57
Trainable Parameters : 151419140
Epoch 57 Train Acc 97.6197738647461% Val Acc 68.80000305175781% Train Loss 0.03688068687915802 Val Loss 1.4093886613845825
EPOCH unfeeze : 58
Trainable Parameters : 151419140
Epoch 58 Train Acc 97.77566528320312% Val Acc 70.0999984741211% Train Loss 0.035295404493808746 Val Loss 1.2939515113830566
EPOCH unfeeze : 59
Trainable Parameters : 151419140
Epoch 59 Train Acc 97.9277572631836% Val Acc 71.80000305175781% Train Loss 0.03207307681441307 Val Loss 1.5011128187179565
EPOCH unfeeze : 60
Trainable Parameters : 151419140
Epoch 60 Train Acc 97.49810028076172% Val Acc 66.70000457763672% Train Loss 0.03784388676285744 Val Loss 1.8227564096450806
EPOCH unfeeze : 61
Trainable Parameters : 151419140
Epoch 61 Train Acc 97.55133056640625% Val Acc 64.5999984741211% Train Loss 0.03576826676726341 Val Loss 1.943276286125183
EPOCH unfeeze : 62
Trainable Parameters : 151419140
Epoch 62 Train Acc 98.12167358398438% Val Acc 67.30000305175781% Train Loss 0.02969912439584732 Val Loss 1.5246397256851196
EPOCH unfeeze : 63
Trainable Parameters : 151419140
Epoch 63 Train Acc 98.384033203125% Val Acc 74.5999984741211% Train Loss 0.026663528755307198 Val Loss 1.5429346561431885
EPOCH unfeeze : 64
Trainable Parameters : 151419140
Epoch 64 Train Acc 98.15589141845703% Val Acc 69.9000015258789% Train Loss 0.02850111573934555 Val Loss 1.836747407913208
EPOCH unfeeze : 65
Trainable Parameters : 151419140
Epoch 65 Train Acc 97.76045227050781% Val Acc 75.4000015258789% Train Loss 0.03295036777853966 Val Loss 1.237903356552124
EPOCH unfeeze : 66
Trainable Parameters : 151419140
Epoch 66 Train Acc 98.11026763916016% Val Acc 63.60000228881836% Train Loss 0.030102001503109932 Val Loss 2.325122117996216
EPOCH unfeeze : 67
Trainable Parameters : 151419140
Epoch 67 Train Acc 98.5855484008789% Val Acc 74.80000305175781% Train Loss 0.023672256618738174 Val Loss 1.6119903326034546
EPOCH unfeeze : 68
Trainable Parameters : 151419140
Epoch 68 Train Acc 98.4410629272461% Val Acc 69.70000457763672% Train Loss 0.024294225499033928 Val Loss 1.5721515417099
EPOCH unfeeze : 69
Trainable Parameters : 151419140
Epoch 69 Train Acc 98.22433471679688% Val Acc 69.5% Train Loss 0.027741476893424988 Val Loss 1.875162124633789
EPOCH unfeeze : 70
Trainable Parameters : 151419140
Epoch 70 Train Acc 98.30418395996094% Val Acc 63.79999923706055% Train Loss 0.027113234624266624 Val Loss 2.5179567337036133
EPOCH unfeeze : 71
Trainable Parameters : 151419140
Epoch 71 Train Acc 98.19011688232422% Val Acc 66.0999984741211% Train Loss 0.028398271650075912 Val Loss 1.8818339109420776
EPOCH unfeeze : 72
Trainable Parameters : 151419140
Epoch 72 Train Acc 98.47148132324219% Val Acc 69.70000457763672% Train Loss 0.02513929083943367 Val Loss 1.4948772192001343
EPOCH unfeeze : 73
Trainable Parameters : 151419140
Epoch 73 Train Acc 98.7490463256836% Val Acc 74.0999984741211% Train Loss 0.02108622156083584 Val Loss 1.416704535484314
EPOCH unfeeze : 74
Trainable Parameters : 151419140
Epoch 74 Train Acc 98.6882095336914% Val Acc 64.5% Train Loss 0.020771954208612442 Val Loss 2.120758056640625
EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 75 Train Acc 98.29277801513672% Val Acc 70.70000457763672% Train Loss 0.025580989196896553 Val Loss 1.6196365356445312
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 76 Train Acc 98.46768188476562% Val Acc 70.4000015258789% Train Loss 0.023359889164566994 Val Loss 1.916486144065857
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 77 Train Acc 98.54753112792969% Val Acc 68.0999984741211% Train Loss 0.021780461072921753 Val Loss 1.7958914041519165
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 78 Train Acc 98.6463851928711% Val Acc 69.20000457763672% Train Loss 0.02322983182966709 Val Loss 1.9629849195480347
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 79 Train Acc 98.8669204711914% Val Acc 67.4000015258789% Train Loss 0.017583835870027542 Val Loss 2.195833921432495
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 80 Train Acc 98.74144744873047% Val Acc 68.30000305175781% Train Loss 0.021055396646261215 Val Loss 1.9407180547714233
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 81 Train Acc 98.90113830566406% Val Acc 73.0% Train Loss 0.018214277923107147 Val Loss 1.507169246673584
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 82 Train Acc 98.7490463256836% Val Acc 72.5% Train Loss 0.020927565172314644 Val Loss 1.6242035627365112
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 83 Train Acc 98.92015075683594% Val Acc 70.80000305175781% Train Loss 0.017335467040538788 Val Loss 1.8005465269088745
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 84 Train Acc 98.88973236083984% Val Acc 70.30000305175781% Train Loss 0.018196169286966324 Val Loss 1.5884865522384644
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 85 Train Acc 98.62357330322266% Val Acc 69.9000015258789% Train Loss 0.021476158872246742 Val Loss 2.053567886352539
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 86 Train Acc 98.69581604003906% Val Acc 65.0999984741211% Train Loss 0.02177400141954422 Val Loss 2.535428047180176
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 87 Train Acc 98.95056915283203% Val Acc 74.0% Train Loss 0.0158200915902853 Val Loss 1.7449311017990112
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 88 Train Acc 98.97718811035156% Val Acc 68.4000015258789% Train Loss 0.018628520891070366 Val Loss 2.2258987426757812
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 89 Train Acc 98.95056915283203% Val Acc 66.0999984741211% Train Loss 0.01544042956084013 Val Loss 2.4353229999542236
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 90 Train Acc 98.8935317993164% Val Acc 70.4000015258789% Train Loss 0.016763631254434586 Val Loss 2.5431125164031982
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 91 Train Acc 98.9695816040039% Val Acc 65.0% Train Loss 0.017544569447636604 Val Loss 2.488410711288452
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 92 Train Acc 99.06463623046875% Val Acc 71.70000457763672% Train Loss 0.014317415654659271 Val Loss 2.039989948272705
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 93 Train Acc 99.07984924316406% Val Acc 64.20000457763672% Train Loss 0.014717326499521732 Val Loss 2.277033567428589
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 94 Train Acc 98.98098754882812% Val Acc 68.30000305175781% Train Loss 0.015746450051665306 Val Loss 2.5287692546844482
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 95 Train Acc 98.91635131835938% Val Acc 69.70000457763672% Train Loss 0.016405398026108742 Val Loss 2.0697519779205322
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 96 Train Acc 99.06083679199219% Val Acc 71.4000015258789% Train Loss 0.015038098208606243 Val Loss 1.7999908924102783
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 97 Train Acc 99.20912170410156% Val Acc 71.20000457763672% Train Loss 0.013718727044761181 Val Loss 1.8953176736831665
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 98 Train Acc 99.09125518798828% Val Acc 66.9000015258789% Train Loss 0.014777353964745998 Val Loss 2.247178077697754
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Configuration saved in /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step75/config.json
Model weights saved in /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step75/pytorch_model.bin
Epoch 99 Train Acc 99.09125518798828% Val Acc 67.0999984741211% Train Loss 0.015035043470561504 Val Loss 2.166036605834961

------> EVALUATING MODEL... ------------------------------------------ 

Final Test Acc:76.5999984741211% Loss:1.462388038635254
CONFUSION MATRIX
[[78  5  8  9]
 [ 7 49 24 20]
 [ 5  3 87  3]
 [ 0  1  8 91]]
CONFUSION MATRIX NORMALISED
[[0.1959799  0.01256281 0.0201005  0.02261307]
 [0.01758794 0.12311558 0.06030151 0.05025126]
 [0.01256281 0.00753769 0.21859296 0.00753769]
 [0.         0.00251256 0.0201005  0.22864322]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.87      0.78      0.82       100
           1       0.84      0.49      0.62       100
           2       0.69      0.89      0.77        98
           3       0.74      0.91      0.82       100

    accuracy                           0.77       398
   macro avg       0.78      0.77      0.76       398
weighted avg       0.78      0.77      0.76       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 07/11/2022 00:41:18
