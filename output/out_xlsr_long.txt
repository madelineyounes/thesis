Wed Nov 2 14:13:59 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_long.py
Started: 02/11/2022 14:14:16

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-long
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_20s
train_filename: u_train_20s
validation_filename: dev_u_20s
evaluation_filename: test_u_20s
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 20
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_20s.csv
--> data_test_fp: data/dev_u_20s.csv
--> data_test_fp: data/test_u_20s.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_20s_local/ADI17-xlsr-long
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_20s_local/ADI17-xlsr-long_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 20 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Traceback (most recent call last):
  File "run_xlsr_long.py", line 378, in <module>
    traincustomdata = CustomDataset(
  File "/home/z5208494/thesis/customData.py", line 35, in __init__
    self.data_frame = pd.read_csv(csv_fp, delimiter=',')
  File "/apps/python/3.8.3/lib/python3.8/site-packages/pandas/io/parsers.py", line 676, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/pandas/io/parsers.py", line 448, in _read
    parser = TextFileReader(fp_or_buf, **kwds)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/pandas/io/parsers.py", line 880, in __init__
    self._make_engine(self.engine)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/pandas/io/parsers.py", line 1114, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/apps/python/3.8.3/lib/python3.8/site-packages/pandas/io/parsers.py", line 1891, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 374, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 674, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File data/u_train_20s.csv does not exist: 'data/u_train_20s.csv'
Wed Nov 2 18:35:10 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_long.py
Started: 02/11/2022 18:35:25

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-long
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: train_u_20s
train_filename: train_u_20s
validation_filename: dev_u_20s
evaluation_filename: test_u_20s
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 20
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/train_u_20s.csv
--> data_test_fp: data/dev_u_20s.csv
--> data_test_fp: data/test_u_20s.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/train_u_20s_local/ADI17-xlsr-long
--> finetuned_results_fp: /srv/scratch/z5208494/output/train_u_20s_local/ADI17-xlsr-long_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 20 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.3608, -0.7283, -1.1966,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1225,  0.0068,  0.0798,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1327,  0.3970,  0.7349,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-1.3413, -1.4013, -1.4236,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.2019,  1.0228,  0.0563,  ..., -0.1448,  0.1240,  0.3632],
        [ 0.0430,  0.0747,  0.1156,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 0, 3, 2, 3, 0, 0, 0, 2, 3, 0, 0, 0, 0, 3, 3, 2, 3, 2])}
Training DataCustom Files: 1672
Training Data Files: 84
Val Data Sample
{'input_values': tensor([[-1.1459, -1.1981, -1.0901,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0248,  0.0585, -0.0062,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0619, -0.9571, -0.6860,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.1015,  0.1309,  0.1427,  ...,  0.4373,  0.3975,  0.3289],
        [-0.6854, -0.8083, -0.7074,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0602,  0.0648,  0.0273,  ..., -1.6031, -1.6094, -1.5167]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 0, 2, 1, 2, 3, 3, 3, 2, 3, 0, 0, 2, 0, 3, 1, 2, 3, 3, 3])}
Test CustomData Files: 1673
Test Data Files: 84
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.bias', 'projector.bias', 'projector.weight', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.0224, -0.0312, -0.0298,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0042,  0.0069,  0.0060,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0873,  0.0093, -0.6172,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0073, -0.0498, -0.0481,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3716,  0.3142,  0.1191,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0718,  0.0700,  0.0723,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 2, 1, 3, 2, 2, 2, 2, 0, 2, 3, 0, 3, 1, 3, 2, 3, 2, 3])}
Test CustomData Files: 1922
Test Data Files: 97
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_long.py", line 721, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_long.py", line 546, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_long.py", line 566, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_long.py", line 609, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 710, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 576, in forward
    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))
RuntimeError: CUDA out of memory. Tried to allocate 428.00 MiB (GPU 0; 31.75 GiB total capacity; 29.79 GiB already allocated; 288.00 MiB free; 30.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Thu Nov 3 02:05:52 AEDT 2022
2022-11-03 02:05:54.766013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-03 02:05:55.144083: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-03 02:05:55.274349: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-03 02:05:56.834396: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-03 02:05:56.835933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-03 02:05:56.835944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_long.py
Started: 03/11/2022 02:06:09

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-long
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: train_u_20s
train_filename: train_u_20s
validation_filename: dev_u_20s
evaluation_filename: test_u_20s
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 4
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/train_u_20s.csv
--> data_test_fp: data/dev_u_20s.csv
--> data_test_fp: data/test_u_20s.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/train_u_20s_local/ADI17-xlsr-long
--> finetuned_results_fp: /srv/scratch/z5208494/output/train_u_20s_local/ADI17-xlsr-long_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 20 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.1027,  0.0870,  0.1135,  ...,  0.0000,  0.0000,  0.0000],
        [ 2.5514,  2.4940,  2.5785,  ...,  0.0000,  0.0000,  0.0000],
        [-0.4966, -0.5530, -0.5977,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3182, -0.4891,  0.2779,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 2, 2])}
Training DataCustom Files: 1672
Training Data Files: 418
Val Data Sample
{'input_values': tensor([[-7.3629e-01, -7.0874e-01, -4.6190e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.7182e+00, -2.4852e+00, -2.2185e+00,  ..., -3.3473e-03,
         -5.0222e-02, -2.0222e-02],
        [ 2.4465e+00,  2.2388e+00,  2.2608e+00,  ..., -5.1469e-02,
         -2.3497e-02,  2.0559e-02],
        [ 4.7295e+00,  4.9069e+00,  3.9104e+00,  ..., -5.7564e-01,
         -5.1669e-01, -4.7546e-01]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 3, 1, 3])}
Test CustomData Files: 1673
Test Data Files: 419
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'projector.bias', 'classifier.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-0.4492, -0.3647, -0.2968,  ...,  0.0000,  0.0000,  0.0000],
        [-0.4380, -0.4528, -0.3049,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0149, -0.0183, -0.0506,  ...,  0.0000,  0.0000,  0.0000],
        [ 3.5872,  3.5487,  3.2981,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 1, 1])}
Test CustomData Files: 1922
Test Data Files: 481
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  4 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 28.05023765563965% Val Acc 25.727651596069336% Train Loss 0.6926565170288086 Val Loss 1.1951181888580322
Trainable Parameters : 264452
Epoch 1 Train Acc 30.26315689086914% Val Acc 25.831600189208984% Train Loss 0.687592625617981 Val Loss 1.1909500360488892
Trainable Parameters : 264452
Epoch 2 Train Acc 32.3564567565918% Val Acc 25.831600189208984% Train Loss 0.68061363697052 Val Loss 1.1785295009613037
Trainable Parameters : 264452
Epoch 3 Train Acc 35.40669631958008% Val Acc 29.93762969970703% Train Loss 0.6701061129570007 Val Loss 1.1568182706832886
Trainable Parameters : 264452
Epoch 4 Train Acc 37.97846603393555% Val Acc 30.041580200195312% Train Loss 0.6603235006332397 Val Loss 1.1474181413650513
Trainable Parameters : 264452
Epoch 5 Train Acc 41.68659973144531% Val Acc 35.55093765258789% Train Loss 0.6445223689079285 Val Loss 1.1340328454971313
Trainable Parameters : 264452
Epoch 6 Train Acc 44.97607421875% Val Acc 34.30353546142578% Train Loss 0.6299849152565002 Val Loss 1.1221061944961548
Trainable Parameters : 264452
Epoch 7 Train Acc 47.787078857421875% Val Acc 39.916839599609375% Train Loss 0.6156458258628845 Val Loss 1.0702803134918213
Trainable Parameters : 264452
Epoch 8 Train Acc 50.71770095825195% Val Acc 45.27027130126953% Train Loss 0.5935149788856506 Val Loss 1.0310392379760742
Trainable Parameters : 264452
Epoch 9 Train Acc 51.614830017089844% Val Acc 40.74843978881836% Train Loss 0.579957902431488 Val Loss 1.082033395767212
Trainable Parameters : 264452
Epoch 10 Train Acc 51.79425811767578% Val Acc 44.854469299316406% Train Loss 0.5686532258987427 Val Loss 0.9958981871604919
Trainable Parameters : 264452
Epoch 11 Train Acc 52.93061828613281% Val Acc 44.646568298339844% Train Loss 0.5551490783691406 Val Loss 0.9674319624900818
Trainable Parameters : 264452
Epoch 12 Train Acc 54.964111328125% Val Acc 47.97297286987305% Train Loss 0.5389673709869385 Val Loss 0.9427022337913513
Trainable Parameters : 264452
Epoch 13 Train Acc 54.665069580078125% Val Acc 49.636173248291016% Train Loss 0.5339860320091248 Val Loss 0.9064825773239136
Trainable Parameters : 264452
Epoch 14 Train Acc 56.3397102355957% Val Acc 50.467777252197266% Train Loss 0.529074490070343 Val Loss 0.902368426322937
Trainable Parameters : 264452
Epoch 15 Train Acc 57.11722183227539% Val Acc 48.44075012207031% Train Loss 0.5245485305786133 Val Loss 0.9091031551361084
Trainable Parameters : 264452
Epoch 16 Train Acc 55.80143356323242% Val Acc 44.5945930480957% Train Loss 0.5153454542160034 Val Loss 0.9758546352386475
Trainable Parameters : 264452
Epoch 17 Train Acc 57.05741500854492% Val Acc 46.30977249145508% Train Loss 0.5144278407096863 Val Loss 0.9159561395645142
Trainable Parameters : 264452
Epoch 18 Train Acc 56.459327697753906% Val Acc 47.765071868896484% Train Loss 0.5089755654335022 Val Loss 0.9485020041465759
Trainable Parameters : 264452
Epoch 19 Train Acc 58.6124382019043% Val Acc 51.55925369262695% Train Loss 0.5062368512153625 Val Loss 0.9274082779884338
Trainable Parameters : 264452
Epoch 20 Train Acc 58.433013916015625% Val Acc 49.636173248291016% Train Loss 0.5034613609313965 Val Loss 0.8944953083992004
Trainable Parameters : 264452
Epoch 21 Train Acc 58.971290588378906% Val Acc 49.688148498535156% Train Loss 0.4943324327468872 Val Loss 0.9022756218910217
Trainable Parameters : 264452
Epoch 22 Train Acc 59.80860900878906% Val Acc 47.97297286987305% Train Loss 0.49037909507751465 Val Loss 0.9475878477096558
Trainable Parameters : 264452
Epoch 23 Train Acc 61.1244010925293% Val Acc 50.67567443847656% Train Loss 0.48724111914634705 Val Loss 0.8795545697212219
Trainable Parameters : 264452
Epoch 24 Train Acc 59.569374084472656% Val Acc 53.7941780090332% Train Loss 0.4909699857234955 Val Loss 0.8244097828865051
Trainable Parameters : 264452
Epoch 25 Train Acc 61.96171951293945% Val Acc 46.621620178222656% Train Loss 0.4801855981349945 Val Loss 1.0157190561294556
Trainable Parameters : 264452
Epoch 26 Train Acc 62.260765075683594% Val Acc 54.46985626220703% Train Loss 0.47223135828971863 Val Loss 0.8085038661956787
Trainable Parameters : 264452
Epoch 27 Train Acc 62.97846603393555% Val Acc 53.3264045715332% Train Loss 0.46052658557891846 Val Loss 0.793622612953186
Trainable Parameters : 264452
Epoch 28 Train Acc 60.76554870605469% Val Acc 50.311851501464844% Train Loss 0.4681090712547302 Val Loss 0.8811772465705872
Trainable Parameters : 264452
Epoch 29 Train Acc 62.67942428588867% Val Acc 49.37630081176758% Train Loss 0.46107202768325806 Val Loss 0.8729844689369202
Trainable Parameters : 264452
Epoch 30 Train Acc 64.05502319335938% Val Acc 50.779624938964844% Train Loss 0.45548614859580994 Val Loss 0.9015523195266724
Trainable Parameters : 264452
Epoch 31 Train Acc 63.09808349609375% Val Acc 47.401248931884766% Train Loss 0.4565609395503998 Val Loss 1.020504355430603
Trainable Parameters : 264452
Epoch 32 Train Acc 64.11483001708984% Val Acc 49.79209899902344% Train Loss 0.4499656558036804 Val Loss 0.8760903477668762
Trainable Parameters : 264452
Epoch 33 Train Acc 64.65310668945312% Val Acc 56.18503189086914% Train Loss 0.43710970878601074 Val Loss 0.7377370595932007
Trainable Parameters : 264452
Epoch 34 Train Acc 64.7129135131836% Val Acc 55.04158020019531% Train Loss 0.4423968493938446 Val Loss 0.7904730439186096
Trainable Parameters : 264452
Epoch 35 Train Acc 62.61961364746094% Val Acc 57.43243408203125% Train Loss 0.44883447885513306 Val Loss 0.7341307401657104
Trainable Parameters : 264452
Epoch 36 Train Acc 64.17463684082031% Val Acc 53.534305572509766% Train Loss 0.4335300624370575 Val Loss 0.9044243097305298
Trainable Parameters : 264452
Epoch 37 Train Acc 68.18181610107422% Val Acc 49.220375061035156% Train Loss 0.4253656566143036 Val Loss 0.9152414202690125
Trainable Parameters : 264452
Epoch 38 Train Acc 66.38755798339844% Val Acc 49.5322265625% Train Loss 0.4274281859397888 Val Loss 0.922785222530365
Trainable Parameters : 264452
Epoch 39 Train Acc 66.26793670654297% Val Acc 55.821205139160156% Train Loss 0.4251527488231659 Val Loss 0.7713838219642639
Trainable Parameters : 264452
Epoch 40 Train Acc 66.68659973144531% Val Acc 43.45114517211914% Train Loss 0.41582661867141724 Val Loss 1.1617870330810547
Trainable Parameters : 264452
Epoch 41 Train Acc 66.62679290771484% Val Acc 56.3929328918457% Train Loss 0.42414921522140503 Val Loss 0.7570138573646545
Trainable Parameters : 264452
Epoch 42 Train Acc 67.464111328125% Val Acc 56.28898239135742% Train Loss 0.4111994802951813 Val Loss 0.7786238789558411
Trainable Parameters : 264452
Epoch 43 Train Acc 66.92583465576172% Val Acc 48.12889862060547% Train Loss 0.41701000928878784 Val Loss 0.9635048508644104
Trainable Parameters : 264452
Epoch 44 Train Acc 67.52391815185547% Val Acc 58.10810852050781% Train Loss 0.4146828353404999 Val Loss 0.7157052755355835
Trainable Parameters : 264452
Epoch 45 Train Acc 66.68659973144531% Val Acc 58.316009521484375% Train Loss 0.4166860580444336 Val Loss 0.7116789221763611
Trainable Parameters : 264452
Epoch 46 Train Acc 67.58373260498047% Val Acc 50.10395050048828% Train Loss 0.4114644527435303 Val Loss 0.9544333815574646
Trainable Parameters : 264452
Epoch 47 Train Acc 67.52391815185547% Val Acc 49.79209899902344% Train Loss 0.40821364521980286 Val Loss 0.9110033512115479
Trainable Parameters : 264452
Epoch 48 Train Acc 66.50717163085938% Val Acc 52.02702713012695% Train Loss 0.4192061126232147 Val Loss 0.902575671672821
Trainable Parameters : 264452
