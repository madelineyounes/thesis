Thu Oct 13 23:21:05 AEDT 2022
------------------------------------------------------------------------
                         run_w2v.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_batch40.py
Started: 13/10/2022 23:21:08

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-batch-40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-40
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-40_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.2231,  1.2585,  1.3976,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0781,  0.0925,  0.0757,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2152,  0.1859,  0.1507,  ...,  3.5361,  3.4354,  3.4149],
        ...,
        [ 0.2089,  0.2468,  0.1245,  ..., -0.3236, -0.3305, -0.3219],
        [-0.7181, -0.7318, -0.6097,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0285, -0.0454, -0.0714,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 1, 0, 3, 0, 1, 2, 1, 1, 2, 0, 2, 3, 3, 0, 2, 3, 1, 3, 2, 3, 3, 3,
        1, 0, 3, 2, 3, 2, 3, 2, 2, 3, 1, 2, 0, 0, 2, 0])}
Training DataCustom Files: 1963
Training Data Files: 50
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'projector.weight', 'classifier.bias', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.7674,  0.3624,  0.1466,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.4739,  0.4929, -0.4964,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1370,  0.1863,  0.1947,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0389, -0.1059, -0.1063,  ...,  0.0000,  0.0000,  0.0000],
        [-1.5994, -1.4733, -1.3183,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.4947,  0.5400, -0.3454,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 3, 3, 2, 0, 2, 1, 3, 0, 3, 0, 2, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2,
        0, 2, 1, 0, 1, 0, 3, 1, 1, 2, 3, 1, 2, 1, 1, 1])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 25.139999389648438% Val Acc 27.30000114440918% Train Loss 0.6962733864784241 Val Loss 1.3944352865219116
Trainable Parameters : 264452
Epoch 1 Train Acc 24.639999389648438% Val Acc 27.80000114440918% Train Loss 0.696022093296051 Val Loss 1.3928412199020386
Trainable Parameters : 264452
Epoch 2 Train Acc 25.899999618530273% Val Acc 26.30000114440918% Train Loss 0.6944071650505066 Val Loss 1.3912098407745361
Trainable Parameters : 264452
Epoch 3 Train Acc 25.399999618530273% Val Acc 26.200000762939453% Train Loss 0.6946102976799011 Val Loss 1.389595627784729
Trainable Parameters : 264452
Epoch 4 Train Acc 26.53999900817871% Val Acc 26.30000114440918% Train Loss 0.6929567456245422 Val Loss 1.3893182277679443
Trainable Parameters : 264452
Epoch 5 Train Acc 28.739999771118164% Val Acc 27.0% Train Loss 0.6907970905303955 Val Loss 1.389567494392395
Trainable Parameters : 264452
Epoch 6 Train Acc 29.279998779296875% Val Acc 26.200000762939453% Train Loss 0.6900984048843384 Val Loss 1.3895750045776367
Trainable Parameters : 264452
Epoch 7 Train Acc 32.05999755859375% Val Acc 25.899999618530273% Train Loss 0.688528299331665 Val Loss 1.3901886940002441
Trainable Parameters : 264452
Epoch 8 Train Acc 34.380001068115234% Val Acc 24.0% Train Loss 0.686776876449585 Val Loss 1.3922207355499268
Trainable Parameters : 264452
Epoch 9 Train Acc 35.73999786376953% Val Acc 23.100000381469727% Train Loss 0.6842513084411621 Val Loss 1.3947880268096924
Trainable Parameters : 264452
Epoch 10 Train Acc 35.86000061035156% Val Acc 23.899999618530273% Train Loss 0.6827591061592102 Val Loss 1.394480586051941
Trainable Parameters : 264452
Epoch 11 Train Acc 36.13999938964844% Val Acc 25.30000114440918% Train Loss 0.6804200410842896 Val Loss 1.3953832387924194
Trainable Parameters : 264452
Epoch 12 Train Acc 42.15999984741211% Val Acc 24.700000762939453% Train Loss 0.6771101355552673 Val Loss 1.397626519203186
Trainable Parameters : 264452
Epoch 13 Train Acc 40.439998626708984% Val Acc 26.30000114440918% Train Loss 0.6759036779403687 Val Loss 1.4009655714035034
Trainable Parameters : 264452
Epoch 14 Train Acc 41.939998626708984% Val Acc 24.100000381469727% Train Loss 0.6739426255226135 Val Loss 1.4035239219665527
Trainable Parameters : 264452
Epoch 15 Train Acc 38.81999969482422% Val Acc 26.100000381469727% Train Loss 0.6724722385406494 Val Loss 1.4040005207061768
Trainable Parameters : 264452
Epoch 16 Train Acc 44.7599983215332% Val Acc 25.700000762939453% Train Loss 0.6661102175712585 Val Loss 1.4091179370880127
Trainable Parameters : 264452
Epoch 17 Train Acc 43.63999938964844% Val Acc 25.80000114440918% Train Loss 0.6661911010742188 Val Loss 1.4083119630813599
Trainable Parameters : 264452
Epoch 18 Train Acc 42.05999755859375% Val Acc 28.5% Train Loss 0.6618895530700684 Val Loss 1.4121757745742798
Trainable Parameters : 264452
Epoch 19 Train Acc 46.29999923706055% Val Acc 27.80000114440918% Train Loss 0.6589748859405518 Val Loss 1.4173345565795898
Trainable Parameters : 264452
Epoch 20 Train Acc 45.07999801635742% Val Acc 25.30000114440918% Train Loss 0.6561562418937683 Val Loss 1.4219353199005127
Trainable Parameters : 264452
Epoch 21 Train Acc 43.52000045776367% Val Acc 28.0% Train Loss 0.6520771384239197 Val Loss 1.4249361753463745
Trainable Parameters : 264452
Epoch 22 Train Acc 45.52000045776367% Val Acc 27.600000381469727% Train Loss 0.6510069966316223 Val Loss 1.4258397817611694
Trainable Parameters : 264452
Epoch 23 Train Acc 46.07999801635742% Val Acc 26.200000762939453% Train Loss 0.6464375853538513 Val Loss 1.4302717447280884
Trainable Parameters : 264452
Epoch 24 Train Acc 46.779998779296875% Val Acc 27.600000381469727% Train Loss 0.6461944580078125 Val Loss 1.4305418729782104
Trainable Parameters : 264452
Epoch 25 Train Acc 48.18000030517578% Val Acc 29.30000114440918% Train Loss 0.6378617882728577 Val Loss 1.4364765882492065
Trainable Parameters : 264452
Epoch 26 Train Acc 49.65999984741211% Val Acc 29.100000381469727% Train Loss 0.6360399723052979 Val Loss 1.4421477317810059
Trainable Parameters : 264452
Epoch 27 Train Acc 47.5% Val Acc 28.0% Train Loss 0.6349591612815857 Val Loss 1.4451595544815063
Trainable Parameters : 264452
Epoch 28 Train Acc 48.65999984741211% Val Acc 30.30000114440918% Train Loss 0.6346296072006226 Val Loss 1.4433537721633911
Trainable Parameters : 264452
Epoch 29 Train Acc 47.23999786376953% Val Acc 28.700000762939453% Train Loss 0.6304536461830139 Val Loss 1.4524290561676025
Trainable Parameters : 264452
Epoch 30 Train Acc 47.65999984741211% Val Acc 28.600000381469727% Train Loss 0.6241709589958191 Val Loss 1.4577207565307617
Trainable Parameters : 264452
Epoch 31 Train Acc 49.619998931884766% Val Acc 26.30000114440918% Train Loss 0.6160072088241577 Val Loss 1.453752875328064
Trainable Parameters : 264452
Epoch 32 Train Acc 50.03999710083008% Val Acc 27.600000381469727% Train Loss 0.6120303869247437 Val Loss 1.4640129804611206
Trainable Parameters : 264452
Epoch 33 Train Acc 48.86000061035156% Val Acc 29.700000762939453% Train Loss 0.6138857007026672 Val Loss 1.4568814039230347
Trainable Parameters : 264452
Epoch 34 Train Acc 50.599998474121094% Val Acc 29.5% Train Loss 0.6084481477737427 Val Loss 1.4708728790283203
Trainable Parameters : 264452
Epoch 35 Train Acc 50.36000061035156% Val Acc 30.80000114440918% Train Loss 0.6033979654312134 Val Loss 1.4643751382827759
Trainable Parameters : 264452
Epoch 36 Train Acc 52.02000045776367% Val Acc 31.5% Train Loss 0.5959814786911011 Val Loss 1.4703630208969116
Trainable Parameters : 264452
Epoch 37 Train Acc 52.05999755859375% Val Acc 29.700000762939453% Train Loss 0.5956445336341858 Val Loss 1.4741177558898926
Trainable Parameters : 264452
Epoch 38 Train Acc 51.5% Val Acc 31.200000762939453% Train Loss 0.5917519330978394 Val Loss 1.467035174369812
Trainable Parameters : 264452
Epoch 39 Train Acc 50.619998931884766% Val Acc 29.5% Train Loss 0.5916574001312256 Val Loss 1.4793565273284912
Trainable Parameters : 264452
Epoch 40 Train Acc 53.07999801635742% Val Acc 31.5% Train Loss 0.5835535526275635 Val Loss 1.46996009349823
Trainable Parameters : 264452
Epoch 41 Train Acc 53.53999710083008% Val Acc 30.399999618530273% Train Loss 0.5771485567092896 Val Loss 1.4781569242477417
Trainable Parameters : 264452
Epoch 42 Train Acc 51.89999771118164% Val Acc 29.700000762939453% Train Loss 0.5809234380722046 Val Loss 1.4815658330917358
Trainable Parameters : 264452
Epoch 43 Train Acc 54.34000015258789% Val Acc 27.5% Train Loss 0.568668007850647 Val Loss 1.494421362876892
Trainable Parameters : 264452
Epoch 44 Train Acc 52.15999984741211% Val Acc 30.899999618530273% Train Loss 0.5722293853759766 Val Loss 1.4799984693527222
Trainable Parameters : 264452
Epoch 45 Train Acc 54.21999740600586% Val Acc 29.700000762939453% Train Loss 0.5660161972045898 Val Loss 1.4842815399169922
Trainable Parameters : 264452
Epoch 46 Train Acc 55.87999725341797% Val Acc 31.0% Train Loss 0.5566734671592712 Val Loss 1.4812287092208862
Trainable Parameters : 264452
Epoch 47 Train Acc 53.57999801635742% Val Acc 31.5% Train Loss 0.559536337852478 Val Loss 1.4797463417053223
Trainable Parameters : 264452
Epoch 48 Train Acc 53.73999786376953% Val Acc 32.10000228881836% Train Loss 0.5609192252159119 Val Loss 1.477871298789978
Trainable Parameters : 264452
Epoch 49 Train Acc 54.57999801635742% Val Acc 32.400001525878906% Train Loss 0.5508416891098022 Val Loss 1.4982393980026245
Trainable Parameters : 264452
Epoch 50 Train Acc 53.84000015258789% Val Acc 30.5% Train Loss 0.5455317497253418 Val Loss 1.521002173423767
Trainable Parameters : 264452
Epoch 51 Train Acc 56.57999801635742% Val Acc 31.30000114440918% Train Loss 0.5398807525634766 Val Loss 1.4905474185943604
Trainable Parameters : 264452
Epoch 52 Train Acc 55.959999084472656% Val Acc 33.900001525878906% Train Loss 0.5329248309135437 Val Loss 1.4811595678329468
Trainable Parameters : 264452
Epoch 53 Train Acc 58.959999084472656% Val Acc 30.30000114440918% Train Loss 0.5319867134094238 Val Loss 1.4905141592025757
Trainable Parameters : 264452
Epoch 54 Train Acc 56.65999984741211% Val Acc 34.20000076293945% Train Loss 0.536932110786438 Val Loss 1.4726699590682983
Trainable Parameters : 264452
Epoch 55 Train Acc 57.29999923706055% Val Acc 34.60000228881836% Train Loss 0.529812753200531 Val Loss 1.4985986948013306
Trainable Parameters : 264452
Epoch 56 Train Acc 59.53999710083008% Val Acc 31.0% Train Loss 0.5211679935455322 Val Loss 1.5290968418121338
Trainable Parameters : 264452
Epoch 57 Train Acc 58.18000030517578% Val Acc 31.700000762939453% Train Loss 0.5159432291984558 Val Loss 1.4936338663101196
Trainable Parameters : 264452
Epoch 58 Train Acc 57.79999923706055% Val Acc 33.900001525878906% Train Loss 0.5237300395965576 Val Loss 1.52480947971344
Trainable Parameters : 264452
Epoch 59 Train Acc 56.89999771118164% Val Acc 32.400001525878906% Train Loss 0.5212927460670471 Val Loss 1.4799983501434326
Trainable Parameters : 264452
Epoch 60 Train Acc 60.41999816894531% Val Acc 30.399999618530273% Train Loss 0.49985331296920776 Val Loss 1.5333552360534668
Trainable Parameters : 264452
Epoch 61 Train Acc 59.119998931884766% Val Acc 32.0% Train Loss 0.5117617845535278 Val Loss 1.5134333372116089
Trainable Parameters : 264452
Epoch 62 Train Acc 59.23999786376953% Val Acc 34.0% Train Loss 0.5049387812614441 Val Loss 1.518475890159607
Trainable Parameters : 264452
Epoch 63 Train Acc 61.099998474121094% Val Acc 32.79999923706055% Train Loss 0.4944656193256378 Val Loss 1.5852538347244263
Trainable Parameters : 264452
Epoch 64 Train Acc 60.439998626708984% Val Acc 34.79999923706055% Train Loss 0.49669149518013 Val Loss 1.5678694248199463
Trainable Parameters : 264452
Epoch 65 Train Acc 61.15999984741211% Val Acc 35.79999923706055% Train Loss 0.49020376801490784 Val Loss 1.4848395586013794
Trainable Parameters : 264452
Epoch 66 Train Acc 61.279998779296875% Val Acc 35.70000076293945% Train Loss 0.4826321005821228 Val Loss 1.5085452795028687
Trainable Parameters : 264452
Epoch 67 Train Acc 60.65999984741211% Val Acc 36.70000076293945% Train Loss 0.48699724674224854 Val Loss 1.5082018375396729
Trainable Parameters : 264452
Epoch 68 Train Acc 63.279998779296875% Val Acc 34.70000076293945% Train Loss 0.4786621034145355 Val Loss 1.547603726387024
Trainable Parameters : 264452
Epoch 69 Train Acc 60.84000015258789% Val Acc 35.70000076293945% Train Loss 0.4786602258682251 Val Loss 1.5368342399597168
Trainable Parameters : 264452
Epoch 70 Train Acc 61.8599967956543% Val Acc 34.60000228881836% Train Loss 0.4705667495727539 Val Loss 1.5165183544158936
Trainable Parameters : 264452
Epoch 71 Train Acc 62.0% Val Acc 35.29999923706055% Train Loss 0.4694000780582428 Val Loss 1.5321873426437378
Trainable Parameters : 264452
Epoch 72 Train Acc 62.7599983215332% Val Acc 35.0% Train Loss 0.4699244499206543 Val Loss 1.5727829933166504
Trainable Parameters : 264452
Epoch 73 Train Acc 63.779998779296875% Val Acc 35.400001525878906% Train Loss 0.457692414522171 Val Loss 1.6166025400161743
Trainable Parameters : 264452
Epoch 74 Train Acc 64.27999877929688% Val Acc 37.5% Train Loss 0.45567792654037476 Val Loss 1.5622419118881226
Trainable Parameters : 264452
Epoch 75 Train Acc 63.05999755859375% Val Acc 37.70000076293945% Train Loss 0.465548038482666 Val Loss 1.5284233093261719
Trainable Parameters : 264452
Epoch 76 Train Acc 63.91999816894531% Val Acc 40.20000076293945% Train Loss 0.4515073001384735 Val Loss 1.5238195657730103
Trainable Parameters : 264452
Epoch 77 Train Acc 63.55999755859375% Val Acc 39.20000076293945% Train Loss 0.45755892992019653 Val Loss 1.5474319458007812
Trainable Parameters : 264452
Epoch 78 Train Acc 64.81999969482422% Val Acc 39.79999923706055% Train Loss 0.4532739222049713 Val Loss 1.5101242065429688
Trainable Parameters : 264452
Epoch 79 Train Acc 64.9000015258789% Val Acc 37.29999923706055% Train Loss 0.4462584853172302 Val Loss 1.5800354480743408
Trainable Parameters : 264452
Epoch 80 Train Acc 66.91999816894531% Val Acc 39.900001525878906% Train Loss 0.43635454773902893 Val Loss 1.5252792835235596
Trainable Parameters : 264452
Epoch 81 Train Acc 64.05999755859375% Val Acc 38.400001525878906% Train Loss 0.44189003109931946 Val Loss 1.6022306680679321
Trainable Parameters : 264452
Epoch 82 Train Acc 64.97999572753906% Val Acc 40.79999923706055% Train Loss 0.4412480890750885 Val Loss 1.5328705310821533
Trainable Parameters : 264452
Epoch 83 Train Acc 65.76000213623047% Val Acc 38.900001525878906% Train Loss 0.43568679690361023 Val Loss 1.559037685394287
Trainable Parameters : 264452
Epoch 84 Train Acc 66.45999908447266% Val Acc 37.900001525878906% Train Loss 0.4323105216026306 Val Loss 1.6723612546920776
Trainable Parameters : 264452
Epoch 85 Train Acc 66.54000091552734% Val Acc 38.5% Train Loss 0.4341225028038025 Val Loss 1.6216601133346558
Trainable Parameters : 264452
Epoch 86 Train Acc 68.05999755859375% Val Acc 43.0% Train Loss 0.42052680253982544 Val Loss 1.5290380716323853
Trainable Parameters : 264452
Epoch 87 Train Acc 66.72000122070312% Val Acc 36.900001525878906% Train Loss 0.42694902420043945 Val Loss 1.5768097639083862
Trainable Parameters : 264452
Epoch 88 Train Acc 67.05999755859375% Val Acc 38.900001525878906% Train Loss 0.4258299171924591 Val Loss 1.6320101022720337
Trainable Parameters : 264452
Epoch 89 Train Acc 67.33999633789062% Val Acc 39.70000076293945% Train Loss 0.4212428629398346 Val Loss 1.6003693342208862
Trainable Parameters : 264452
Epoch 90 Train Acc 66.13999938964844% Val Acc 43.0% Train Loss 0.4235321581363678 Val Loss 1.5550798177719116
Trainable Parameters : 264452
Epoch 91 Train Acc 67.5999984741211% Val Acc 37.60000228881836% Train Loss 0.41594308614730835 Val Loss 1.7226717472076416
Trainable Parameters : 264452
Epoch 92 Train Acc 68.0% Val Acc 41.10000228881836% Train Loss 0.41562220454216003 Val Loss 1.6104376316070557
Trainable Parameters : 264452
Epoch 93 Train Acc 68.81999969482422% Val Acc 41.70000076293945% Train Loss 0.4050194323062897 Val Loss 1.566745638847351
Trainable Parameters : 264452
Epoch 94 Train Acc 66.76000213623047% Val Acc 38.10000228881836% Train Loss 0.4259504973888397 Val Loss 1.6604331731796265
Trainable Parameters : 264452
Epoch 95 Train Acc 66.72000122070312% Val Acc 41.29999923706055% Train Loss 0.4343981146812439 Val Loss 1.557567834854126
Trainable Parameters : 264452
Epoch 96 Train Acc 68.69999694824219% Val Acc 40.5% Train Loss 0.4114561378955841 Val Loss 1.6296499967575073
Trainable Parameters : 264452
Epoch 97 Train Acc 67.05999755859375% Val Acc 39.60000228881836% Train Loss 0.4092977046966553 Val Loss 1.67889404296875
Trainable Parameters : 264452
Epoch 98 Train Acc 68.54000091552734% Val Acc 41.400001525878906% Train Loss 0.40632712841033936 Val Loss 1.6214122772216797
Trainable Parameters : 264452
Configuration saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-40/config.json
Model weights saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-batch-40/pytorch_model.bin
Epoch 99 Train Acc 68.31999969482422% Val Acc 39.10000228881836% Train Loss 0.40837275981903076 Val Loss 1.603644609451294

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.   0.   0.   0.  ]
 [0.25 0.   0.   0.  ]
 [0.5  0.   0.   0.25]
 [0.   0.   0.   0.  ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
          98       0.00      0.00      0.00       1.0
         100       0.00      0.00      0.00       3.0
         398       0.00      0.00      0.00       0.0

    accuracy                           0.00       4.0
   macro avg       0.00      0.00      0.00       4.0
weighted avg       0.00      0.00      0.00       4.0


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/10/2022 00:23:46
