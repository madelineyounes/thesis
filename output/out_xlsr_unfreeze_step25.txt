Sat Nov 5 18:49:59 AEDT 2022
2022-11-05 18:50:01.625495: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-05 18:50:01.882820: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-05 18:50:01.918830: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-05 18:50:03.906556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-05 18:50:03.908124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-05 18:50:03.908137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_unfreezestep25.py
Started: 05/11/2022 18:50:17

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-araic-unfreeze-step25
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 25
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step25
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step25_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0017,  0.0116,  0.0027,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0103,  0.0085,  0.0057,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.4015,  0.8330,  0.3296,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1239,  0.4260,  0.9525,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0200,  0.0114,  0.0525,  ..., -0.0297, -0.0071, -0.0152],
        [ 1.1115,  1.0810,  1.3358,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 1, 3, 3, 2, 2, 2, 1, 0, 2, 2, 3, 2, 0, 2, 1, 2, 0, 2, 0, 2, 2, 2,
        2, 0, 3, 2, 3, 2, 0, 2, 1, 2, 2, 2, 0, 3, 2, 3])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-0.3766, -0.3857, -0.3947,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4607,  0.3141, -0.0073,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3545,  0.5312,  0.9027,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.8563,  0.1056,  0.9895,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0377, -0.0106,  0.0270,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0287, -0.9592,  0.5421,  ...,  1.6599,  1.4288,  1.0692]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 1, 2, 3, 0, 2, 3, 3, 3, 1, 2, 3, 1, 0, 0, 3, 0, 3, 3, 0, 1, 1, 2, 1,
        0, 1, 2, 2, 1, 2, 3, 2, 3, 1, 2, 3, 3, 1, 3, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'projector.weight', 'projector.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.8050,  0.8547,  0.9041,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1013, -0.1371, -0.1340,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1520,  0.3014,  0.5165,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 1.6677,  1.5194,  0.9645,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0913,  0.0480,  0.0778,  ...,  0.5903,  0.6188,  1.1459],
        [ 1.4739,  0.4929, -0.4964,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 1, 0, 3, 3, 1, 0, 2, 3, 2, 2, 0, 1, 3, 0, 1, 1, 0, 2, 1, 0, 3, 0,
        1, 0, 2, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 3, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 0 Train Acc 39.64638900756836% Val Acc 25.5% Train Loss 0.6652619242668152 Val Loss 1.444146990776062
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 1 Train Acc 46.84790802001953% Val Acc 35.400001525878906% Train Loss 0.5994253754615784 Val Loss 1.4470404386520386
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 2 Train Acc 59.74905014038086% Val Acc 50.79999923706055% Train Loss 0.4999832808971405 Val Loss 1.1230882406234741
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 3 Train Acc 71.39163208007812% Val Acc 61.10000228881836% Train Loss 0.3765094578266144 Val Loss 1.058939814567566
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 4 Train Acc 78.56653594970703% Val Acc 61.79999923706055% Train Loss 0.29459914565086365 Val Loss 1.085315227508545
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 5 Train Acc 83.58174896240234% Val Acc 76.5% Train Loss 0.23087924718856812 Val Loss 0.6688718795776367
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 6 Train Acc 87.55513000488281% Val Acc 72.9000015258789% Train Loss 0.17719997465610504 Val Loss 0.808601975440979
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 7 Train Acc 90.01901245117188% Val Acc 70.0% Train Loss 0.13891462981700897 Val Loss 1.0699137449264526
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 8 Train Acc 91.7224349975586% Val Acc 73.5999984741211% Train Loss 0.11456441134214401 Val Loss 0.8186292052268982
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 9 Train Acc 93.39163208007812% Val Acc 69.0% Train Loss 0.09548599272966385 Val Loss 1.4371012449264526
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 10 Train Acc 93.78327178955078% Val Acc 73.0999984741211% Train Loss 0.08658396452665329 Val Loss 1.0238792896270752
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 11 Train Acc 94.7908706665039% Val Acc 65.5% Train Loss 0.0749782845377922 Val Loss 1.6400402784347534
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 12 Train Acc 94.85551452636719% Val Acc 69.0% Train Loss 0.07322689890861511 Val Loss 1.3235467672348022
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 13 Train Acc 95.67300415039062% Val Acc 73.70000457763672% Train Loss 0.06676825881004333 Val Loss 1.004252314567566
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 14 Train Acc 95.7186279296875% Val Acc 66.0999984741211% Train Loss 0.06687628477811813 Val Loss 1.5752185583114624
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 15 Train Acc 95.93536376953125% Val Acc 71.70000457763672% Train Loss 0.060926973819732666 Val Loss 1.365050196647644
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 16 Train Acc 95.68441009521484% Val Acc 61.5% Train Loss 0.06338197737932205 Val Loss 1.888606309890747
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 17 Train Acc 95.4866943359375% Val Acc 71.30000305175781% Train Loss 0.06262684613466263 Val Loss 1.3402785062789917
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 18 Train Acc 95.40684509277344% Val Acc 71.5% Train Loss 0.06736108660697937 Val Loss 1.0576971769332886
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 19 Train Acc 95.73384094238281% Val Acc 71.0999984741211% Train Loss 0.06399975717067719 Val Loss 1.3020493984222412
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 20 Train Acc 95.39163208007812% Val Acc 74.0999984741211% Train Loss 0.06821342557668686 Val Loss 0.9986519813537598
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 21 Train Acc 95.65019226074219% Val Acc 67.0% Train Loss 0.06327163428068161 Val Loss 1.557119607925415
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 22 Train Acc 95.80608367919922% Val Acc 74.20000457763672% Train Loss 0.0629562959074974 Val Loss 1.1038925647735596
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 23 Train Acc 95.58935546875% Val Acc 72.80000305175781% Train Loss 0.06603605300188065 Val Loss 1.3128817081451416
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 24 Train Acc 95.31558990478516% Val Acc 67.0% Train Loss 0.07154607027769089 Val Loss 1.5171878337860107
EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 25 Train Acc 96.5171127319336% Val Acc 68.9000015258789% Train Loss 0.05711996182799339 Val Loss 1.3578886985778809
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 26 Train Acc 96.18630981445312% Val Acc 72.20000457763672% Train Loss 0.0608079731464386 Val Loss 1.3891831636428833
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 27 Train Acc 95.56653594970703% Val Acc 68.0% Train Loss 0.06628280133008957 Val Loss 1.5065213441848755
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 28 Train Acc 95.37261962890625% Val Acc 63.79999923706055% Train Loss 0.07063056528568268 Val Loss 1.8540633916854858
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 29 Train Acc 95.56273651123047% Val Acc 68.5% Train Loss 0.06406014412641525 Val Loss 1.5669535398483276
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 30 Train Acc 95.14448547363281% Val Acc 69.9000015258789% Train Loss 0.07263881713151932 Val Loss 1.3170868158340454
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 31 Train Acc 94.33079528808594% Val Acc 72.0% Train Loss 0.08232279121875763 Val Loss 1.0289760828018188
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 32 Train Acc 94.70342254638672% Val Acc 72.9000015258789% Train Loss 0.08060479164123535 Val Loss 1.0283116102218628
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 33 Train Acc 94.73384094238281% Val Acc 55.79999923706055% Train Loss 0.0791376456618309 Val Loss 1.903791069984436
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 34 Train Acc 95.06463623046875% Val Acc 66.0% Train Loss 0.07433423399925232 Val Loss 1.388932228088379
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 35 Train Acc 94.22813415527344% Val Acc 70.5% Train Loss 0.084067702293396 Val Loss 1.111431360244751
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 36 Train Acc 94.42585754394531% Val Acc 59.70000076293945% Train Loss 0.08228688687086105 Val Loss 1.7462705373764038
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 37 Train Acc 94.4866943359375% Val Acc 64.20000457763672% Train Loss 0.08110939711332321 Val Loss 1.3744367361068726
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 38 Train Acc 95.34600830078125% Val Acc 62.79999923706055% Train Loss 0.07072614133358002 Val Loss 1.892083764076233
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 39 Train Acc 94.8973388671875% Val Acc 67.20000457763672% Train Loss 0.07623366266489029 Val Loss 1.4699764251708984
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 40 Train Acc 94.59695434570312% Val Acc 72.0% Train Loss 0.0794425681233406 Val Loss 1.0413122177124023
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 41 Train Acc 95.4866943359375% Val Acc 62.70000076293945% Train Loss 0.06834404170513153 Val Loss 1.4181022644042969
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 42 Train Acc 95.44866943359375% Val Acc 61.29999923706055% Train Loss 0.06707834452390671 Val Loss 1.7821146249771118
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 43 Train Acc 95.56653594970703% Val Acc 69.0999984741211% Train Loss 0.06549452245235443 Val Loss 1.293725609779358
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 44 Train Acc 96.08364868164062% Val Acc 69.4000015258789% Train Loss 0.05675553157925606 Val Loss 1.4352725744247437
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 45 Train Acc 96.46768188476562% Val Acc 68.30000305175781% Train Loss 0.05334557965397835 Val Loss 1.1085199117660522
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 46 Train Acc 96.68441009521484% Val Acc 61.60000228881836% Train Loss 0.0503072664141655 Val Loss 1.959149956703186
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 47 Train Acc 96.01140594482422% Val Acc 69.30000305175781% Train Loss 0.06064606457948685 Val Loss 1.3208322525024414
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 48 Train Acc 97.22433471679688% Val Acc 68.5999984741211% Train Loss 0.04331928491592407 Val Loss 1.4891457557678223
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 49 Train Acc 96.93536376953125% Val Acc 72.0999984741211% Train Loss 0.04767364263534546 Val Loss 1.4087446928024292
EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 50 Train Acc 97.15209197998047% Val Acc 65.0% Train Loss 0.04282429814338684 Val Loss 1.8418644666671753
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 51 Train Acc 97.12547302246094% Val Acc 68.5% Train Loss 0.04455964267253876 Val Loss 1.6747817993164062
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 52 Train Acc 97.17110443115234% Val Acc 66.5% Train Loss 0.04362329840660095 Val Loss 1.6869710683822632
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 53 Train Acc 97.5437240600586% Val Acc 72.4000015258789% Train Loss 0.039694227278232574 Val Loss 1.2969526052474976
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 54 Train Acc 97.26995849609375% Val Acc 63.79999923706055% Train Loss 0.04219263419508934 Val Loss 1.8607219457626343
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 55 Train Acc 97.29657745361328% Val Acc 66.70000457763672% Train Loss 0.04228139668703079 Val Loss 1.5323470830917358
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 56 Train Acc 97.31558990478516% Val Acc 66.5999984741211% Train Loss 0.04073069244623184 Val Loss 1.8065261840820312
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 57 Train Acc 97.91635131835938% Val Acc 60.10000228881836% Train Loss 0.03580566868185997 Val Loss 1.9967339038848877
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 58 Train Acc 97.80228424072266% Val Acc 71.20000457763672% Train Loss 0.03534094616770744 Val Loss 1.486811876296997
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 59 Train Acc 97.60456085205078% Val Acc 67.5999984741211% Train Loss 0.03682592511177063 Val Loss 1.4697073698043823
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 60 Train Acc 97.65399169921875% Val Acc 72.4000015258789% Train Loss 0.03723108395934105 Val Loss 1.336341142654419
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 61 Train Acc 97.74144744873047% Val Acc 63.10000228881836% Train Loss 0.03602760285139084 Val Loss 1.938724160194397
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 62 Train Acc 98.12928009033203% Val Acc 65.0999984741211% Train Loss 0.02847808040678501 Val Loss 1.649927020072937
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 63 Train Acc 98.14448547363281% Val Acc 65.70000457763672% Train Loss 0.029808057472109795 Val Loss 1.6472454071044922
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 64 Train Acc 97.77566528320312% Val Acc 66.80000305175781% Train Loss 0.031762972474098206 Val Loss 1.6996396780014038
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 65 Train Acc 98.46768188476562% Val Acc 67.70000457763672% Train Loss 0.025608325377106667 Val Loss 1.6709070205688477
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 66 Train Acc 98.26235961914062% Val Acc 67.0% Train Loss 0.027515094727277756 Val Loss 1.8119724988937378
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 67 Train Acc 98.01520538330078% Val Acc 65.80000305175781% Train Loss 0.02931392937898636 Val Loss 1.8504432439804077
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 68 Train Acc 98.23954010009766% Val Acc 61.60000228881836% Train Loss 0.02664412185549736 Val Loss 2.177687168121338
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 69 Train Acc 98.28136444091797% Val Acc 71.20000457763672% Train Loss 0.02851276285946369 Val Loss 1.7748380899429321
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 70 Train Acc 98.19391632080078% Val Acc 63.79999923706055% Train Loss 0.026075759902596474 Val Loss 2.2352354526519775
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 71 Train Acc 98.39543914794922% Val Acc 67.30000305175781% Train Loss 0.025861158967018127 Val Loss 2.0223710536956787
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 72 Train Acc 98.2775650024414% Val Acc 68.30000305175781% Train Loss 0.02935219742357731 Val Loss 1.5100685358047485
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 73 Train Acc 98.31558990478516% Val Acc 70.30000305175781% Train Loss 0.027381092309951782 Val Loss 1.422163486480713
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Epoch 74 Train Acc 98.5133056640625% Val Acc 64.30000305175781% Train Loss 0.023399587720632553 Val Loss 2.1625216007232666
EPOCH unfeeze : 0
Trainable Parameters : 151419140
Epoch 75 Train Acc 98.55133056640625% Val Acc 69.70000457763672% Train Loss 0.0246871504932642 Val Loss 1.81511390209198
EPOCH unfeeze : 1
Trainable Parameters : 151419140
Epoch 76 Train Acc 98.25094604492188% Val Acc 68.5999984741211% Train Loss 0.025635499507188797 Val Loss 1.7117527723312378
EPOCH unfeeze : 2
Trainable Parameters : 151419140
Epoch 77 Train Acc 98.80228424072266% Val Acc 64.9000015258789% Train Loss 0.018617456778883934 Val Loss 2.397078275680542
EPOCH unfeeze : 3
Trainable Parameters : 151419140
Epoch 78 Train Acc 98.6197738647461% Val Acc 72.5% Train Loss 0.021788299083709717 Val Loss 1.5491173267364502
EPOCH unfeeze : 4
Trainable Parameters : 151419140
Epoch 79 Train Acc 98.47148132324219% Val Acc 67.5999984741211% Train Loss 0.025202861055731773 Val Loss 1.9532493352890015
EPOCH unfeeze : 5
Trainable Parameters : 151419140
Epoch 80 Train Acc 98.70342254638672% Val Acc 68.70000457763672% Train Loss 0.01946682669222355 Val Loss 1.8509752750396729
EPOCH unfeeze : 6
Trainable Parameters : 151419140
Epoch 81 Train Acc 98.85931396484375% Val Acc 66.20000457763672% Train Loss 0.02029816061258316 Val Loss 1.8280550241470337
EPOCH unfeeze : 7
Trainable Parameters : 151419140
Epoch 82 Train Acc 99.08364868164062% Val Acc 65.4000015258789% Train Loss 0.016031360253691673 Val Loss 2.226435899734497
EPOCH unfeeze : 8
Trainable Parameters : 151419140
Epoch 83 Train Acc 99.15969848632812% Val Acc 67.0999984741211% Train Loss 0.015668878331780434 Val Loss 1.8047417402267456
EPOCH unfeeze : 9
Trainable Parameters : 151419140
Epoch 84 Train Acc 98.66919708251953% Val Acc 70.80000305175781% Train Loss 0.020025422796607018 Val Loss 1.788094162940979
EPOCH unfeeze : 10
Trainable Parameters : 151419140
Epoch 85 Train Acc 98.8669204711914% Val Acc 67.5999984741211% Train Loss 0.018467774614691734 Val Loss 2.338367462158203
EPOCH unfeeze : 11
Trainable Parameters : 151419140
Epoch 86 Train Acc 98.91254425048828% Val Acc 60.400001525878906% Train Loss 0.01601177640259266 Val Loss 2.8444807529449463
EPOCH unfeeze : 12
Trainable Parameters : 151419140
Epoch 87 Train Acc 98.70342254638672% Val Acc 68.4000015258789% Train Loss 0.02072143740952015 Val Loss 2.2089107036590576
EPOCH unfeeze : 13
Trainable Parameters : 151419140
Epoch 88 Train Acc 98.84030151367188% Val Acc 70.0% Train Loss 0.017787210643291473 Val Loss 1.7156826257705688
EPOCH unfeeze : 14
Trainable Parameters : 151419140
Epoch 89 Train Acc 98.95817565917969% Val Acc 66.4000015258789% Train Loss 0.017601575702428818 Val Loss 2.262845754623413
EPOCH unfeeze : 15
Trainable Parameters : 151419140
Epoch 90 Train Acc 98.79847717285156% Val Acc 70.70000457763672% Train Loss 0.019615450873970985 Val Loss 1.8648601770401
EPOCH unfeeze : 16
Trainable Parameters : 151419140
Epoch 91 Train Acc 99.19011688232422% Val Acc 69.4000015258789% Train Loss 0.013018190860748291 Val Loss 2.1929266452789307
EPOCH unfeeze : 17
Trainable Parameters : 151419140
Epoch 92 Train Acc 99.1330795288086% Val Acc 67.4000015258789% Train Loss 0.014337940141558647 Val Loss 2.1508119106292725
EPOCH unfeeze : 18
Trainable Parameters : 151419140
Epoch 93 Train Acc 98.88212585449219% Val Acc 67.0999984741211% Train Loss 0.01726016029715538 Val Loss 2.383186101913452
EPOCH unfeeze : 19
Trainable Parameters : 151419140
Epoch 94 Train Acc 99.03421783447266% Val Acc 63.900001525878906% Train Loss 0.01676992140710354 Val Loss 2.4592554569244385
EPOCH unfeeze : 20
Trainable Parameters : 151419140
Epoch 95 Train Acc 99.02281188964844% Val Acc 69.0% Train Loss 0.016580786556005478 Val Loss 2.1843507289886475
EPOCH unfeeze : 21
Trainable Parameters : 151419140
Epoch 96 Train Acc 99.00760650634766% Val Acc 71.70000457763672% Train Loss 0.014495611190795898 Val Loss 1.695044755935669
EPOCH unfeeze : 22
Trainable Parameters : 151419140
Epoch 97 Train Acc 98.84410858154297% Val Acc 70.0% Train Loss 0.01852954737842083 Val Loss 2.0688817501068115
EPOCH unfeeze : 23
Trainable Parameters : 151419140
Epoch 98 Train Acc 99.21292877197266% Val Acc 70.9000015258789% Train Loss 0.013763590715825558 Val Loss 1.6620620489120483
EPOCH unfeeze : 24
Trainable Parameters : 151419140
Configuration saved in /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step25/config.json
Model weights saved in /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-araic-unfreeze-step25/pytorch_model.bin
Epoch 99 Train Acc 99.04943084716797% Val Acc 67.80000305175781% Train Loss 0.013748256489634514 Val Loss 2.4407923221588135

------> EVALUATING MODEL... ------------------------------------------ 

Final Test Acc:76.0% Loss:1.8099266290664673
CONFUSION MATRIX
[[79  2 12  7]
 [ 4 45 31 20]
 [ 0  3 93  2]
 [ 1  2 11 86]]
CONFUSION MATRIX NORMALISED
[[0.19849246 0.00502513 0.03015075 0.01758794]
 [0.01005025 0.11306533 0.07788945 0.05025126]
 [0.         0.00753769 0.23366834 0.00502513]
 [0.00251256 0.00502513 0.02763819 0.2160804 ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.94      0.79      0.86       100
           1       0.87      0.45      0.59       100
           2       0.63      0.95      0.76        98
           3       0.75      0.86      0.80       100

    accuracy                           0.76       398
   macro avg       0.80      0.76      0.75       398
weighted avg       0.80      0.76      0.75       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 06/11/2022 06:32:22
