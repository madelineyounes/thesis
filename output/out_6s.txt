Mon Oct 10 03:01:06 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_6s.py
Started: 10/10/2022 03:01:10

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-1s
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 4
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-1s
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-1s_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 6 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0025, -0.0171, -0.0056,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2015,  0.0067,  0.0802,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.7278,  0.8852,  1.0333,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1557,  0.1464,  0.1507,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 0, 3])}
Training DataCustom Files: 1963
Training Data Files: 491
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'project_hid.bias', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.weight', 'classifier.bias', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 0.0488,  0.0204,  0.0220,  ...,  0.0000,  0.0000,  0.0000],
        [-0.5868, -0.3971, -0.0181,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8789, -0.6262, -0.3632,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3582, -0.4719, -0.3916,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 3, 3, 3])}
Test CustomData Files: 1997
Test Data Files: 500
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 23.981670379638672% Val Acc 22.000001907348633% Train Loss 0.6923699378967285 Val Loss 1.3916447162628174
Trainable Parameters : 198660
Epoch 1 Train Acc 30.820775985717773% Val Acc 21.200000762939453% Train Loss 0.6887795925140381 Val Loss 1.3958978652954102
Trainable Parameters : 198660
Epoch 2 Train Acc 32.17922592163086% Val Acc 22.05000114440918% Train Loss 0.6830369830131531 Val Loss 1.4036308526992798
Trainable Parameters : 198660
Epoch 3 Train Acc 33.67210006713867% Val Acc 22.600000381469727% Train Loss 0.6743637323379517 Val Loss 1.4345985651016235
Trainable Parameters : 198660
Epoch 4 Train Acc 35.30142593383789% Val Acc 22.350000381469727% Train Loss 0.6670350432395935 Val Loss 1.4638313055038452
Trainable Parameters : 198660
Epoch 5 Train Acc 36.116092681884766% Val Acc 22.500001907348633% Train Loss 0.6590371131896973 Val Loss 1.472252368927002
Trainable Parameters : 198660
Epoch 6 Train Acc 37.08350372314453% Val Acc 22.05000114440918% Train Loss 0.6530798077583313 Val Loss 1.5455254316329956
Trainable Parameters : 198660
Epoch 7 Train Acc 39.629329681396484% Val Acc 22.80000114440918% Train Loss 0.6399012207984924 Val Loss 1.5642958879470825
Trainable Parameters : 198660
Epoch 8 Train Acc 40.83503341674805% Val Acc 22.150001525878906% Train Loss 0.629886269569397 Val Loss 1.6207144260406494
Trainable Parameters : 198660
Epoch 9 Train Acc 44.5865592956543% Val Acc 21.750001907348633% Train Loss 0.6143754124641418 Val Loss 1.7273170948028564
Trainable Parameters : 198660
Epoch 10 Train Acc 46.18126678466797% Val Acc 22.650001525878906% Train Loss 0.6053242683410645 Val Loss 1.8216911554336548
Trainable Parameters : 198660
Epoch 11 Train Acc 47.81059265136719% Val Acc 27.200000762939453% Train Loss 0.590114414691925 Val Loss 1.8629770278930664
Trainable Parameters : 198660
Epoch 12 Train Acc 49.81262969970703% Val Acc 24.500001907348633% Train Loss 0.58017498254776 Val Loss 1.9977456331253052
Trainable Parameters : 198660
Epoch 13 Train Acc 50.25458526611328% Val Acc 27.100000381469727% Train Loss 0.5701587796211243 Val Loss 2.1422505378723145
Trainable Parameters : 198660
Epoch 14 Train Acc 52.13849639892578% Val Acc 25.900001525878906% Train Loss 0.5615077614784241 Val Loss 2.1219239234924316
Trainable Parameters : 198660
Epoch 15 Train Acc 53.751529693603516% Val Acc 26.750001907348633% Train Loss 0.5400618314743042 Val Loss 2.1874375343322754
Trainable Parameters : 198660
Epoch 16 Train Acc 54.853363037109375% Val Acc 26.250001907348633% Train Loss 0.531643807888031 Val Loss 2.5165646076202393
Trainable Parameters : 198660
Epoch 17 Train Acc 55.78818893432617% Val Acc 26.450000762939453% Train Loss 0.5245568752288818 Val Loss 2.5081186294555664
Trainable Parameters : 198660
Epoch 18 Train Acc 57.57026672363281% Val Acc 26.200000762939453% Train Loss 0.5136602520942688 Val Loss 2.428891897201538
Trainable Parameters : 198660
Epoch 19 Train Acc 57.688392639160156% Val Acc 24.55000114440918% Train Loss 0.5109401941299438 Val Loss 2.7625954151153564
Trainable Parameters : 198660
Epoch 20 Train Acc 58.232181549072266% Val Acc 24.950000762939453% Train Loss 0.5064916014671326 Val Loss 2.9822309017181396
Trainable Parameters : 198660
Epoch 21 Train Acc 59.403263092041016% Val Acc 25.05000114440918% Train Loss 0.5018008351325989 Val Loss 2.599614143371582
Trainable Parameters : 198660
Epoch 22 Train Acc 60.77800750732422% Val Acc 25.450000762939453% Train Loss 0.48547908663749695 Val Loss 3.4742164611816406
Trainable Parameters : 198660
Epoch 23 Train Acc 61.79633712768555% Val Acc 26.400001525878906% Train Loss 0.47975119948387146 Val Loss 2.8060059547424316
Trainable Parameters : 198660
Epoch 24 Train Acc 60.86151123046875% Val Acc 25.000001907348633% Train Loss 0.4768456518650055 Val Loss 2.8079237937927246
Trainable Parameters : 198660
Epoch 25 Train Acc 62.96741485595703% Val Acc 26.350000381469727% Train Loss 0.46038901805877686 Val Loss 2.7943813800811768
Trainable Parameters : 198660
Epoch 26 Train Acc 62.169044494628906% Val Acc 25.55000114440918% Train Loss 0.4654656946659088 Val Loss 3.9711248874664307
Trainable Parameters : 198660
Epoch 27 Train Acc 63.543792724609375% Val Acc 25.55000114440918% Train Loss 0.45760101079940796 Val Loss 3.8198599815368652
Trainable Parameters : 198660
Epoch 28 Train Acc 64.93482971191406% Val Acc 25.350000381469727% Train Loss 0.4427107572555542 Val Loss 3.2964398860931396
Trainable Parameters : 198660
Epoch 29 Train Acc 65.29124450683594% Val Acc 25.80000114440918% Train Loss 0.43970608711242676 Val Loss 3.649233818054199
Trainable Parameters : 198660
Epoch 30 Train Acc 64.49491119384766% Val Acc 25.250001907348633% Train Loss 0.4441913962364197 Val Loss 3.2092912197113037
Trainable Parameters : 198660
Epoch 31 Train Acc 66.27699279785156% Val Acc 25.750001907348633% Train Loss 0.4289105534553528 Val Loss 3.1942970752716064
Trainable Parameters : 198660
Epoch 32 Train Acc 65.2077407836914% Val Acc 25.650001525878906% Train Loss 0.43320202827453613 Val Loss 3.6669960021972656
Trainable Parameters : 198660
Epoch 33 Train Acc 67.29531860351562% Val Acc 25.400001525878906% Train Loss 0.4224397838115692 Val Loss 3.87849497795105
Trainable Parameters : 198660
Epoch 34 Train Acc 68.26273345947266% Val Acc 26.200000762939453% Train Loss 0.40934988856315613 Val Loss 3.3823723793029785
Trainable Parameters : 198660
Epoch 35 Train Acc 67.70265197753906% Val Acc 27.05000114440918% Train Loss 0.41376960277557373 Val Loss 3.4077939987182617
Trainable Parameters : 198660
Epoch 36 Train Acc 68.36456298828125% Val Acc 25.000001907348633% Train Loss 0.4049733281135559 Val Loss 4.934237480163574
Trainable Parameters : 198660
Epoch 37 Train Acc 70.14664459228516% Val Acc 25.650001525878906% Train Loss 0.39814865589141846 Val Loss 4.084740161895752
Trainable Parameters : 198660
Epoch 38 Train Acc 69.17922973632812% Val Acc 25.350000381469727% Train Loss 0.39238670468330383 Val Loss 4.430087566375732
Trainable Parameters : 198660
Epoch 39 Train Acc 69.73931121826172% Val Acc 26.200000762939453% Train Loss 0.38340136408805847 Val Loss 4.433247089385986
Trainable Parameters : 198660
Epoch 40 Train Acc 68.61914825439453% Val Acc 27.000001907348633% Train Loss 0.3940364718437195 Val Loss 3.7722833156585693
Trainable Parameters : 198660
Epoch 41 Train Acc 69.2464370727539% Val Acc 25.650001525878906% Train Loss 0.39184847474098206 Val Loss 4.009364604949951
Trainable Parameters : 198660
Epoch 42 Train Acc 71.9613037109375% Val Acc 26.250001907348633% Train Loss 0.36651068925857544 Val Loss 3.8334298133850098
Trainable Parameters : 198660
Epoch 43 Train Acc 69.993896484375% Val Acc 25.400001525878906% Train Loss 0.3850073218345642 Val Loss 4.421654224395752
Trainable Parameters : 198660
Epoch 44 Train Acc 71.06314086914062% Val Acc 25.05000114440918% Train Loss 0.3651953935623169 Val Loss 4.762974262237549
Trainable Parameters : 198660
Fri Oct 14 00:28:19 AEDT 2022
------------------------------------------------------------------------
                         run_6s.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_6s.py
Started: 14/10/2022 00:28:21

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-6s
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 20
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-6s
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-6s_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 6 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0242, -0.0367, -0.0455,  ..., -0.2925, -0.3336, -0.3345],
        [-0.2633, -0.2296, -0.2588,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0378,  0.0419, -0.0140,  ..., -0.3312, -0.3817, -0.5506],
        ...,
        [-0.0143, -0.0173, -0.0059,  ..., -0.7033, -0.5777, -0.4124],
        [ 0.1292, -0.1432,  0.0192,  ..., -0.2328, -0.2681, -0.2022],
        [ 0.5533,  0.5500,  0.5821,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 3, 1, 1, 2, 3, 1, 0, 1, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2])}
Training DataCustom Files: 1963
Training Data Files: 99
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_q.bias', 'quantizer.codevectors', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'projector.weight', 'classifier.bias', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.1190, -0.1682, -0.1634,  ..., -1.3195, -0.4326,  1.5693],
        [ 0.2491,  0.3217,  0.3998,  ..., -1.8538, -1.4693, -0.9864],
        [ 0.0086,  0.0031, -0.0727,  ..., -1.5578, -1.2746, -0.8860],
        ...,
        [-2.7422, -2.5016, -2.3377,  ..., -0.0089,  0.0196,  0.0330],
        [-0.2024, -0.1708, -0.1320,  ..., -0.1604, -0.1440, -0.1371],
        [-0.0175, -0.0164, -0.0152,  ...,  0.0896,  0.0819,  0.0769]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 0, 0, 3, 2, 0, 3, 0, 3, 2, 2, 2, 2, 3, 0, 3, 3, 3, 3, 0])}
Test CustomData Files: 1997
Test Data Files: 100
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 23.73737335205078% Val Acc 22.799999237060547% Train Loss 0.6935275197029114 Val Loss 1.3879435062408447
Trainable Parameters : 198660
Epoch 1 Train Acc 27.050504684448242% Val Acc 22.619998931884766% Train Loss 0.692162275314331 Val Loss 1.388063907623291
Trainable Parameters : 198660
Epoch 2 Train Acc 28.88888931274414% Val Acc 22.739999771118164% Train Loss 0.6901107430458069 Val Loss 1.38905668258667
Trainable Parameters : 198660
Epoch 3 Train Acc 32.22222137451172% Val Acc 21.44999885559082% Train Loss 0.6869004964828491 Val Loss 1.390380620956421
Trainable Parameters : 198660
Epoch 4 Train Acc 34.52525329589844% Val Acc 20.889999389648438% Train Loss 0.6830589771270752 Val Loss 1.3924615383148193
Trainable Parameters : 198660
Epoch 5 Train Acc 36.33333206176758% Val Acc 21.899999618530273% Train Loss 0.6786754727363586 Val Loss 1.394890546798706
Trainable Parameters : 198660
Epoch 6 Train Acc 37.54545593261719% Val Acc 22.10999870300293% Train Loss 0.6736359000205994 Val Loss 1.3989834785461426
Trainable Parameters : 198660
Epoch 7 Train Acc 38.787879943847656% Val Acc 23.15999984741211% Train Loss 0.6690999865531921 Val Loss 1.4022200107574463
Trainable Parameters : 198660
Epoch 8 Train Acc 41.767677307128906% Val Acc 23.229999542236328% Train Loss 0.6636368036270142 Val Loss 1.4065649509429932
Trainable Parameters : 198660
Epoch 9 Train Acc 44.31312942504883% Val Acc 22.920000076293945% Train Loss 0.6565068364143372 Val Loss 1.4126009941101074
Trainable Parameters : 198660
Epoch 10 Train Acc 43.161617279052734% Val Acc 24.119998931884766% Train Loss 0.6502217650413513 Val Loss 1.4176676273345947
Trainable Parameters : 198660
Epoch 11 Train Acc 44.44444274902344% Val Acc 26.170000076293945% Train Loss 0.6429779529571533 Val Loss 1.4223155975341797
Trainable Parameters : 198660
Epoch 12 Train Acc 46.66666793823242% Val Acc 24.989999771118164% Train Loss 0.6354599595069885 Val Loss 1.4280705451965332
Trainable Parameters : 198660
Epoch 13 Train Acc 45.989898681640625% Val Acc 26.729999542236328% Train Loss 0.6287892460823059 Val Loss 1.4325395822525024
Trainable Parameters : 198660
Epoch 14 Train Acc 48.11111068725586% Val Acc 25.939998626708984% Train Loss 0.6223894953727722 Val Loss 1.4381070137023926
Trainable Parameters : 198660
Epoch 15 Train Acc 49.26262664794922% Val Acc 26.0% Train Loss 0.6132506728172302 Val Loss 1.4440370798110962
Trainable Parameters : 198660
Epoch 16 Train Acc 50.07070541381836% Val Acc 28.43000030517578% Train Loss 0.6046774983406067 Val Loss 1.4490880966186523
Trainable Parameters : 198660
Epoch 17 Train Acc 51.64646530151367% Val Acc 27.889999389648438% Train Loss 0.5961863398551941 Val Loss 1.4636179208755493
Trainable Parameters : 198660
Epoch 18 Train Acc 50.88888931274414% Val Acc 29.309999465942383% Train Loss 0.5884461998939514 Val Loss 1.4661903381347656
Trainable Parameters : 198660
Epoch 19 Train Acc 53.35353469848633% Val Acc 29.299999237060547% Train Loss 0.577159583568573 Val Loss 1.4741480350494385
Trainable Parameters : 198660
Epoch 20 Train Acc 54.57575607299805% Val Acc 29.689998626708984% Train Loss 0.5692068338394165 Val Loss 1.481755018234253
Trainable Parameters : 198660
Epoch 21 Train Acc 55.727272033691406% Val Acc 30.529998779296875% Train Loss 0.5577283501625061 Val Loss 1.4954938888549805
Trainable Parameters : 198660
Epoch 22 Train Acc 57.0% Val Acc 30.65999984741211% Train Loss 0.5475459098815918 Val Loss 1.506189227104187
Trainable Parameters : 198660
Epoch 23 Train Acc 57.54545593261719% Val Acc 29.899999618530273% Train Loss 0.5414278507232666 Val Loss 1.527166724205017
Trainable Parameters : 198660
Epoch 24 Train Acc 57.60606002807617% Val Acc 30.34000015258789% Train Loss 0.5335924029350281 Val Loss 1.530387043952942
Trainable Parameters : 198660
Epoch 25 Train Acc 58.93939208984375% Val Acc 30.689998626708984% Train Loss 0.5177198052406311 Val Loss 1.5539321899414062
Trainable Parameters : 198660
Epoch 26 Train Acc 59.292930603027344% Val Acc 31.0% Train Loss 0.5157502889633179 Val Loss 1.545661449432373
Trainable Parameters : 198660
Epoch 27 Train Acc 60.37373733520508% Val Acc 30.78999900817871% Train Loss 0.5000836849212646 Val Loss 1.5667002201080322
Trainable Parameters : 198660
Epoch 28 Train Acc 62.4040412902832% Val Acc 30.239999771118164% Train Loss 0.49905529618263245 Val Loss 1.615463376045227
Trainable Parameters : 198660
Epoch 29 Train Acc 62.84848403930664% Val Acc 31.389999389648438% Train Loss 0.48287343978881836 Val Loss 1.6362580060958862
Trainable Parameters : 198660
Epoch 30 Train Acc 62.97979736328125% Val Acc 31.349998474121094% Train Loss 0.4750254452228546 Val Loss 1.5860052108764648
Trainable Parameters : 198660
Epoch 31 Train Acc 64.21212005615234% Val Acc 30.439998626708984% Train Loss 0.4662579596042633 Val Loss 1.61900794506073
Trainable Parameters : 198660
Epoch 32 Train Acc 64.71717071533203% Val Acc 31.260000228881836% Train Loss 0.4592166841030121 Val Loss 1.6855250597000122
Trainable Parameters : 198660
Epoch 33 Train Acc 64.54545593261719% Val Acc 30.689998626708984% Train Loss 0.4479323923587799 Val Loss 1.6382089853286743
Trainable Parameters : 198660
Epoch 34 Train Acc 66.48484802246094% Val Acc 30.139999389648438% Train Loss 0.4423886239528656 Val Loss 1.7436002492904663
Trainable Parameters : 198660
Epoch 35 Train Acc 65.92929077148438% Val Acc 30.439998626708984% Train Loss 0.43206486105918884 Val Loss 1.714665174484253
Trainable Parameters : 198660
Epoch 36 Train Acc 67.54545593261719% Val Acc 30.389999389648438% Train Loss 0.4229485094547272 Val Loss 1.8113877773284912
Trainable Parameters : 198660
Epoch 37 Train Acc 68.45454406738281% Val Acc 30.529998779296875% Train Loss 0.41876494884490967 Val Loss 1.7551294565200806
Trainable Parameters : 198660
Epoch 38 Train Acc 68.6868667602539% Val Acc 29.489999771118164% Train Loss 0.41118624806404114 Val Loss 1.8602608442306519
Trainable Parameters : 198660
Epoch 39 Train Acc 69.8787841796875% Val Acc 29.81999969482422% Train Loss 0.4032822549343109 Val Loss 1.8807271718978882
Trainable Parameters : 198660
Epoch 40 Train Acc 69.44444274902344% Val Acc 30.389999389648438% Train Loss 0.39085477590560913 Val Loss 1.8311151266098022
Trainable Parameters : 198660
Epoch 41 Train Acc 70.97979736328125% Val Acc 31.049999237060547% Train Loss 0.3884359896183014 Val Loss 1.844046711921692
Trainable Parameters : 198660
Epoch 42 Train Acc 71.39393615722656% Val Acc 29.84000015258789% Train Loss 0.38006970286369324 Val Loss 1.85117506980896
Trainable Parameters : 198660
Epoch 43 Train Acc 71.24242401123047% Val Acc 30.510000228881836% Train Loss 0.3746340572834015 Val Loss 1.9077268838882446
Trainable Parameters : 198660
Epoch 44 Train Acc 71.88888549804688% Val Acc 30.389999389648438% Train Loss 0.3758425712585449 Val Loss 1.8472764492034912
Trainable Parameters : 198660
Epoch 45 Train Acc 72.60606384277344% Val Acc 30.59000015258789% Train Loss 0.36910444498062134 Val Loss 1.9649308919906616
Trainable Parameters : 198660
Epoch 46 Train Acc 71.79798126220703% Val Acc 31.03999900817871% Train Loss 0.3699384033679962 Val Loss 1.8587177991867065
Trainable Parameters : 198660
Epoch 47 Train Acc 73.41413879394531% Val Acc 29.84000015258789% Train Loss 0.35192084312438965 Val Loss 1.9550443887710571
Trainable Parameters : 198660
Epoch 48 Train Acc 73.86869049072266% Val Acc 31.329999923706055% Train Loss 0.3534930944442749 Val Loss 1.9673601388931274
Trainable Parameters : 198660
Epoch 49 Train Acc 73.20201873779297% Val Acc 30.34000015258789% Train Loss 0.34534314274787903 Val Loss 2.1383566856384277
Trainable Parameters : 198660
Epoch 50 Train Acc 73.88888549804688% Val Acc 30.389999389648438% Train Loss 0.34047845005989075 Val Loss 2.3951430320739746
Trainable Parameters : 198660
Epoch 51 Train Acc 73.55555725097656% Val Acc 30.849998474121094% Train Loss 0.3450009822845459 Val Loss 2.0920250415802
Trainable Parameters : 198660
Epoch 52 Train Acc 74.79798126220703% Val Acc 31.799999237060547% Train Loss 0.3301492929458618 Val Loss 2.0481178760528564
Trainable Parameters : 198660
Epoch 53 Train Acc 74.79798126220703% Val Acc 30.739999771118164% Train Loss 0.33061715960502625 Val Loss 2.016078472137451
Trainable Parameters : 198660
Epoch 54 Train Acc 75.9595947265625% Val Acc 30.329999923706055% Train Loss 0.3238604664802551 Val Loss 2.2416231632232666
Trainable Parameters : 198660
Epoch 55 Train Acc 74.919189453125% Val Acc 28.849998474121094% Train Loss 0.3329123556613922 Val Loss 2.372180938720703
Trainable Parameters : 198660
Epoch 56 Train Acc 76.16161346435547% Val Acc 31.529998779296875% Train Loss 0.32000091671943665 Val Loss 2.1138362884521484
Trainable Parameters : 198660
Epoch 57 Train Acc 76.11111450195312% Val Acc 30.09000015258789% Train Loss 0.31752538681030273 Val Loss 2.494966745376587
Trainable Parameters : 198660
Epoch 58 Train Acc 76.44444274902344% Val Acc 29.689998626708984% Train Loss 0.3181670308113098 Val Loss 2.5248606204986572
Trainable Parameters : 198660
Epoch 59 Train Acc 76.96969604492188% Val Acc 29.729999542236328% Train Loss 0.3137599229812622 Val Loss 2.4565560817718506
Trainable Parameters : 198660
Epoch 60 Train Acc 76.98989868164062% Val Acc 30.119998931884766% Train Loss 0.30370867252349854 Val Loss 2.281057596206665
Trainable Parameters : 198660
Epoch 61 Train Acc 77.32323455810547% Val Acc 29.65999984741211% Train Loss 0.30254945158958435 Val Loss 2.746917963027954
Trainable Parameters : 198660
Epoch 62 Train Acc 76.79798126220703% Val Acc 30.739999771118164% Train Loss 0.30665674805641174 Val Loss 2.5093863010406494
Trainable Parameters : 198660
Epoch 63 Train Acc 78.88888549804688% Val Acc 29.75% Train Loss 0.2938634157180786 Val Loss 2.6328396797180176
Trainable Parameters : 198660
Epoch 64 Train Acc 77.97979736328125% Val Acc 30.049999237060547% Train Loss 0.29544344544410706 Val Loss 2.8977653980255127
Trainable Parameters : 198660
Epoch 65 Train Acc 76.78787994384766% Val Acc 30.56999969482422% Train Loss 0.300070583820343 Val Loss 2.8538315296173096
Trainable Parameters : 198660
Epoch 66 Train Acc 77.8787841796875% Val Acc 30.889999389648438% Train Loss 0.29014018177986145 Val Loss 2.739511251449585
Trainable Parameters : 198660
Epoch 67 Train Acc 78.2323226928711% Val Acc 30.53999900817871% Train Loss 0.29212382435798645 Val Loss 2.777331590652466
Trainable Parameters : 198660
Epoch 68 Train Acc 78.28282928466797% Val Acc 30.53999900817871% Train Loss 0.28803059458732605 Val Loss 2.536839723587036
Trainable Parameters : 198660
Epoch 69 Train Acc 78.65656280517578% Val Acc 30.719999313354492% Train Loss 0.2830374836921692 Val Loss 2.517402410507202
Trainable Parameters : 198660
Epoch 70 Train Acc 77.89898681640625% Val Acc 29.439998626708984% Train Loss 0.28945398330688477 Val Loss 2.508948564529419
Trainable Parameters : 198660
Epoch 71 Train Acc 78.03030395507812% Val Acc 30.760000228881836% Train Loss 0.28140005469322205 Val Loss 2.484128952026367
Trainable Parameters : 198660
Epoch 72 Train Acc 78.9595947265625% Val Acc 31.149999618530273% Train Loss 0.28541168570518494 Val Loss 3.1224663257598877
Trainable Parameters : 198660
Epoch 73 Train Acc 79.11111450195312% Val Acc 30.28999900817871% Train Loss 0.2726917564868927 Val Loss 2.58302903175354
Trainable Parameters : 198660
Epoch 74 Train Acc 77.7272720336914% Val Acc 30.34000015258789% Train Loss 0.2817971706390381 Val Loss 2.9029555320739746
Trainable Parameters : 198660
Epoch 75 Train Acc 79.36363983154297% Val Acc 30.329999923706055% Train Loss 0.27456772327423096 Val Loss 2.7244224548339844
Trainable Parameters : 198660
Epoch 76 Train Acc 80.10101318359375% Val Acc 31.529998779296875% Train Loss 0.27667391300201416 Val Loss 2.3197195529937744
Trainable Parameters : 198660
Epoch 77 Train Acc 80.05050659179688% Val Acc 30.889999389648438% Train Loss 0.26811063289642334 Val Loss 2.6858181953430176
Trainable Parameters : 198660
Epoch 78 Train Acc 79.36363983154297% Val Acc 30.489999771118164% Train Loss 0.27320948243141174 Val Loss 2.5299019813537598
Trainable Parameters : 198660
Epoch 79 Train Acc 78.50505065917969% Val Acc 30.489999771118164% Train Loss 0.2693111300468445 Val Loss 3.0108444690704346
Trainable Parameters : 198660
Epoch 80 Train Acc 79.02020263671875% Val Acc 30.35999870300293% Train Loss 0.2686121463775635 Val Loss 2.874926805496216
Trainable Parameters : 198660
Epoch 81 Train Acc 79.24242401123047% Val Acc 31.17999839782715% Train Loss 0.2634075880050659 Val Loss 2.4798076152801514
Trainable Parameters : 198660
Epoch 82 Train Acc 79.21212005615234% Val Acc 30.28999900817871% Train Loss 0.2766951620578766 Val Loss 3.147852659225464
Trainable Parameters : 198660
Epoch 83 Train Acc 80.50505065917969% Val Acc 30.0% Train Loss 0.26502346992492676 Val Loss 3.447439193725586
Trainable Parameters : 198660
Epoch 84 Train Acc 79.7676773071289% Val Acc 30.44999885559082% Train Loss 0.25878769159317017 Val Loss 2.830437660217285
Trainable Parameters : 198660
Epoch 85 Train Acc 80.33333587646484% Val Acc 31.59000015258789% Train Loss 0.2654531002044678 Val Loss 2.753248453140259
Trainable Parameters : 198660
Epoch 86 Train Acc 81.01010131835938% Val Acc 31.489999771118164% Train Loss 0.2564096450805664 Val Loss 2.6770904064178467
Trainable Parameters : 198660
Epoch 87 Train Acc 80.62625885009766% Val Acc 31.149999618530273% Train Loss 0.26191574335098267 Val Loss 2.530487537384033
Trainable Parameters : 198660
Epoch 88 Train Acc 80.05050659179688% Val Acc 30.809999465942383% Train Loss 0.260810911655426 Val Loss 2.681851387023926
Trainable Parameters : 198660
Epoch 89 Train Acc 79.86869049072266% Val Acc 30.399999618530273% Train Loss 0.26054656505584717 Val Loss 3.1495468616485596
Trainable Parameters : 198660
Epoch 90 Train Acc 80.62625885009766% Val Acc 30.84000015258789% Train Loss 0.2557304799556732 Val Loss 3.0522005558013916
Trainable Parameters : 198660
Epoch 91 Train Acc 79.69696807861328% Val Acc 31.049999237060547% Train Loss 0.27406808733940125 Val Loss 3.101548910140991
Trainable Parameters : 198660
Epoch 92 Train Acc 80.22222137451172% Val Acc 30.84000015258789% Train Loss 0.26787281036376953 Val Loss 3.1935548782348633
Trainable Parameters : 198660
Epoch 93 Train Acc 81.61616516113281% Val Acc 29.78999900817871% Train Loss 0.2508358061313629 Val Loss 3.0617165565490723
Trainable Parameters : 198660
Epoch 94 Train Acc 80.40403747558594% Val Acc 30.239999771118164% Train Loss 0.24830789864063263 Val Loss 2.7232565879821777
Trainable Parameters : 198660
Epoch 95 Train Acc 80.47474670410156% Val Acc 32.0099983215332% Train Loss 0.25559744238853455 Val Loss 2.4907236099243164
Trainable Parameters : 198660
Epoch 96 Train Acc 80.45454406738281% Val Acc 31.979999542236328% Train Loss 0.2596738040447235 Val Loss 2.8800621032714844
Trainable Parameters : 198660
Epoch 97 Train Acc 80.10101318359375% Val Acc 30.59000015258789% Train Loss 0.26232895255088806 Val Loss 3.1401681900024414
Trainable Parameters : 198660
Epoch 98 Train Acc 80.83838653564453% Val Acc 31.059999465942383% Train Loss 0.2568536102771759 Val Loss 3.077883243560791
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-6s/config.json
Epoch 99 Train Acc 80.7272720336914% Val Acc 31.59000015258789% Train Loss 0.25699231028556824 Val Loss 2.4086344242095947
Traceback (most recent call last):
  File "run_6s.py", line 710, in <module>
    model.module.save_pretrained(model_fp)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1657, in save_pretrained
    save_function(shard, os.path.join(save_directory, shard_file))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 381, in save
    return
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in __exit__
    self.file_like.close()
OSError: [Errno 122] Disk quota exceeded
