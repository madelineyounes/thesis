Mon Oct 10 14:27:40 AEDT 2022
------------------------------------------------------------------------
                         run_w2v.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_w2v.py
Started: 10/10/2022 14:27:44

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-w2v
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-w2v
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-w2v_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.7929, -0.8289, -0.8241,  ...,  0.0000,  0.0000,  0.0000],
        [-1.1903, -1.2624, -0.7926,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7058, -0.2130,  0.3337,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.9378,  1.1650,  1.3046,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7635, -0.5795, -0.4703,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2356,  0.8698,  1.8955,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 1, 0, 3, 2, 0, 2, 3, 1, 2, 3, 3])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.weight', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'classifier.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 3.3494,  3.9602,  4.3515,  ...,  0.0000,  0.0000,  0.0000],
        [ 2.4396,  2.1874,  0.7738,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1674, -0.0682, -0.0856,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.4901, -0.5992, -0.6270,  ...,  0.0000,  0.0000,  0.0000],
        [ 2.3572,  2.3723,  2.4055,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0986, -0.0721,  0.1168,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 0, 0, 2, 0, 3, 0, 2, 2, 0, 1])}
Test CustomData Files: 398
Test Data Files: 34
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  4 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 25.378047943115234% Val Acc 24.41176414489746% Train Loss 0.6950516104698181 Val Loss 1.3892368078231812
Trainable Parameters : 198660
Epoch 1 Train Acc 25.25% Val Acc 23.97058868408203% Train Loss 0.6935300230979919 Val Loss 1.39143967628479
Trainable Parameters : 198660
Epoch 2 Train Acc 27.96341323852539% Val Acc 21.294116973876953% Train Loss 0.6909712553024292 Val Loss 1.3905423879623413
Trainable Parameters : 198660
Epoch 3 Train Acc 32.32316970825195% Val Acc 21.58823585510254% Train Loss 0.688391387462616 Val Loss 1.39081871509552
Trainable Parameters : 198660
Epoch 4 Train Acc 32.59756088256836% Val Acc 20.852941513061523% Train Loss 0.686591386795044 Val Loss 1.3977981805801392
Trainable Parameters : 198660
Epoch 5 Train Acc 34.81097412109375% Val Acc 23.235294342041016% Train Loss 0.6822067499160767 Val Loss 1.394766926765442
Trainable Parameters : 198660
Epoch 6 Train Acc 34.664634704589844% Val Acc 19.647058486938477% Train Loss 0.6796102523803711 Val Loss 1.4067895412445068
Trainable Parameters : 198660
Epoch 7 Train Acc 35.1219482421875% Val Acc 21.41176414489746% Train Loss 0.6747971773147583 Val Loss 1.4142882823944092
Trainable Parameters : 198660
Epoch 8 Train Acc 36.189022064208984% Val Acc 20.55882453918457% Train Loss 0.6703673601150513 Val Loss 1.4253120422363281
Trainable Parameters : 198660
Epoch 9 Train Acc 36.841461181640625% Val Acc 19.352941513061523% Train Loss 0.6661807298660278 Val Loss 1.452587604522705
Trainable Parameters : 198660
Epoch 10 Train Acc 36.94512176513672% Val Acc 21.47058868408203% Train Loss 0.662270188331604 Val Loss 1.4579918384552002
Trainable Parameters : 198660
Epoch 11 Train Acc 38.57316970825195% Val Acc 21.91176414489746% Train Loss 0.656520426273346 Val Loss 1.4628138542175293
Trainable Parameters : 198660
Epoch 12 Train Acc 38.2621955871582% Val Acc 21.08823585510254% Train Loss 0.65274578332901 Val Loss 1.511415958404541
Trainable Parameters : 198660
Epoch 13 Train Acc 39.56097412109375% Val Acc 21.08823585510254% Train Loss 0.6467868685722351 Val Loss 1.4966857433319092
Trainable Parameters : 198660
Epoch 14 Train Acc 40.45731735229492% Val Acc 20.382352828979492% Train Loss 0.6410984396934509 Val Loss 1.5607845783233643
Trainable Parameters : 198660
Epoch 15 Train Acc 41.8719482421875% Val Acc 22.08823585510254% Train Loss 0.6342626214027405 Val Loss 1.5830771923065186
Trainable Parameters : 198660
Epoch 16 Train Acc 42.243900299072266% Val Acc 22.05882453918457% Train Loss 0.6289440989494324 Val Loss 1.6063958406448364
Trainable Parameters : 198660
Epoch 17 Train Acc 44.036582946777344% Val Acc 23.117647171020508% Train Loss 0.6230766773223877 Val Loss 1.6638209819793701
Trainable Parameters : 198660
Epoch 18 Train Acc 43.493900299072266% Val Acc 23.97058868408203% Train Loss 0.6163866519927979 Val Loss 1.6416041851043701
Trainable Parameters : 198660
Epoch 19 Train Acc 45.780487060546875% Val Acc 25.02941131591797% Train Loss 0.6104452610015869 Val Loss 1.6597808599472046
Trainable Parameters : 198660
Epoch 20 Train Acc 45.82926559448242% Val Acc 23.794116973876953% Train Loss 0.6038013100624084 Val Loss 1.7293751239776611
Trainable Parameters : 198660
Epoch 21 Train Acc 47.92682647705078% Val Acc 22.97058868408203% Train Loss 0.5936527252197266 Val Loss 1.786874771118164
Trainable Parameters : 198660
Epoch 22 Train Acc 49.23170471191406% Val Acc 22.823530197143555% Train Loss 0.58835369348526 Val Loss 1.8728039264678955
Trainable Parameters : 198660
Epoch 23 Train Acc 49.34756088256836% Val Acc 26.441177368164062% Train Loss 0.5829821825027466 Val Loss 1.7656832933425903
Trainable Parameters : 198660
Epoch 24 Train Acc 50.804874420166016% Val Acc 22.764705657958984% Train Loss 0.5731979012489319 Val Loss 1.9104607105255127
Trainable Parameters : 198660
Epoch 25 Train Acc 51.743900299072266% Val Acc 23.5% Train Loss 0.5659366250038147 Val Loss 1.9080476760864258
Trainable Parameters : 198660
Epoch 26 Train Acc 52.32926559448242% Val Acc 23.323530197143555% Train Loss 0.5661601424217224 Val Loss 2.0799942016601562
Trainable Parameters : 198660
Epoch 27 Train Acc 53.70121765136719% Val Acc 25.91176414489746% Train Loss 0.5530881881713867 Val Loss 2.0429227352142334
Trainable Parameters : 198660
Epoch 28 Train Acc 52.69512176513672% Val Acc 22.47058868408203% Train Loss 0.5493921041488647 Val Loss 2.136160135269165
Trainable Parameters : 198660
Epoch 29 Train Acc 54.939022064208984% Val Acc 26.705883026123047% Train Loss 0.5393663048744202 Val Loss 2.136124610900879
Trainable Parameters : 198660
Epoch 30 Train Acc 54.652435302734375% Val Acc 21.882352828979492% Train Loss 0.534270167350769 Val Loss 2.165384292602539
Trainable Parameters : 198660
Epoch 31 Train Acc 56.189022064208984% Val Acc 22.97058868408203% Train Loss 0.5262385606765747 Val Loss 2.372393846511841
Trainable Parameters : 198660
Epoch 32 Train Acc 56.749996185302734% Val Acc 26.235294342041016% Train Loss 0.5219817757606506 Val Loss 2.303941011428833
Trainable Parameters : 198660
Epoch 33 Train Acc 57.152435302734375% Val Acc 25.52941131591797% Train Loss 0.5185041427612305 Val Loss 2.2850699424743652
Trainable Parameters : 198660
Epoch 34 Train Acc 57.25609588623047% Val Acc 25.97058868408203% Train Loss 0.5077404379844666 Val Loss 2.2946324348449707
Trainable Parameters : 198660
Epoch 35 Train Acc 59.36585235595703% Val Acc 25.52941131591797% Train Loss 0.5014116168022156 Val Loss 2.3774900436401367
Trainable Parameters : 198660
Epoch 36 Train Acc 59.65853500366211% Val Acc 26.176469802856445% Train Loss 0.49181798100471497 Val Loss 3.05505633354187
Trainable Parameters : 198660
Epoch 37 Train Acc 58.77438735961914% Val Acc 26.441177368164062% Train Loss 0.49504730105400085 Val Loss 2.5327887535095215
Trainable Parameters : 198660
Epoch 38 Train Acc 59.896339416503906% Val Acc 25.676469802856445% Train Loss 0.4822084307670593 Val Loss 2.7843639850616455
Trainable Parameters : 198660
Epoch 39 Train Acc 60.286582946777344% Val Acc 24.02941131591797% Train Loss 0.48393118381500244 Val Loss 2.572568893432617
Trainable Parameters : 198660
Epoch 40 Train Acc 61.335365295410156% Val Acc 25.97058868408203% Train Loss 0.4799208641052246 Val Loss 2.741537094116211
Trainable Parameters : 198660
Epoch 41 Train Acc 61.8841438293457% Val Acc 24.941177368164062% Train Loss 0.47359544038772583 Val Loss 3.026355743408203
Trainable Parameters : 198660
Epoch 42 Train Acc 62.786582946777344% Val Acc 24.52941131591797% Train Loss 0.47112810611724854 Val Loss 2.857309103012085
Trainable Parameters : 198660
Epoch 43 Train Acc 63.16463088989258% Val Acc 26.91176414489746% Train Loss 0.46290117502212524 Val Loss 2.664736032485962
Trainable Parameters : 198660
Epoch 44 Train Acc 61.932926177978516% Val Acc 25.52941131591797% Train Loss 0.4606165885925293 Val Loss 2.9723312854766846
Trainable Parameters : 198660
Epoch 45 Train Acc 63.054874420166016% Val Acc 25.52941131591797% Train Loss 0.4638301432132721 Val Loss 3.0560925006866455
Trainable Parameters : 198660
Epoch 46 Train Acc 62.92073059082031% Val Acc 21.764705657958984% Train Loss 0.4579343795776367 Val Loss 2.98144793510437
Trainable Parameters : 198660
Epoch 47 Train Acc 63.73780059814453% Val Acc 26.176469802856445% Train Loss 0.45228978991508484 Val Loss 2.8235011100769043
Trainable Parameters : 198660
Epoch 48 Train Acc 63.286582946777344% Val Acc 24.264705657958984% Train Loss 0.4512365162372589 Val Loss 3.127436399459839
Trainable Parameters : 198660
Epoch 49 Train Acc 63.98170471191406% Val Acc 27.852941513061523% Train Loss 0.4538092017173767 Val Loss 2.5442724227905273
Trainable Parameters : 198660
Epoch 50 Train Acc 65.15243530273438% Val Acc 25.235294342041016% Train Loss 0.4389517903327942 Val Loss 3.05196213722229
Trainable Parameters : 198660
Epoch 51 Train Acc 64.68901824951172% Val Acc 25.441177368164062% Train Loss 0.44226691126823425 Val Loss 3.212393045425415
Trainable Parameters : 198660
Epoch 52 Train Acc 63.73780059814453% Val Acc 24.441177368164062% Train Loss 0.4378276765346527 Val Loss 3.0377230644226074
Trainable Parameters : 198660
Epoch 53 Train Acc 65.96951293945312% Val Acc 24.235294342041016% Train Loss 0.4309060871601105 Val Loss 3.186845064163208
Trainable Parameters : 198660
Epoch 54 Train Acc 64.75% Val Acc 24.5% Train Loss 0.43616920709609985 Val Loss 3.5807785987854004
Trainable Parameters : 198660
Epoch 55 Train Acc 63.902435302734375% Val Acc 25.52941131591797% Train Loss 0.43332093954086304 Val Loss 2.9610698223114014
Trainable Parameters : 198660
Epoch 56 Train Acc 66.5% Val Acc 26.5% Train Loss 0.41952967643737793 Val Loss 2.7040419578552246
Trainable Parameters : 198660
Epoch 57 Train Acc 65.64024353027344% Val Acc 25.05882453918457% Train Loss 0.4233410358428955 Val Loss 2.701996326446533
Trainable Parameters : 198660
Epoch 58 Train Acc 66.34146118164062% Val Acc 25.235294342041016% Train Loss 0.41893142461776733 Val Loss 3.066178560256958
Trainable Parameters : 198660
Epoch 59 Train Acc 67.04877471923828% Val Acc 23.264705657958984% Train Loss 0.41629013419151306 Val Loss 3.690286159515381
Trainable Parameters : 198660
Epoch 60 Train Acc 65.44512176513672% Val Acc 24.55882453918457% Train Loss 0.41593262553215027 Val Loss 3.0912723541259766
Trainable Parameters : 198660
Epoch 61 Train Acc 67.82926940917969% Val Acc 23.176469802856445% Train Loss 0.3980073928833008 Val Loss 3.6653480529785156
Trainable Parameters : 198660
Epoch 62 Train Acc 67.80487823486328% Val Acc 25.52941131591797% Train Loss 0.41108712553977966 Val Loss 3.5339536666870117
Trainable Parameters : 198660
Epoch 63 Train Acc 68.41463470458984% Val Acc 23.5% Train Loss 0.3997723162174225 Val Loss 3.5262553691864014
Trainable Parameters : 198660
Epoch 64 Train Acc 67.40243530273438% Val Acc 23.5% Train Loss 0.40034613013267517 Val Loss 3.584087610244751
Trainable Parameters : 198660
