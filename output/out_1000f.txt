Mon Oct 10 03:01:04 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_500f.py
Started: 10/10/2022 03:01:08

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-500-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.5560e-01,  1.0507e-01,  1.5982e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.5074e-03,  7.2549e-03, -1.4235e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.7804e-01, -1.8382e-01, -6.6453e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 1.4459e-01,  1.2123e-01,  1.1584e-01,  ...,  2.1693e+00,
          1.7339e+00,  1.3007e+00],
        [ 9.7513e-01,  1.2202e+00,  1.2507e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.8948e-01,  2.5500e-01,  1.7960e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 2, 3, 0, 2, 2, 0, 0, 3, 0, 1])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.codevectors', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.weight', 'projector.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 8.7424e-01,  8.5100e-01,  7.9191e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.1801e-01, -6.1852e-02, -1.0126e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 6.4287e-02,  5.5718e-02,  1.0538e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 3.1119e-01, -2.5085e-01,  3.5707e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.4606e+00,  6.9502e+00,  7.2792e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.9109e-02, -2.2954e-01, -2.9814e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 3, 0, 3, 0, 3, 1, 1, 3, 1, 3])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 27.573169708251953% Val Acc 25.970060348510742% Train Loss 0.6921254992485046 Val Loss 1.386112928390503
Trainable Parameters : 198660
Epoch 1 Train Acc 28.591463088989258% Val Acc 23.916168212890625% Train Loss 0.690926730632782 Val Loss 1.3860269784927368
Trainable Parameters : 198660
Epoch 2 Train Acc 32.04877853393555% Val Acc 23.520959854125977% Train Loss 0.6883280873298645 Val Loss 1.3875173330307007
Trainable Parameters : 198660
Epoch 3 Train Acc 31.981706619262695% Val Acc 23.970060348510742% Train Loss 0.686112642288208 Val Loss 1.3882125616073608
Trainable Parameters : 198660
Epoch 4 Train Acc 33.146339416503906% Val Acc 23.497007369995117% Train Loss 0.6827237606048584 Val Loss 1.3911885023117065
Trainable Parameters : 198660
Epoch 5 Train Acc 35.15243911743164% Val Acc 23.9940128326416% Train Loss 0.6792387962341309 Val Loss 1.3933409452438354
Trainable Parameters : 198660
Epoch 6 Train Acc 35.39024353027344% Val Acc 22.329341888427734% Train Loss 0.6761834621429443 Val Loss 1.4065639972686768
Trainable Parameters : 198660
Epoch 7 Train Acc 35.70731735229492% Val Acc 23.934133529663086% Train Loss 0.6720531582832336 Val Loss 1.4077821969985962
Trainable Parameters : 198660
Epoch 8 Train Acc 36.0% Val Acc 22.84431266784668% Train Loss 0.6686638593673706 Val Loss 1.415639042854309
Trainable Parameters : 198660
Epoch 9 Train Acc 38.0% Val Acc 22.526947021484375% Train Loss 0.6640304923057556 Val Loss 1.4263176918029785
Trainable Parameters : 198660
Epoch 10 Train Acc 37.2621955871582% Val Acc 22.790420532226562% Train Loss 0.6592988967895508 Val Loss 1.4506540298461914
Trainable Parameters : 198660
Epoch 11 Train Acc 38.286582946777344% Val Acc 23.45509147644043% Train Loss 0.6535123586654663 Val Loss 1.458675742149353
Trainable Parameters : 198660
Epoch 12 Train Acc 39.1219482421875% Val Acc 22.84431266784668% Train Loss 0.6506932377815247 Val Loss 1.4929639101028442
Trainable Parameters : 198660
Epoch 13 Train Acc 38.48170471191406% Val Acc 23.694612503051758% Train Loss 0.644037663936615 Val Loss 1.487052321434021
Trainable Parameters : 198660
Epoch 14 Train Acc 40.34756088256836% Val Acc 22.718563079833984% Train Loss 0.640159547328949 Val Loss 1.5279791355133057
Trainable Parameters : 198660
Epoch 15 Train Acc 42.10365676879883% Val Acc 23.19760513305664% Train Loss 0.6335709691047668 Val Loss 1.533288836479187
Trainable Parameters : 198660
Epoch 16 Train Acc 43.76219177246094% Val Acc 24.43712615966797% Train Loss 0.6272653937339783 Val Loss 1.5498543977737427
Trainable Parameters : 198660
Epoch 17 Train Acc 43.682926177978516% Val Acc 23.20958137512207% Train Loss 0.6231908202171326 Val Loss 1.6068605184555054
Trainable Parameters : 198660
Epoch 18 Train Acc 44.17682647705078% Val Acc 23.61077880859375% Train Loss 0.6147034168243408 Val Loss 1.5978984832763672
Trainable Parameters : 198660
Epoch 19 Train Acc 46.341461181640625% Val Acc 24.179641723632812% Train Loss 0.6033933758735657 Val Loss 1.6354951858520508
Trainable Parameters : 198660
Epoch 20 Train Acc 47.04877853393555% Val Acc 23.299402236938477% Train Loss 0.5960630178451538 Val Loss 1.7233929634094238
Trainable Parameters : 198660
Epoch 21 Train Acc 47.878047943115234% Val Acc 23.9940128326416% Train Loss 0.5906317830085754 Val Loss 1.6998475790023804
Trainable Parameters : 198660
Epoch 22 Train Acc 48.66463088989258% Val Acc 24.970060348510742% Train Loss 0.5844171643257141 Val Loss 1.8465780019760132
Trainable Parameters : 198660
Epoch 23 Train Acc 49.91463088989258% Val Acc 25.05389404296875% Train Loss 0.579992949962616 Val Loss 1.7106014490127563
Trainable Parameters : 198660
Epoch 24 Train Acc 50.8597526550293% Val Acc 24.125749588012695% Train Loss 0.5679834485054016 Val Loss 1.8518081903457642
Trainable Parameters : 198660
Epoch 25 Train Acc 51.92682647705078% Val Acc 25.18562889099121% Train Loss 0.5619426965713501 Val Loss 1.8394949436187744
Trainable Parameters : 198660
Epoch 26 Train Acc 52.493900299072266% Val Acc 24.802396774291992% Train Loss 0.5613855719566345 Val Loss 1.9742289781570435
Trainable Parameters : 198660
Epoch 27 Train Acc 52.86585235595703% Val Acc 24.934133529663086% Train Loss 0.5504640936851501 Val Loss 1.9480339288711548
Trainable Parameters : 198660
Epoch 28 Train Acc 53.40853500366211% Val Acc 25.401199340820312% Train Loss 0.5464589595794678 Val Loss 2.2419066429138184
Trainable Parameters : 198660
Epoch 29 Train Acc 55.02438735961914% Val Acc 27.155689239501953% Train Loss 0.5380857586860657 Val Loss 2.087872266769409
Trainable Parameters : 198660
Epoch 30 Train Acc 55.8719482421875% Val Acc 25.43712615966797% Train Loss 0.5302569270133972 Val Loss 2.0973987579345703
Trainable Parameters : 198660
Epoch 31 Train Acc 56.8597526550293% Val Acc 24.736528396606445% Train Loss 0.5196149349212646 Val Loss 2.173734664916992
Trainable Parameters : 198660
Epoch 32 Train Acc 57.02438735961914% Val Acc 26.251497268676758% Train Loss 0.5221918225288391 Val Loss 2.0630438327789307
Trainable Parameters : 198660
Epoch 33 Train Acc 57.29268264770508% Val Acc 26.65868377685547% Train Loss 0.5104029178619385 Val Loss 2.2734696865081787
Trainable Parameters : 198660
Epoch 34 Train Acc 57.878047943115234% Val Acc 26.520959854125977% Train Loss 0.5033010244369507 Val Loss 2.2573304176330566
Trainable Parameters : 198660
Epoch 35 Train Acc 59.46341323852539% Val Acc 25.766468048095703% Train Loss 0.4990711510181427 Val Loss 2.4305343627929688
Trainable Parameters : 198660
Epoch 36 Train Acc 59.54267883300781% Val Acc 25.988025665283203% Train Loss 0.4918382465839386 Val Loss 2.8491125106811523
Trainable Parameters : 198660
Epoch 37 Train Acc 60.14024353027344% Val Acc 26.377246856689453% Train Loss 0.4879423677921295 Val Loss 2.5638134479522705
Trainable Parameters : 198660
Epoch 38 Train Acc 61.335365295410156% Val Acc 26.341318130493164% Train Loss 0.48424866795539856 Val Loss 2.593747138977051
Trainable Parameters : 198660
Epoch 39 Train Acc 61.9878044128418% Val Acc 26.886228561401367% Train Loss 0.47908642888069153 Val Loss 2.6266613006591797
Trainable Parameters : 198660
Epoch 40 Train Acc 62.646339416503906% Val Acc 25.61676788330078% Train Loss 0.4727540612220764 Val Loss 2.5626561641693115
Trainable Parameters : 198660
Epoch 41 Train Acc 61.847557067871094% Val Acc 24.814373016357422% Train Loss 0.4752179980278015 Val Loss 2.9019153118133545
Trainable Parameters : 198660
Epoch 42 Train Acc 63.54267883300781% Val Acc 25.41916275024414% Train Loss 0.4653604030609131 Val Loss 2.719233274459839
Trainable Parameters : 198660
Epoch 43 Train Acc 62.835365295410156% Val Acc 26.18562889099121% Train Loss 0.4651263952255249 Val Loss 2.7493369579315186
Trainable Parameters : 198660
Epoch 44 Train Acc 63.207313537597656% Val Acc 25.293415069580078% Train Loss 0.4580838084220886 Val Loss 3.096198558807373
Trainable Parameters : 198660
Epoch 45 Train Acc 62.786582946777344% Val Acc 25.7724552154541% Train Loss 0.45625588297843933 Val Loss 3.0339019298553467
Trainable Parameters : 198660
Epoch 46 Train Acc 63.46950912475586% Val Acc 25.39521026611328% Train Loss 0.4600556790828705 Val Loss 2.912964105606079
Trainable Parameters : 198660
Epoch 47 Train Acc 64.16463470458984% Val Acc 25.04790496826172% Train Loss 0.44983288645744324 Val Loss 2.6885077953338623
Trainable Parameters : 198660
Epoch 48 Train Acc 63.786582946777344% Val Acc 24.83233642578125% Train Loss 0.448271244764328 Val Loss 3.0041897296905518
Trainable Parameters : 198660
Epoch 49 Train Acc 63.95121765136719% Val Acc 25.83832359313965% Train Loss 0.4533887505531311 Val Loss 2.940715789794922
Trainable Parameters : 198660
Epoch 50 Train Acc 65.69512176513672% Val Acc 25.61077880859375% Train Loss 0.4373506009578705 Val Loss 3.070552349090576
Trainable Parameters : 198660
Epoch 51 Train Acc 64.53048706054688% Val Acc 24.82036018371582% Train Loss 0.4390254318714142 Val Loss 3.270648241043091
Trainable Parameters : 198660
Epoch 52 Train Acc 64.12804412841797% Val Acc 25.461078643798828% Train Loss 0.4374025762081146 Val Loss 3.075981616973877
Trainable Parameters : 198660
Epoch 53 Train Acc 65.67073059082031% Val Acc 26.125749588012695% Train Loss 0.4287995398044586 Val Loss 3.0164434909820557
Trainable Parameters : 198660
Epoch 54 Train Acc 65.243896484375% Val Acc 24.700599670410156% Train Loss 0.43139949440956116 Val Loss 3.566986322402954
Trainable Parameters : 198660
Epoch 55 Train Acc 65.78048706054688% Val Acc 25.60479164123535% Train Loss 0.42647257447242737 Val Loss 2.93770432472229
Trainable Parameters : 198660
Epoch 56 Train Acc 64.50609588623047% Val Acc 27.119762420654297% Train Loss 0.4298408627510071 Val Loss 2.6958236694335938
Trainable Parameters : 198660
Epoch 57 Train Acc 66.30487823486328% Val Acc 25.263473510742188% Train Loss 0.4278033971786499 Val Loss 2.837838649749756
Trainable Parameters : 198660
Epoch 58 Train Acc 66.89024353027344% Val Acc 25.736528396606445% Train Loss 0.41869837045669556 Val Loss 3.0285861492156982
Trainable Parameters : 198660
Epoch 59 Train Acc 67.493896484375% Val Acc 24.766468048095703% Train Loss 0.4094911813735962 Val Loss 3.8233420848846436
Trainable Parameters : 198660
Epoch 60 Train Acc 66.58536529541016% Val Acc 25.502994537353516% Train Loss 0.41782939434051514 Val Loss 3.163722038269043
Trainable Parameters : 198660
Epoch 61 Train Acc 67.7256088256836% Val Acc 25.2215576171875% Train Loss 0.4147942066192627 Val Loss 3.188894748687744
Trainable Parameters : 198660
Epoch 62 Train Acc 66.5975570678711% Val Acc 24.59880256652832% Train Loss 0.4104868471622467 Val Loss 3.9851737022399902
Trainable Parameters : 198660
Epoch 63 Train Acc 68.71340942382812% Val Acc 24.526947021484375% Train Loss 0.4039415419101715 Val Loss 4.1703782081604
Trainable Parameters : 198660
Epoch 64 Train Acc 68.08536529541016% Val Acc 25.317365646362305% Train Loss 0.40280213952064514 Val Loss 3.538083553314209
Trainable Parameters : 198660
Epoch 65 Train Acc 68.20731353759766% Val Acc 25.461078643798828% Train Loss 0.4005885422229767 Val Loss 4.037206172943115
Trainable Parameters : 198660
Epoch 66 Train Acc 68.04877471923828% Val Acc 25.26946258544922% Train Loss 0.3971952795982361 Val Loss 4.242782115936279
Trainable Parameters : 198660
Epoch 67 Train Acc 68.44512176513672% Val Acc 24.574851989746094% Train Loss 0.3991399109363556 Val Loss 3.8262436389923096
Trainable Parameters : 198660
Epoch 68 Train Acc 69.53658294677734% Val Acc 25.45509147644043% Train Loss 0.3860589563846588 Val Loss 3.9519968032836914
Trainable Parameters : 198660
Epoch 69 Train Acc 69.56097412109375% Val Acc 26.155689239501953% Train Loss 0.3866167664527893 Val Loss 3.4069671630859375
Trainable Parameters : 198660
Epoch 70 Train Acc 69.41463470458984% Val Acc 23.952096939086914% Train Loss 0.3815310001373291 Val Loss 3.4258501529693604
Trainable Parameters : 198660
Epoch 71 Train Acc 70.45121765136719% Val Acc 24.359281539916992% Train Loss 0.3911740779876709 Val Loss 4.5513105392456055
Trainable Parameters : 198660
Epoch 72 Train Acc 69.68292236328125% Val Acc 25.479042053222656% Train Loss 0.3824985921382904 Val Loss 3.7248101234436035
Trainable Parameters : 198660
Epoch 73 Train Acc 70.81097412109375% Val Acc 25.778444290161133% Train Loss 0.3762827515602112 Val Loss 4.326137542724609
Trainable Parameters : 198660
Epoch 74 Train Acc 71.60975646972656% Val Acc 26.82036018371582% Train Loss 0.3733596205711365 Val Loss 3.7894413471221924
Trainable Parameters : 198660
Epoch 75 Train Acc 71.11585235595703% Val Acc 25.6706600189209% Train Loss 0.36792299151420593 Val Loss 3.775878667831421
Trainable Parameters : 198660
Epoch 76 Train Acc 71.3963394165039% Val Acc 24.61077880859375% Train Loss 0.37093988060951233 Val Loss 3.1657514572143555
Trainable Parameters : 198660
Epoch 77 Train Acc 73.37804412841797% Val Acc 27.413175582885742% Train Loss 0.35744839906692505 Val Loss 3.778211832046509
Trainable Parameters : 198660
Epoch 78 Train Acc 72.90853118896484% Val Acc 27.586828231811523% Train Loss 0.3593519926071167 Val Loss 4.0026164054870605
Trainable Parameters : 198660
Epoch 79 Train Acc 73.36585235595703% Val Acc 26.491018295288086% Train Loss 0.35610833764076233 Val Loss 4.35413122177124
Trainable Parameters : 198660
Epoch 80 Train Acc 71.07316589355469% Val Acc 26.45509147644043% Train Loss 0.37270936369895935 Val Loss 4.322908878326416
Trainable Parameters : 198660
Epoch 81 Train Acc 71.70121765136719% Val Acc 25.952096939086914% Train Loss 0.359483003616333 Val Loss 3.79655385017395
Trainable Parameters : 198660
Mon Oct 10 16:59:41 AEDT 2022
------------------------------------------------------------------------
                         run_500f.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_500f.py
Started: 10/10/2022 16:59:48

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-500-files
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-500-files_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 5 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 2.6794e-01,  1.4265e-01,  9.5450e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.1706e-01, -2.0059e-01, -4.7173e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.3388e+00,  2.0114e+00,  1.0376e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 3.1266e-03,  5.1869e-03,  8.1302e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.8524e+00, -2.6766e+00, -1.7229e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.9667e+00, -3.3215e+00, -3.5383e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 2, 0, 2, 3, 2, 3, 0, 1, 1, 2])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_hid.weight', 'project_q.weight', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_q.bias', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.7046, -0.6310, -0.3184,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0133, -0.0133, -0.0071,  ...,  0.0000,  0.0000,  0.0000],
        [-1.0431, -1.2030, -1.1993,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0583,  0.0808,  0.0110,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0448,  0.1608,  0.3422,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0359,  0.0485,  0.0693,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0, 1, 0, 2, 0, 1, 3, 0, 2])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  4 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 23.29878044128418% Val Acc 26.04790496826172% Train Loss 0.6953955888748169 Val Loss 1.3858144283294678
Trainable Parameters : 198660
Epoch 1 Train Acc 25.30487632751465% Val Acc 25.694612503051758% Train Loss 0.6931220293045044 Val Loss 1.3849756717681885
Trainable Parameters : 198660
Epoch 2 Train Acc 29.170730590820312% Val Acc 22.892215728759766% Train Loss 0.6901795864105225 Val Loss 1.3854128122329712
Trainable Parameters : 198660
Epoch 3 Train Acc 32.743900299072266% Val Acc 23.077844619750977% Train Loss 0.6873948574066162 Val Loss 1.3872438669204712
Trainable Parameters : 198660
Epoch 4 Train Acc 32.341461181640625% Val Acc 23.802396774291992% Train Loss 0.6833845973014832 Val Loss 1.3881744146347046
Trainable Parameters : 198660
Epoch 5 Train Acc 34.2621955871582% Val Acc 26.131736755371094% Train Loss 0.6810389757156372 Val Loss 1.3904622793197632
Trainable Parameters : 198660
Epoch 6 Train Acc 34.5121955871582% Val Acc 22.479042053222656% Train Loss 0.6772848963737488 Val Loss 1.4055360555648804
Trainable Parameters : 198660
Epoch 7 Train Acc 36.85975646972656% Val Acc 23.688623428344727% Train Loss 0.6719425916671753 Val Loss 1.4058743715286255
Trainable Parameters : 198660
Epoch 8 Train Acc 35.585365295410156% Val Acc 22.83233642578125% Train Loss 0.6698246598243713 Val Loss 1.4125984907150269
Trainable Parameters : 198660
Epoch 9 Train Acc 36.975608825683594% Val Acc 22.862276077270508% Train Loss 0.664792001247406 Val Loss 1.4299081563949585
Trainable Parameters : 198660
Epoch 10 Train Acc 37.02438735961914% Val Acc 22.79640769958496% Train Loss 0.6622077226638794 Val Loss 1.4469201564788818
Trainable Parameters : 198660
Epoch 11 Train Acc 38.80487823486328% Val Acc 23.251497268676758% Train Loss 0.6563185453414917 Val Loss 1.4564054012298584
Trainable Parameters : 198660
Epoch 12 Train Acc 39.06097412109375% Val Acc 22.730539321899414% Train Loss 0.6529908776283264 Val Loss 1.4871073961257935
Trainable Parameters : 198660
Epoch 13 Train Acc 37.70121765136719% Val Acc 23.64670753479004% Train Loss 0.6494775414466858 Val Loss 1.4743067026138306
Trainable Parameters : 198660
Epoch 14 Train Acc 40.79877853393555% Val Acc 22.62275505065918% Train Loss 0.644123375415802 Val Loss 1.5139164924621582
Trainable Parameters : 198660
Epoch 15 Train Acc 40.59756088256836% Val Acc 23.401199340820312% Train Loss 0.6365330815315247 Val Loss 1.5280746221542358
Trainable Parameters : 198660
Epoch 16 Train Acc 41.90243911743164% Val Acc 24.065868377685547% Train Loss 0.6325539350509644 Val Loss 1.5665851831436157
Trainable Parameters : 198660
Epoch 17 Train Acc 43.56707000732422% Val Acc 22.910181045532227% Train Loss 0.6240993142127991 Val Loss 1.6255087852478027
Trainable Parameters : 198660
Epoch 18 Train Acc 43.81707000732422% Val Acc 24.113773345947266% Train Loss 0.6188132762908936 Val Loss 1.5995866060256958
Trainable Parameters : 198660
Epoch 19 Train Acc 45.2378044128418% Val Acc 23.814373016357422% Train Loss 0.6117112040519714 Val Loss 1.6228606700897217
Trainable Parameters : 198660
Epoch 20 Train Acc 45.75% Val Acc 23.167665481567383% Train Loss 0.6072949767112732 Val Loss 1.6703890562057495
Trainable Parameters : 198660
Epoch 21 Train Acc 47.79268264770508% Val Acc 24.113773345947266% Train Loss 0.5981574654579163 Val Loss 1.6911277770996094
Trainable Parameters : 198660
Epoch 22 Train Acc 49.23170471191406% Val Acc 24.82634735107422% Train Loss 0.5894522070884705 Val Loss 1.8187994956970215
Trainable Parameters : 198660
Epoch 23 Train Acc 48.780487060546875% Val Acc 25.544910430908203% Train Loss 0.5860127806663513 Val Loss 1.7306627035140991
Trainable Parameters : 198660
Epoch 24 Train Acc 49.554874420166016% Val Acc 24.443115234375% Train Loss 0.5814688801765442 Val Loss 1.7749193906784058
Trainable Parameters : 198660
Epoch 25 Train Acc 51.48170471191406% Val Acc 23.946107864379883% Train Loss 0.5668374300003052 Val Loss 1.8117718696594238
Trainable Parameters : 198660
Epoch 26 Train Acc 50.932926177978516% Val Acc 24.688623428344727% Train Loss 0.5680347084999084 Val Loss 1.963093876838684
Trainable Parameters : 198660
Epoch 27 Train Acc 51.42073059082031% Val Acc 24.62874412536621% Train Loss 0.5598600506782532 Val Loss 1.9637861251831055
Trainable Parameters : 198660
Epoch 28 Train Acc 51.44512176513672% Val Acc 24.952096939086914% Train Loss 0.5564055442810059 Val Loss 2.0254626274108887
Trainable Parameters : 198660
Epoch 29 Train Acc 54.95121765136719% Val Acc 26.9940128326416% Train Loss 0.5419617891311646 Val Loss 1.9571644067764282
Trainable Parameters : 198660
Epoch 30 Train Acc 54.77438735961914% Val Acc 23.886228561401367% Train Loss 0.5369299650192261 Val Loss 2.0988478660583496
Trainable Parameters : 198660
Epoch 31 Train Acc 56.225608825683594% Val Acc 23.18562889099121% Train Loss 0.5284172296524048 Val Loss 2.2277865409851074
Trainable Parameters : 198660
Epoch 32 Train Acc 56.439022064208984% Val Acc 25.760480880737305% Train Loss 0.5227112174034119 Val Loss 2.0743799209594727
Trainable Parameters : 198660
Epoch 33 Train Acc 57.81707000732422% Val Acc 26.41916275024414% Train Loss 0.5177178382873535 Val Loss 2.2692718505859375
Trainable Parameters : 198660
Epoch 34 Train Acc 56.40853500366211% Val Acc 26.65868377685547% Train Loss 0.5122125744819641 Val Loss 2.322101354598999
Trainable Parameters : 198660
Epoch 35 Train Acc 58.554874420166016% Val Acc 25.64670753479004% Train Loss 0.5020466446876526 Val Loss 2.359978199005127
Trainable Parameters : 198660
Epoch 36 Train Acc 58.57316970825195% Val Acc 25.754491806030273% Train Loss 0.5011011362075806 Val Loss 2.893019914627075
Trainable Parameters : 198660
Epoch 37 Train Acc 59.128047943115234% Val Acc 26.077844619750977% Train Loss 0.4934864938259125 Val Loss 2.7226593494415283
Trainable Parameters : 198660
Epoch 38 Train Acc 61.243900299072266% Val Acc 26.02994155883789% Train Loss 0.48016560077667236 Val Loss 2.6125988960266113
Trainable Parameters : 198660
Epoch 39 Train Acc 60.07316970825195% Val Acc 26.952096939086914% Train Loss 0.48846885561943054 Val Loss 2.5366268157958984
Trainable Parameters : 198660
Epoch 40 Train Acc 60.804874420166016% Val Acc 25.694612503051758% Train Loss 0.4812980890274048 Val Loss 2.702885627746582
Trainable Parameters : 198660
Epoch 41 Train Acc 61.04877853393555% Val Acc 24.119760513305664% Train Loss 0.4800858199596405 Val Loss 2.7205729484558105
Trainable Parameters : 198660
Epoch 42 Train Acc 62.280487060546875% Val Acc 25.341318130493164% Train Loss 0.4776965081691742 Val Loss 2.712094783782959
Trainable Parameters : 198660
Epoch 43 Train Acc 62.8719482421875% Val Acc 26.107786178588867% Train Loss 0.4620319604873657 Val Loss 2.7395999431610107
Trainable Parameters : 198660
Epoch 44 Train Acc 62.878047943115234% Val Acc 25.02994155883789% Train Loss 0.4602406919002533 Val Loss 3.331132411956787
Trainable Parameters : 198660
Epoch 45 Train Acc 64.35975646972656% Val Acc 25.574851989746094% Train Loss 0.45140019059181213 Val Loss 3.1434385776519775
Trainable Parameters : 198660
Epoch 46 Train Acc 63.79877853393555% Val Acc 24.19760513305664% Train Loss 0.45692265033721924 Val Loss 2.8018901348114014
Trainable Parameters : 198660
Epoch 47 Train Acc 63.06097412109375% Val Acc 24.86826515197754% Train Loss 0.4495792090892792 Val Loss 2.883096694946289
Trainable Parameters : 198660
Epoch 48 Train Acc 63.597557067871094% Val Acc 25.287425994873047% Train Loss 0.44827714562416077 Val Loss 3.510193347930908
Trainable Parameters : 198660
Epoch 49 Train Acc 64.38414764404297% Val Acc 25.143712997436523% Train Loss 0.4496254026889801 Val Loss 3.2422618865966797
Trainable Parameters : 198660
Epoch 50 Train Acc 65.993896484375% Val Acc 25.329341888427734% Train Loss 0.43883025646209717 Val Loss 3.5240378379821777
Trainable Parameters : 198660
Epoch 51 Train Acc 65.79267883300781% Val Acc 25.556886672973633% Train Loss 0.4396161735057831 Val Loss 3.4290060997009277
Trainable Parameters : 198660
Epoch 52 Train Acc 65.05487823486328% Val Acc 25.335330963134766% Train Loss 0.43878260254859924 Val Loss 3.286839008331299
Trainable Parameters : 198660
Epoch 53 Train Acc 65.46951293945312% Val Acc 26.28143882751465% Train Loss 0.43077653646469116 Val Loss 3.2873141765594482
Trainable Parameters : 198660
Epoch 54 Train Acc 65.5975570678711% Val Acc 25.20958137512207% Train Loss 0.43220654129981995 Val Loss 4.378538608551025
Trainable Parameters : 198660
Epoch 55 Train Acc 66.06707000732422% Val Acc 25.389223098754883% Train Loss 0.42823463678359985 Val Loss 3.385645866394043
Trainable Parameters : 198660
Epoch 56 Train Acc 65.53048706054688% Val Acc 25.86826515197754% Train Loss 0.4306000769138336 Val Loss 3.118130922317505
Trainable Parameters : 198660
Epoch 57 Train Acc 65.6219482421875% Val Acc 26.730539321899414% Train Loss 0.42589306831359863 Val Loss 3.2707536220550537
Trainable Parameters : 198660
Epoch 58 Train Acc 67.0% Val Acc 25.43113899230957% Train Loss 0.4151267409324646 Val Loss 3.3694076538085938
Trainable Parameters : 198660
Epoch 59 Train Acc 68.06097412109375% Val Acc 25.580839157104492% Train Loss 0.4157998859882355 Val Loss 3.4767777919769287
Trainable Parameters : 198660
Epoch 60 Train Acc 66.17073059082031% Val Acc 25.700599670410156% Train Loss 0.4137486219406128 Val Loss 3.4860103130340576
Trainable Parameters : 198660
Epoch 61 Train Acc 67.56097412109375% Val Acc 24.7724552154541% Train Loss 0.4011588394641876 Val Loss 4.0754876136779785
Trainable Parameters : 198660
Epoch 62 Train Acc 67.95731353759766% Val Acc 24.9940128326416% Train Loss 0.40455347299575806 Val Loss 3.919782876968384
Trainable Parameters : 198660
Epoch 63 Train Acc 68.0% Val Acc 24.964073181152344% Train Loss 0.39942696690559387 Val Loss 4.545344829559326
Trainable Parameters : 198660
Epoch 64 Train Acc 68.53048706054688% Val Acc 25.083833694458008% Train Loss 0.4045831561088562 Val Loss 3.8850483894348145
Trainable Parameters : 198660
Epoch 65 Train Acc 68.493896484375% Val Acc 25.766468048095703% Train Loss 0.3956610858440399 Val Loss 3.6110169887542725
Trainable Parameters : 198660
Epoch 66 Train Acc 68.89024353027344% Val Acc 26.580839157104492% Train Loss 0.3951091170310974 Val Loss 4.158627033233643
Trainable Parameters : 198660
