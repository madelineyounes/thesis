Mon Oct 17 00:28:30 AEDT 2022
------------------------------------------------------------------------
                         run_8s.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_outdebug.py
Started: 17/10/2022 00:28:34

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-outdebug
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 2
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 15 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.1903,  0.1139,  0.0599,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0748,  0.1256,  0.3432,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8586, -0.6404, -0.5263,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-1.1756, -1.1705, -1.1413,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0087,  0.0111,  0.0157,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1413,  0.0057, -0.0289,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 1, 2, 3, 0, 3, 0, 3, 1, 2, 2, 2, 0, 3, 2, 2, 3, 2, 0, 3, 3, 2, 0,
        2, 1, 3, 2, 0, 2, 1, 1, 1, 1, 0, 0, 1, 0, 2, 3])}
Training DataCustom Files: 1963
Training Data Files: 50
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.codevectors', 'quantizer.weight_proj.weight', 'project_q.bias', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_hid.weight', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.bias', 'classifier.weight', 'projector.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 1.6876,  1.5775,  1.4215,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2875,  0.3308,  0.3550,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0878,  0.1169,  0.1571,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1156, -0.1146, -0.1422,  ...,  0.0000,  0.0000,  0.0000],
        [-1.7779, -1.3218, -0.8569,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6527, -0.7317, -0.8635,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 3, 3, 1, 3, 1, 0, 0, 1, 0, 2, 2, 0, 1, 2, 2, 0, 1, 3, 1, 0, 1, 2,
        2, 1, 2, 0, 0, 3, 0, 3, 1, 0, 0, 1, 2, 2, 0, 2])}
Test CustomData Files: 1997
Test Data Files: 50
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 26.099998474121094% Val Acc 26.69999885559082% Train Loss 0.6944513320922852 Val Loss 1.38728928565979
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug/config.json
Model weights saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug/pytorch_model.bin
Epoch 1 Train Acc 26.81999969482422% Val Acc 26.459999084472656% Train Loss 0.6933943033218384 Val Loss 1.386728048324585

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[13, 13, 9, 5]
[18, 22, 0, 0]
[20, 25, 20, 15]
[31, 47, 2, 0]
[31, 35, 31, 23]
[56, 61, 2, 1]
[41, 46, 41, 32]
[74, 82, 2, 2]
[52, 56, 54, 38]
[92, 104, 2, 2]
[63, 67, 58, 52]
[109, 125, 2, 4]
[73, 81, 65, 61]
[129, 145, 2, 4]
[77, 93, 79, 71]
[149, 164, 3, 4]
[85, 101, 91, 83]
[166, 186, 4, 4]
[94, 115, 100, 91]
[183, 206, 5, 6]
[107, 126, 112, 95]
[205, 223, 6, 6]
[116, 139, 119, 106]
[222, 245, 7, 6]
[126, 149, 133, 112]
[244, 262, 8, 6]
[136, 155, 143, 126]
[267, 279, 8, 6]
[147, 167, 152, 134]
[282, 300, 12, 6]
[157, 182, 158, 143]
[297, 323, 12, 8]
[168, 193, 163, 156]
[310, 347, 14, 9]
[173, 207, 171, 169]
[325, 372, 14, 9]
[184, 220, 179, 177]
[343, 393, 15, 9]
[191, 228, 194, 187]
[362, 412, 17, 9]
[201, 237, 202, 200]
[381, 433, 17, 9]
[210, 251, 210, 209]
[399, 454, 18, 9]
[218, 269, 218, 215]
[418, 474, 18, 10]
[228, 279, 229, 224]
[435, 496, 19, 10]
[241, 292, 235, 232]
[455, 514, 19, 12]
[249, 300, 249, 242]
[473, 535, 19, 13]
[262, 315, 255, 248]
[488, 560, 19, 13]
[271, 323, 266, 260]
[507, 578, 22, 13]
[283, 332, 276, 269]
[529, 593, 25, 13]
[298, 338, 288, 276]
[544, 616, 27, 13]
[312, 345, 294, 289]
[563, 636, 28, 13]
[319, 357, 307, 297]
[585, 653, 29, 13]
[329, 361, 320, 310]
[605, 672, 29, 14]
[344, 365, 333, 318]
[623, 694, 29, 14]
[356, 375, 347, 322]
[642, 714, 30, 14]
[361, 380, 362, 337]
[663, 733, 30, 14]
[369, 389, 369, 353]
[680, 754, 30, 16]
[386, 394, 378, 362]
[693, 780, 31, 16]
[404, 400, 386, 370]
[713, 799, 31, 17]
[415, 408, 390, 387]
[736, 816, 31, 17]
[423, 414, 401, 402]
[757, 835, 31, 17]
[429, 423, 409, 419]
[777, 854, 32, 17]
[435, 435, 417, 433]
[799, 870, 34, 17]
[443, 443, 426, 448]
[818, 890, 34, 18]
[454, 454, 436, 456]
[836, 912, 34, 18]
[462, 469, 444, 465]
[856, 929, 37, 18]
[472, 475, 462, 471]
[873, 952, 37, 18]
[480, 483, 476, 481]
[886, 977, 39, 18]
[491, 491, 486, 492]
[906, 995, 41, 18]
[500, 500, 497, 500]
[919, 1017, 42, 19]
CONFUSION MATRIX
[[0.   0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.   0.  ]
 [0.   0.25 0.   0.   0.   0.  ]
 [0.25 0.   0.   0.   0.25 0.25]
 [0.   0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.   0.  ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

          19       0.00      0.00      0.00       0.0
          42       0.00      0.00      0.00       0.0
         497       0.00      0.00      0.00       1.0
         500       0.00      0.00      0.00       3.0
         919       0.00      0.00      0.00       0.0
        1017       0.00      0.00      0.00       0.0

    accuracy                           0.00       4.0
   macro avg       0.00      0.00      0.00       4.0
weighted avg       0.00      0.00      0.00       4.0


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 17/10/2022 00:33:36
Mon Oct 17 00:51:41 AEDT 2022
------------------------------------------------------------------------
                         run_8s.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_outdebug.py
Started: 17/10/2022 00:51:45

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-outdebug
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 2
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 15 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.4097, -0.4077, -0.3908,  ...,  0.0000,  0.0000,  0.0000],
        [-1.0786, -0.5530,  0.8109,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2328, -1.2953, -0.5376,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.5974,  0.3779,  0.3973,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2327, -0.2077, -0.1628,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1301, -0.1016, -0.0908,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 2, 0, 1, 3, 2, 0, 0, 0, 3, 0, 0, 2, 2, 0, 2, 0, 1, 0, 3, 3, 2, 0,
        2, 2, 3, 2, 2, 0, 1, 0, 1, 3, 0, 2, 0, 0, 3, 2])}
Training DataCustom Files: 1963
Training Data Files: 50
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.codevectors', 'project_q.weight', 'project_hid.weight', 'quantizer.weight_proj.weight', 'project_q.bias', 'quantizer.weight_proj.bias', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'projector.weight', 'classifier.bias', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.3026,  0.5578,  0.7141,  ...,  0.0000,  0.0000,  0.0000],
        [-2.3144, -1.9959, -2.1670,  ...,  0.0000,  0.0000,  0.0000],
        [-0.4381, -1.1493, -1.1702,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.4208,  0.4818,  0.1551,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3593,  0.3372,  0.3104,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0153, -0.0217, -0.0137,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 0, 3, 2, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 3, 1, 2, 2, 2,
        3, 3, 0, 2, 2, 2, 2, 0, 1, 0, 0, 0, 3, 2, 0, 3])}
Test CustomData Files: 1997
Test Data Files: 50
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 24.439998626708984% Val Acc 24.279998779296875% Train Loss 0.6942623853683472 Val Loss 1.3859446048736572
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug/config.json
Model weights saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-outdebug/pytorch_model.bin
Epoch 1 Train Acc 25.18000030517578% Val Acc 24.279998779296875% Train Loss 0.6936550140380859 Val Loss 1.385864019393921

------> EVALUATING MODEL... ------------------------------------------ 

[500, 500, 497, 500]
[6, 30, 89, 1872]
[3, 3, 3, 0, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 1, 3, 0, 1, 2, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 0, 3, 1, 2, 1, 2, 2, 1, 1, 0, 0, 3, 2, 3, 1, 1, 3, 1, 1, 1, 0, 3, 1, 1, 2, 2, 1, 0, 1, 0, 1, 3, 2, 2, 2, 2, 2, 3, 0, 2, 0, 3, 2, 0, 2, 3, 3, 1, 1, 0, 3, 3, 3, 1, 0, 0, 2, 0, 2, 1, 2, 0, 2, 1, 3, 3, 2, 3, 2, 1, 1, 1, 1, 2, 1, 2, 3, 0, 0, 0, 1, 0, 0, 3, 0, 2, 2, 3, 2, 1, 0, 0, 1, 0, 0, 0, 1, 1, 2, 2, 2, 3, 1, 2, 1, 3, 1, 1, 3, 0, 0, 3, 2, 3, 2, 3, 0, 0, 0, 2, 1, 3, 2, 2, 1, 3, 1, 1, 2, 0, 3, 1, 3, 1, 2, 0, 3, 1, 0, 1, 1, 2, 0, 0, 0, 2, 2, 0, 2, 1, 3, 0, 1, 0, 2, 0, 2, 3, 0, 1, 2, 3, 3, 2, 2, 1, 2, 1, 2, 0, 2, 1, 3, 1, 2, 0, 3, 3, 1, 0, 3, 0, 1, 0, 0, 0, 2, 3, 3, 3, 0, 0, 0, 3, 1, 1, 1, 3, 0, 1, 1, 2, 3, 3, 2, 3, 3, 1, 1, 0, 3, 3, 1, 3, 0, 3, 3, 1, 2, 3, 1, 0, 2, 0, 1, 2, 3, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0, 3, 3, 0, 0, 1, 0, 1, 1, 3, 2, 0, 2, 1, 1, 3, 1, 2, 3, 1, 2, 0, 1, 1, 3, 1, 2, 3, 3, 2, 1, 3, 3, 1, 0, 2, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 3, 2, 1, 1, 1, 0, 2, 0, 2, 3, 3, 2, 0, 1, 0, 3, 2, 1, 0, 0, 1, 3, 0, 3, 0, 2, 3, 2, 2, 3, 0, 1, 1, 3, 2, 3, 1, 2, 3, 3, 3, 0, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 3, 1, 1, 1, 0, 3, 1, 1, 0, 1, 1, 0, 1, 0, 3, 2, 3, 1, 2, 2, 0, 0, 3, 0, 0, 2, 2, 1, 1, 2, 3, 0, 2, 3, 2, 3, 1, 2, 0, 1, 1, 2, 3, 2, 3, 3, 2, 1, 0, 0, 2, 0, 1, 2, 2, 3, 0, 0, 2, 1, 0, 1, 1, 0, 2, 2, 0, 2, 1, 0, 1, 0, 0, 1, 1, 2, 0, 3, 1, 1, 2, 1, 3, 3, 1, 0, 1, 2, 0, 1, 1, 3, 3, 2, 2, 3, 1, 0, 3, 0, 0, 2, 1, 1, 2, 1, 0, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 0, 3, 3, 2, 0, 1, 2, 2, 2, 0, 0, 3, 0, 3, 1, 1, 3, 1, 2, 2, 1, 1, 1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 0, 2, 2, 2, 2, 2, 3, 0, 1, 0, 2, 1, 0, 3, 2, 0, 1, 3, 3, 2, 3, 3, 2, 0, 2, 2, 0, 2, 3, 3, 2, 3, 0, 0, 3, 0, 0, 2, 0, 3, 3, 2, 1, 3, 3, 3, 1, 1, 1, 1, 1, 2, 0, 1, 2, 3, 0, 3, 2, 2, 1, 0, 0, 2, 0, 0, 2, 3, 0, 1, 1, 1, 2, 3, 0, 3, 0, 3, 3, 1, 2, 1, 0, 2, 1, 3, 0, 1, 1, 3, 1, 0, 1, 1, 0, 0, 2, 3, 1, 0, 3, 3, 3, 2, 1, 2, 1, 1, 2, 3, 0, 3, 0, 1, 3, 1, 3, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 3, 0, 3, 0, 3, 1, 3, 1, 3, 0, 2, 3, 0, 3, 3, 2, 1, 1, 2, 0, 0, 3, 1, 3, 3, 0, 1, 1, 3, 1, 2, 1, 1, 0, 0, 3, 1, 0, 2, 2, 1, 1, 3, 2, 1, 2, 3, 3, 3, 1, 3, 1, 0, 1, 3, 1, 0, 3, 3, 2, 1, 1, 3, 2, 3, 3, 1, 1, 3, 1, 0, 3, 2, 1, 0, 2, 1, 0, 2, 0, 0, 3, 1, 2, 3, 1, 3, 1, 0, 0, 2, 1, 0, 1, 2, 1, 1, 3, 0, 1, 1, 0, 0, 2, 3, 2, 2, 3, 3, 1, 3, 0, 0, 1, 1, 2, 0, 1, 2, 2, 1, 3, 2, 2, 0, 1, 1, 3, 2, 3, 2, 3, 3, 2, 0, 2, 1, 2, 1, 0, 0, 2, 3, 2, 2, 2, 3, 1, 2, 1, 0, 3, 0, 3, 2, 3, 3, 2, 0, 3, 3, 3, 2, 1, 1, 0, 0, 3, 3, 0, 2, 1, 1, 3, 2, 0, 3, 1, 0, 3, 1, 3, 3, 0, 1, 0, 2, 0, 1, 3, 2, 1, 0, 2, 2, 3, 3, 1, 0, 1, 1, 1, 2, 3, 1, 2, 1, 0, 1, 1, 3, 3, 0, 3, 1, 1, 1, 3, 3, 0, 0, 1, 2, 1, 0, 0, 2, 2, 2, 3, 2, 2, 1, 3, 0, 0, 1, 0, 2, 1, 0, 1, 2, 0, 3, 0, 1, 1, 1, 1, 1, 2, 3, 0, 1, 3, 0, 0, 1, 3, 1, 2, 1, 2, 1, 1, 1, 3, 2, 1, 2, 1, 2, 1, 3, 0, 2, 3, 1, 1, 2, 1, 3, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 0, 3, 0, 2, 2, 1, 2, 3, 2, 0, 3, 2, 0, 0, 0, 2, 0, 3, 2, 3, 3, 3, 2, 3, 3, 1, 1, 0, 1, 1, 1, 1, 0, 3, 3, 2, 1, 1, 0, 2, 2, 1, 3, 3, 1, 1, 0, 0, 1, 0, 0, 3, 0, 2, 0, 2, 2, 0, 1, 0, 0, 3, 0, 1, 3, 2, 3, 3, 2, 2, 1, 0, 1, 1, 2, 3, 3, 2, 0, 2, 2, 0, 2, 3, 0, 3, 1, 1, 3, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 3, 3, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 3, 1, 2, 2, 0, 2, 2, 1, 1, 0, 3, 1, 0, 1, 2, 0, 3, 0, 0, 2, 1, 1, 3, 0, 0, 3, 1, 3, 0, 1, 1, 0, 3, 2, 1, 0, 0, 2, 3, 1, 0, 0, 2, 3, 2, 3, 1, 3, 3, 3, 2, 0, 3, 1, 0, 0, 2, 0, 3, 1, 2, 3, 2, 1, 3, 2, 3, 1, 1, 2, 2, 1, 1, 0, 3, 2, 0, 2, 0, 3, 3, 3, 3, 1, 1, 2, 1, 0, 0, 0, 3, 2, 2, 0, 0, 0, 2, 1, 3, 0, 0, 2, 1, 3, 2, 1, 2, 1, 3, 0, 2, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 2, 1, 2, 2, 3, 2, 0, 0, 3, 3, 1, 0, 3, 2, 3, 0, 3, 0, 2, 2, 1, 2, 1, 0, 1, 2, 2, 3, 1, 3, 1, 0, 2, 3, 2, 3, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 0, 1, 3, 3, 1, 0, 0, 0, 1, 0, 2, 3, 1, 3, 2, 1, 2, 3, 1, 0, 2, 3, 3, 0, 1, 2, 1, 1, 2, 2, 3, 1, 1, 2, 0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 3, 2, 3, 2, 3, 2, 1, 3, 0, 3, 0, 2, 3, 0, 3, 0, 2, 2, 3, 2, 2, 3, 3, 0, 2, 2, 1, 2, 0, 2, 0, 3, 3, 0, 3, 2, 1, 0, 3, 3, 1, 2, 0, 2, 2, 3, 3, 0, 0, 2, 2, 1, 2, 3, 2, 2, 0, 2, 0, 0, 2, 3, 0, 2, 0, 2, 3, 0, 1, 0, 3, 0, 1, 0, 1, 3, 0, 0, 0, 2, 0, 2, 3, 0, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 0, 2, 0, 1, 2, 1, 0, 3, 3, 2, 0, 1, 0, 0, 2, 2, 0, 1, 2, 2, 3, 1, 2, 2, 0, 0, 1, 3, 1, 2, 3, 0, 2, 2, 0, 3, 2, 0, 3, 0, 2, 1, 3, 3, 3, 1, 2, 3, 2, 3, 0, 3, 1, 2, 2, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 1, 2, 1, 3, 2, 2, 3, 1, 3, 3, 2, 0, 1, 1, 1, 3, 0, 2, 3, 3, 2, 1, 3, 1, 0, 2, 1, 1, 3, 1, 3, 3, 0, 3, 2, 3, 0, 3, 3, 0, 3, 3, 0, 0, 2, 0, 1, 0, 3, 2, 0, 3, 3, 2, 0, 1, 1, 3, 0, 2, 2, 1, 3, 0, 0, 2, 1, 3, 3, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 3, 3, 0, 1, 3, 2, 0, 2, 3, 0, 2, 3, 0, 3, 2, 0, 1, 0, 3, 0, 3, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 3, 0, 1, 0, 0, 2, 0, 1, 3, 0, 3, 1, 3, 3, 3, 3, 3, 1, 1, 3, 0, 1, 0, 3, 0, 1, 3, 1, 3, 2, 0, 1, 3, 0, 3, 2, 0, 0, 0, 3, 2, 3, 1, 2, 0, 3, 0, 3, 3, 1, 3, 2, 0, 2, 3, 3, 2, 3, 3, 2, 0, 0, 2, 1, 3, 3, 0, 0, 1, 3, 3, 2, 2, 0, 1, 3, 3, 3, 3, 2, 0, 1, 0, 1, 2, 3, 3, 2, 2, 2, 3, 3, 3, 2, 0, 3, 3, 0, 1, 3, 2, 2, 0, 1, 3, 3, 1, 1, 3, 1, 3, 0, 1, 3, 3, 0, 1, 3, 1, 2, 2, 2, 3, 0, 3, 3, 3, 1, 2, 1, 3, 3, 1, 1, 3, 2, 3, 3, 3, 1, 3, 2, 3, 0, 1, 2, 1, 1, 3, 1, 1, 3, 2, 0, 0, 3, 1, 0, 1, 3, 2, 2, 2, 0, 0, 2, 3, 3, 1, 0, 3, 1, 1, 0, 1, 3, 2, 1, 3, 2, 3, 2, 0, 2, 3, 3, 3, 0, 3, 3, 3, 1, 2, 2, 0, 1, 0, 1, 3, 2, 0, 1, 2, 2, 3, 3, 0, 3, 3, 1, 3, 2, 1, 1, 0, 2, 1, 3, 2, 3, 3, 2, 1, 0, 0, 3, 1, 0, 0, 2, 1, 1, 0, 3, 0, 2, 0, 2, 1, 0, 0, 1, 3, 2, 3, 0, 1, 2, 2, 1, 1, 1, 2, 0, 1, 0, 2, 1, 2, 3, 1, 3, 1, 0, 3, 2, 1, 1, 2, 1, 1, 2, 1, 3, 3, 0, 1, 1, 0, 1, 0, 3, 2, 3, 3, 0, 2, 3, 0, 3, 2, 1, 2, 2, 3, 3, 2, 1, 1, 2, 2, 1, 0, 1, 3, 0, 2, 2, 2, 0, 0, 2, 3, 2, 0, 0, 1, 2, 2, 3, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 3, 1, 2, 0, 3, 1, 3, 1, 2, 2, 0, 2, 0, 0, 3, 3, 0, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 0, 3, 2, 3, 3, 3, 2, 0, 3, 3, 3, 0, 3, 2, 2, 3, 0, 1, 1, 2, 2, 1, 3, 0, 3, 2, 3, 0, 3, 1, 0, 1, 2, 3, 2, 0, 2, 3, 0, 2, 0, 0, 1, 3, 1, 0, 0, 2, 1, 3, 1, 0, 2, 0, 1, 0, 2, 2, 0, 2, 2, 1, 3, 2, 2, 2, 1, 2, 1, 3, 0, 3, 0, 1, 2, 1, 0, 3, 1, 1, 0, 0, 3, 3, 2, 3]
[3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 0, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

CONFUSION MATRIX
[[0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 1 0 0 0]
 [1 1 0 0 0 1]
 [0 0 0 0 0 0]]
[[  1   5  14 480]
 [  2   4   8 486]
 [  2  10  29 456]
 [  1  11  38 450]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           6       0.00      0.00      0.00       0.0
          30       0.00      0.00      0.00       0.0
          89       0.00      0.00      0.00       0.0
         497       0.00      0.00      0.00       1.0
         500       0.00      0.00      0.00       3.0
        1872       0.00      0.00      0.00       0.0

    accuracy                           0.00       4.0
   macro avg       0.00      0.00      0.00       4.0
weighted avg       0.00      0.00      0.00       4.0

              precision    recall  f1-score   support

           0       0.17      0.00      0.00       500
           1       0.13      0.01      0.02       500
           2       0.33      0.06      0.10       497
           3       0.24      0.90      0.38       500

    accuracy                           0.24      1997
   macro avg       0.22      0.24      0.12      1997
weighted avg       0.22      0.24      0.12      1997


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 17/10/2022 00:56:48
