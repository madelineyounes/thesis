Mon Oct 10 03:00:59 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_2s.py
Started: 10/10/2022 03:01:04

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-1s
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: test_u_500f
evaluation_filename: train_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 12
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/test_u_500f.csv
--> data_test_fp: data/train_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-1s
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-1s_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 2 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.5514,  0.5410,  0.5136,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1748,  0.3254,  0.3892,  ...,  0.0000,  0.0000,  0.0000],
        [-0.5460,  0.3636,  1.0612,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0340, -0.0324, -0.0324,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2104, -1.3594, -2.8107,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0928,  0.0790,  0.0553,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 2, 1, 1, 3, 2, 0, 2, 1, 3, 1])}
Training DataCustom Files: 1963
Training Data Files: 164
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_hid.weight', 'quantizer.weight_proj.bias', 'quantizer.codevectors', 'quantizer.weight_proj.weight', 'project_hid.bias', 'project_q.bias', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'projector.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-0.1026, -0.1399, -0.1369,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6596, -0.5478, -0.9002,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0103,  0.0103,  0.0086,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.3207,  0.2928,  0.2697,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1468,  0.0213,  0.1551,  ..., -0.0178,  0.0025, -0.0220],
        [-0.2346, -0.2851, -0.6653,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 0, 2, 0, 2, 0, 2, 0, 2, 3, 0])}
Test CustomData Files: 1997
Test Data Files: 167
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 28.81097412109375% Val Acc 25.550899505615234% Train Loss 0.6920249462127686 Val Loss 1.3908292055130005
Trainable Parameters : 198660
Epoch 1 Train Acc 30.146339416503906% Val Acc 25.497007369995117% Train Loss 0.6903994679450989 Val Loss 1.3895220756530762
Trainable Parameters : 198660
Epoch 2 Train Acc 31.06707191467285% Val Acc 25.538923263549805% Train Loss 0.6875253915786743 Val Loss 1.3893710374832153
Trainable Parameters : 198660
Epoch 3 Train Acc 35.95731735229492% Val Acc 23.736528396606445% Train Loss 0.6838046312332153 Val Loss 1.389750361442566
Trainable Parameters : 198660
Epoch 4 Train Acc 35.8719482421875% Val Acc 24.874252319335938% Train Loss 0.679301917552948 Val Loss 1.390873908996582
Trainable Parameters : 198660
Epoch 5 Train Acc 36.79268264770508% Val Acc 25.173654556274414% Train Loss 0.6750330924987793 Val Loss 1.392924189567566
Trainable Parameters : 198660
Epoch 6 Train Acc 38.57926559448242% Val Acc 24.904191970825195% Train Loss 0.6689943075180054 Val Loss 1.4035704135894775
Trainable Parameters : 198660
Epoch 7 Train Acc 38.41463088989258% Val Acc 24.958084106445312% Train Loss 0.6625891923904419 Val Loss 1.4044303894042969
Trainable Parameters : 198660
Epoch 8 Train Acc 38.993900299072266% Val Acc 24.892215728759766% Train Loss 0.6579847931861877 Val Loss 1.4102636575698853
Trainable Parameters : 198660
Epoch 9 Train Acc 39.39024353027344% Val Acc 24.904191970825195% Train Loss 0.6521485447883606 Val Loss 1.423936367034912
Trainable Parameters : 198660
Epoch 10 Train Acc 39.7378044128418% Val Acc 24.592815399169922% Train Loss 0.6449939012527466 Val Loss 1.4462435245513916
Trainable Parameters : 198660
Epoch 11 Train Acc 41.66463088989258% Val Acc 26.82634735107422% Train Loss 0.638067364692688 Val Loss 1.4480812549591064
Trainable Parameters : 198660
Epoch 12 Train Acc 43.60365676879883% Val Acc 25.00598907470703% Train Loss 0.632803738117218 Val Loss 1.4686810970306396
Trainable Parameters : 198660
Epoch 13 Train Acc 43.51829147338867% Val Acc 27.305389404296875% Train Loss 0.6243534684181213 Val Loss 1.4764682054519653
Trainable Parameters : 198660
Epoch 14 Train Acc 46.457313537597656% Val Acc 25.239521026611328% Train Loss 0.6174435019493103 Val Loss 1.508589267730713
Trainable Parameters : 198660
Epoch 15 Train Acc 46.26219177246094% Val Acc 26.107786178588867% Train Loss 0.6094229817390442 Val Loss 1.5031349658966064
Trainable Parameters : 198660
Epoch 16 Train Acc 46.804874420166016% Val Acc 27.9940128326416% Train Loss 0.6022223830223083 Val Loss 1.521484375
Trainable Parameters : 198660
Epoch 17 Train Acc 48.42682647705078% Val Acc 27.730539321899414% Train Loss 0.5908514857292175 Val Loss 1.5774006843566895
Trainable Parameters : 198660
Epoch 18 Train Acc 49.15853500366211% Val Acc 28.311378479003906% Train Loss 0.58650803565979 Val Loss 1.5653619766235352
Trainable Parameters : 198660
Epoch 19 Train Acc 49.780487060546875% Val Acc 29.173654556274414% Train Loss 0.5772715210914612 Val Loss 1.5798897743225098
Trainable Parameters : 198660
Epoch 20 Train Acc 52.23170471191406% Val Acc 28.28143882751465% Train Loss 0.5666636228561401 Val Loss 1.6383616924285889
Trainable Parameters : 198660
Epoch 21 Train Acc 53.11585235595703% Val Acc 28.341318130493164% Train Loss 0.5554938316345215 Val Loss 1.701798677444458
Trainable Parameters : 198660
Epoch 22 Train Acc 54.02438735961914% Val Acc 29.03592872619629% Train Loss 0.5485504865646362 Val Loss 1.7737343311309814
Trainable Parameters : 198660
Epoch 23 Train Acc 54.67073059082031% Val Acc 28.41916275024414% Train Loss 0.543268620967865 Val Loss 1.6443880796432495
Trainable Parameters : 198660
Epoch 24 Train Acc 55.286582946777344% Val Acc 29.19760513305664% Train Loss 0.5322092175483704 Val Loss 1.7060580253601074
Trainable Parameters : 198660
Epoch 25 Train Acc 57.01219177246094% Val Acc 28.263473510742188% Train Loss 0.5236620306968689 Val Loss 1.67641282081604
Trainable Parameters : 198660
Epoch 26 Train Acc 57.76829147338867% Val Acc 29.05988121032715% Train Loss 0.5171641707420349 Val Loss 1.8160890340805054
Trainable Parameters : 198660
Epoch 27 Train Acc 58.64024353027344% Val Acc 29.682636260986328% Train Loss 0.5044981837272644 Val Loss 1.766658067703247
Trainable Parameters : 198660
Epoch 28 Train Acc 59.432926177978516% Val Acc 29.60479164123535% Train Loss 0.49854764342308044 Val Loss 1.8764140605926514
Trainable Parameters : 198660
Epoch 29 Train Acc 59.57926559448242% Val Acc 28.61077880859375% Train Loss 0.48905208706855774 Val Loss 1.8854341506958008
Trainable Parameters : 198660
Epoch 30 Train Acc 60.457313537597656% Val Acc 29.18562889099121% Train Loss 0.48533931374549866 Val Loss 1.8895152807235718
Trainable Parameters : 198660
Epoch 31 Train Acc 62.35365676879883% Val Acc 28.305389404296875% Train Loss 0.4754427671432495 Val Loss 1.9889127016067505
Trainable Parameters : 198660
Epoch 32 Train Acc 61.707313537597656% Val Acc 29.532936096191406% Train Loss 0.46898123621940613 Val Loss 1.8065780401229858
Trainable Parameters : 198660
Epoch 33 Train Acc 62.57316970825195% Val Acc 28.275449752807617% Train Loss 0.46020281314849854 Val Loss 1.9284924268722534
Trainable Parameters : 198660
Epoch 34 Train Acc 64.8475570678711% Val Acc 29.664670944213867% Train Loss 0.4472510814666748 Val Loss 1.9283596277236938
Trainable Parameters : 198660
Epoch 35 Train Acc 64.65243530273438% Val Acc 28.916168212890625% Train Loss 0.43940454721450806 Val Loss 1.9708054065704346
Trainable Parameters : 198660
Epoch 36 Train Acc 65.20731353759766% Val Acc 26.60479164123535% Train Loss 0.4381650388240814 Val Loss 2.709672212600708
Trainable Parameters : 198660
Epoch 37 Train Acc 65.73170471191406% Val Acc 27.85628890991211% Train Loss 0.43736952543258667 Val Loss 2.1587843894958496
Trainable Parameters : 198660
Epoch 38 Train Acc 67.29877471923828% Val Acc 28.508983612060547% Train Loss 0.42025336623191833 Val Loss 2.217200517654419
Trainable Parameters : 198660
Epoch 39 Train Acc 67.42682647705078% Val Acc 28.113773345947266% Train Loss 0.4153834879398346 Val Loss 2.4951796531677246
Trainable Parameters : 198660
Epoch 40 Train Acc 67.29267883300781% Val Acc 28.892215728759766% Train Loss 0.4190594255924225 Val Loss 2.232290267944336
Trainable Parameters : 198660
Epoch 41 Train Acc 67.89024353027344% Val Acc 27.676647186279297% Train Loss 0.407869428396225 Val Loss 2.316426992416382
Trainable Parameters : 198660
Epoch 42 Train Acc 68.85365295410156% Val Acc 27.778444290161133% Train Loss 0.40464603900909424 Val Loss 2.326230764389038
Trainable Parameters : 198660
Epoch 43 Train Acc 68.95731353759766% Val Acc 27.940120697021484% Train Loss 0.40022769570350647 Val Loss 2.403242826461792
Trainable Parameters : 198660
Epoch 44 Train Acc 69.56707000732422% Val Acc 26.724552154541016% Train Loss 0.3943116068840027 Val Loss 2.7092151641845703
Trainable Parameters : 198660
Epoch 45 Train Acc 69.82316589355469% Val Acc 27.42514991760254% Train Loss 0.3841044008731842 Val Loss 2.490922451019287
Trainable Parameters : 198660
Epoch 46 Train Acc 69.75609588623047% Val Acc 28.065868377685547% Train Loss 0.3875170648097992 Val Loss 2.448249340057373
Trainable Parameters : 198660
Epoch 47 Train Acc 69.57926940917969% Val Acc 28.287425994873047% Train Loss 0.38419002294540405 Val Loss 2.3737807273864746
Trainable Parameters : 198660
Epoch 48 Train Acc 70.11585235595703% Val Acc 26.982036590576172% Train Loss 0.38153478503227234 Val Loss 3.0018649101257324
Trainable Parameters : 198660
Epoch 49 Train Acc 70.2682876586914% Val Acc 28.05988121032715% Train Loss 0.3777380883693695 Val Loss 2.6005640029907227
Trainable Parameters : 198660
Epoch 50 Train Acc 71.71340942382812% Val Acc 27.167665481567383% Train Loss 0.36368951201438904 Val Loss 3.244658946990967
Trainable Parameters : 198660
Epoch 51 Train Acc 71.18901824951172% Val Acc 27.46706771850586% Train Loss 0.3709082007408142 Val Loss 2.5812065601348877
Trainable Parameters : 198660
Epoch 52 Train Acc 71.29877471923828% Val Acc 27.7724552154541% Train Loss 0.3689638674259186 Val Loss 2.5513579845428467
Trainable Parameters : 198660
Epoch 53 Train Acc 71.36585235595703% Val Acc 27.508983612060547% Train Loss 0.37204980850219727 Val Loss 2.6685259342193604
Trainable Parameters : 198660
Epoch 54 Train Acc 72.0% Val Acc 26.239521026611328% Train Loss 0.3617520034313202 Val Loss 2.9601874351501465
Trainable Parameters : 198660
Epoch 55 Train Acc 72.64024353027344% Val Acc 25.22754669189453% Train Loss 0.35667258501052856 Val Loss 3.2198970317840576
Trainable Parameters : 198660
Epoch 56 Train Acc 72.82926177978516% Val Acc 25.946107864379883% Train Loss 0.3584114611148834 Val Loss 2.7727925777435303
Trainable Parameters : 198660
Epoch 57 Train Acc 73.68901824951172% Val Acc 25.766468048095703% Train Loss 0.3427588939666748 Val Loss 3.0019383430480957
Trainable Parameters : 198660
Epoch 58 Train Acc 74.6463394165039% Val Acc 26.22754669189453% Train Loss 0.3390955328941345 Val Loss 3.328920364379883
Trainable Parameters : 198660
Epoch 59 Train Acc 72.98780059814453% Val Acc 25.107786178588867% Train Loss 0.3493342995643616 Val Loss 3.151236057281494
Trainable Parameters : 198660
Epoch 60 Train Acc 73.82926177978516% Val Acc 26.520959854125977% Train Loss 0.34991925954818726 Val Loss 2.8940839767456055
Trainable Parameters : 198660
Epoch 61 Train Acc 74.21340942382812% Val Acc 26.01796531677246% Train Loss 0.33364957571029663 Val Loss 3.889678478240967
Trainable Parameters : 198660
Epoch 62 Train Acc 74.5182876586914% Val Acc 26.377246856689453% Train Loss 0.335556298494339 Val Loss 3.424699544906616
Trainable Parameters : 198660
Epoch 63 Train Acc 74.35975646972656% Val Acc 26.03592872619629% Train Loss 0.33135032653808594 Val Loss 4.128381729125977
Trainable Parameters : 198660
Epoch 64 Train Acc 75.5182876586914% Val Acc 25.790420532226562% Train Loss 0.3281354606151581 Val Loss 3.8858895301818848
Trainable Parameters : 198660
Epoch 65 Train Acc 74.03658294677734% Val Acc 26.05988121032715% Train Loss 0.33870914578437805 Val Loss 3.076287031173706
Trainable Parameters : 198660
Epoch 66 Train Acc 74.23170471191406% Val Acc 25.41317367553711% Train Loss 0.3243703246116638 Val Loss 3.9068524837493896
Trainable Parameters : 198660
Epoch 67 Train Acc 74.85365295410156% Val Acc 25.790420532226562% Train Loss 0.3255994915962219 Val Loss 3.7507026195526123
Trainable Parameters : 198660
Epoch 68 Train Acc 76.64024353027344% Val Acc 25.802396774291992% Train Loss 0.31959596276283264 Val Loss 3.91567325592041
Trainable Parameters : 198660
Epoch 69 Train Acc 77.7682876586914% Val Acc 26.910181045532227% Train Loss 0.29693055152893066 Val Loss 3.8537888526916504
Trainable Parameters : 198660
Epoch 70 Train Acc 77.12804412841797% Val Acc 26.341318130493164% Train Loss 0.30658382177352905 Val Loss 3.2868247032165527
Trainable Parameters : 198660
Epoch 71 Train Acc 76.33536529541016% Val Acc 25.86826515197754% Train Loss 0.3013886511325836 Val Loss 4.223610877990723
Trainable Parameters : 198660
Epoch 72 Train Acc 76.79877471923828% Val Acc 25.60479164123535% Train Loss 0.30330976843833923 Val Loss 4.253525733947754
Trainable Parameters : 198660
Epoch 73 Train Acc 78.13414001464844% Val Acc 26.299402236938477% Train Loss 0.29744085669517517 Val Loss 4.296451568603516
Trainable Parameters : 198660
Epoch 74 Train Acc 76.01219177246094% Val Acc 25.850299835205078% Train Loss 0.30787649750709534 Val Loss 4.539513111114502
Trainable Parameters : 198660
Epoch 75 Train Acc 78.15243530273438% Val Acc 25.62275505065918% Train Loss 0.29075348377227783 Val Loss 4.046244144439697
Trainable Parameters : 198660
Epoch 76 Train Acc 76.68292236328125% Val Acc 26.137725830078125% Train Loss 0.29314377903938293 Val Loss 3.23983097076416
Trainable Parameters : 198660
Epoch 77 Train Acc 77.15243530273438% Val Acc 25.377246856689453% Train Loss 0.2950896620750427 Val Loss 4.369302749633789
Trainable Parameters : 198660
Epoch 78 Train Acc 76.96951293945312% Val Acc 26.38323402404785% Train Loss 0.29764172434806824 Val Loss 3.967430830001831
Trainable Parameters : 198660
Epoch 79 Train Acc 79.03658294677734% Val Acc 24.580839157104492% Train Loss 0.27359145879745483 Val Loss 5.2974019050598145
Trainable Parameters : 198660
Epoch 80 Train Acc 76.80487823486328% Val Acc 25.05389404296875% Train Loss 0.2964400351047516 Val Loss 4.40608549118042
Trainable Parameters : 198660
Epoch 81 Train Acc 77.98170471191406% Val Acc 25.502994537353516% Train Loss 0.29561686515808105 Val Loss 3.850259304046631
Trainable Parameters : 198660
Epoch 82 Train Acc 78.8719482421875% Val Acc 26.155689239501953% Train Loss 0.28568029403686523 Val Loss 3.8526058197021484
Trainable Parameters : 198660
Epoch 83 Train Acc 78.77438354492188% Val Acc 26.4491024017334% Train Loss 0.28702712059020996 Val Loss 4.837985038757324
Trainable Parameters : 198660
Epoch 84 Train Acc 79.06097412109375% Val Acc 25.43113899230957% Train Loss 0.28075045347213745 Val Loss 4.3199591636657715
Trainable Parameters : 198660
Epoch 85 Train Acc 78.61585235595703% Val Acc 25.59880256652832% Train Loss 0.2729119658470154 Val Loss 3.8476779460906982
Trainable Parameters : 198660
Epoch 86 Train Acc 79.93292236328125% Val Acc 25.39521026611328% Train Loss 0.271802693605423 Val Loss 4.875336170196533
Trainable Parameters : 198660
Epoch 87 Train Acc 78.71340942382812% Val Acc 26.161678314208984% Train Loss 0.27886006236076355 Val Loss 3.2184910774230957
Trainable Parameters : 198660
Epoch 88 Train Acc 78.87804412841797% Val Acc 26.652694702148438% Train Loss 0.273539662361145 Val Loss 4.505199432373047
Trainable Parameters : 198660
Epoch 89 Train Acc 78.90853118896484% Val Acc 25.568862915039062% Train Loss 0.2765178978443146 Val Loss 4.818364143371582
Trainable Parameters : 198660
Epoch 90 Train Acc 78.79267883300781% Val Acc 25.88024139404297% Train Loss 0.2768772542476654 Val Loss 4.748331546783447
Trainable Parameters : 198660
Epoch 91 Train Acc 80.31707000732422% Val Acc 26.275449752807617% Train Loss 0.26215580105781555 Val Loss 4.4969706535339355
Trainable Parameters : 198660
Epoch 92 Train Acc 79.64024353027344% Val Acc 25.514970779418945% Train Loss 0.2723839581012726 Val Loss 5.401113986968994
Trainable Parameters : 198660
Epoch 93 Train Acc 79.46951293945312% Val Acc 26.389223098754883% Train Loss 0.2717805504798889 Val Loss 4.346952438354492
Trainable Parameters : 198660
Epoch 94 Train Acc 80.04877471923828% Val Acc 24.05389404296875% Train Loss 0.2693372666835785 Val Loss 3.7870748043060303
Trainable Parameters : 198660
Epoch 95 Train Acc 80.243896484375% Val Acc 24.664670944213867% Train Loss 0.25968965888023376 Val Loss 4.56943941116333
Trainable Parameters : 198660
Epoch 96 Train Acc 80.56097412109375% Val Acc 25.401199340820312% Train Loss 0.25789812207221985 Val Loss 4.439887523651123
Trainable Parameters : 198660
Epoch 97 Train Acc 80.35365295410156% Val Acc 25.652694702148438% Train Loss 0.2584027945995331 Val Loss 4.764418125152588
Trainable Parameters : 198660
Epoch 98 Train Acc 80.3963394165039% Val Acc 24.538923263549805% Train Loss 0.2595111131668091 Val Loss 4.680445194244385
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-1s/config.json
Model weights saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-1s/pytorch_model.bin
Epoch 99 Train Acc 79.18901824951172% Val Acc 25.329341888427734% Train Loss 0.27528125047683716 Val Loss 4.642701625823975

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.25037556 0.         0.         0.        ]
 [0.25037556 0.         0.         0.        ]
 [0.24887331 0.         0.         0.        ]
 [0.25037556 0.         0.         0.        ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.25      1.00      0.40       500
           1       0.00      0.00      0.00       500
           2       0.00      0.00      0.00       497
           3       0.00      0.00      0.00       500

    accuracy                           0.25      1997
   macro avg       0.06      0.25      0.10      1997
weighted avg       0.06      0.25      0.10      1997


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 10/10/2022 12:13:57
Fri Oct 14 00:17:40 AEDT 2022
------------------------------------------------------------------------
                         run_umbrellaDID.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_2s.py
Started: 14/10/2022 00:17:42

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: wav2vec-ADI17-2s
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: umbrella_500f_devdata
train_filename: dev_u_500f
evaluation_filename: test_u_500f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 20
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: False
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/dev_u_500f.csv
--> data_test_fp: data/test_u_500f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/umbrella_500f_devdata_local/wav2vec-ADI17-2s
--> finetuned_results_fp: /srv/scratch/z5208494/output/umbrella_500f_devdata_local/wav2vec-ADI17-2s_finetuned_results.csv
--> pretrained_mod: facebook/wav2vec2-base

------> PREPARING DATASET LABELS... ------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 2 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 0.2981,  0.3132,  0.3518,  ...,  0.3627,  0.3762,  0.3804],
        [ 0.2863,  0.1681,  0.1681,  ..., -0.1203,  0.0133,  0.1541],
        [-0.3494,  0.1355,  0.6300,  ...,  0.3492,  0.4739,  0.4478],
        ...,
        [-0.6892, -0.4810, -0.1328,  ...,  1.8152,  1.4770,  1.3480],
        [-2.0886, -2.0759, -2.2708,  ...,  0.0901,  0.0978,  0.1066],
        [-0.2250, -0.2418, -0.2517,  ..., -0.2239, -0.2356, -0.2895]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 0, 2, 3, 1, 0, 0, 3, 3, 0, 0, 3, 0, 1, 1, 1, 2, 2, 0, 3])}
Training DataCustom Files: 1963
Training Data Files: 99
Test Data Sample
/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 1.0978e-01,  8.7672e-02,  9.8727e-02,  ...,  1.5169e+00,
          2.2813e+00,  2.4502e+00],
        [-3.1213e-01, -3.6667e-01, -4.2465e-01,  ...,  1.2976e+00,
          1.4946e+00,  1.4814e+00],
        [ 2.7001e-01, -1.6203e-01, -4.1760e-01,  ...,  3.4985e-01,
          4.9270e-01,  4.8265e-01],
        ...,
        [ 4.6359e-01,  8.6928e-01,  9.2144e-01,  ...,  1.4038e-03,
          1.4444e-02, -1.1153e-02],
        [ 3.2279e-01,  1.5591e+00,  3.0096e-01,  ...,  5.1087e-01,
          5.1152e-01, -9.0898e-03],
        [-7.4783e-01, -4.1579e-01, -7.0350e-01,  ..., -7.0947e-02,
         -1.3075e-01, -9.8320e-02]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 3, 1, 0, 0, 3, 1, 0, 1, 1, 1, 3, 3, 1, 1, 1, 3, 2, 1, 3])}
Test CustomData Files: 1997
Test Data Files: 100
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 198660
Epoch 0 Train Acc 21.26262664794922% Val Acc 24.5% Train Loss 0.6974027752876282 Val Loss 1.389580488204956
Trainable Parameters : 198660
Epoch 1 Train Acc 22.121212005615234% Val Acc 23.90999984741211% Train Loss 0.6958757638931274 Val Loss 1.3881587982177734
Trainable Parameters : 198660
Epoch 2 Train Acc 24.29292869567871% Val Acc 23.26999855041504% Train Loss 0.6936874985694885 Val Loss 1.3872089385986328
Trainable Parameters : 198660
Epoch 3 Train Acc 31.363636016845703% Val Acc 25.989999771118164% Train Loss 0.690010666847229 Val Loss 1.3869298696517944
Trainable Parameters : 198660
Epoch 4 Train Acc 36.26262664794922% Val Acc 25.350000381469727% Train Loss 0.686305046081543 Val Loss 1.3876665830612183
Trainable Parameters : 198660
Epoch 5 Train Acc 38.252525329589844% Val Acc 26.189998626708984% Train Loss 0.6817113161087036 Val Loss 1.3889228105545044
Trainable Parameters : 198660
Epoch 6 Train Acc 38.101009368896484% Val Acc 24.149999618530273% Train Loss 0.677494466304779 Val Loss 1.3910033702850342
Trainable Parameters : 198660
Epoch 7 Train Acc 38.6363639831543% Val Acc 24.03999900817871% Train Loss 0.6732497811317444 Val Loss 1.3931849002838135
Trainable Parameters : 198660
Epoch 8 Train Acc 40.45454406738281% Val Acc 23.670000076293945% Train Loss 0.6686988472938538 Val Loss 1.396087646484375
Trainable Parameters : 198660
Epoch 9 Train Acc 42.24242401123047% Val Acc 23.469999313354492% Train Loss 0.6626287698745728 Val Loss 1.3998653888702393
Trainable Parameters : 198660
Epoch 10 Train Acc 42.34343338012695% Val Acc 24.719999313354492% Train Loss 0.6564540863037109 Val Loss 1.4039033651351929
Trainable Parameters : 198660
Epoch 11 Train Acc 42.47474670410156% Val Acc 26.689998626708984% Train Loss 0.6506224870681763 Val Loss 1.4065064191818237
Trainable Parameters : 198660
Epoch 12 Train Acc 43.858585357666016% Val Acc 26.469999313354492% Train Loss 0.646101176738739 Val Loss 1.4125449657440186
Trainable Parameters : 198660
Epoch 13 Train Acc 46.28282928466797% Val Acc 26.84000015258789% Train Loss 0.6385783553123474 Val Loss 1.415809154510498
Trainable Parameters : 198660
Epoch 14 Train Acc 46.0404052734375% Val Acc 26.889999389648438% Train Loss 0.6340696811676025 Val Loss 1.4179606437683105
Trainable Parameters : 198660
Epoch 15 Train Acc 46.54545593261719% Val Acc 26.09000015258789% Train Loss 0.6280688643455505 Val Loss 1.4242074489593506
Trainable Parameters : 198660
Epoch 16 Train Acc 45.92929458618164% Val Acc 29.31999969482422% Train Loss 0.6223995685577393 Val Loss 1.4247807264328003
Trainable Parameters : 198660
Epoch 17 Train Acc 47.858585357666016% Val Acc 27.739999771118164% Train Loss 0.6161347031593323 Val Loss 1.4342759847640991
Trainable Parameters : 198660
Epoch 18 Train Acc 47.65656661987305% Val Acc 29.439998626708984% Train Loss 0.6094841957092285 Val Loss 1.438600778579712
Trainable Parameters : 198660
Epoch 19 Train Acc 49.46464538574219% Val Acc 29.42999839782715% Train Loss 0.6032686829566956 Val Loss 1.437929391860962
Trainable Parameters : 198660
Epoch 20 Train Acc 49.47474670410156% Val Acc 29.729999542236328% Train Loss 0.5951308608055115 Val Loss 1.4445316791534424
Trainable Parameters : 198660
Epoch 21 Train Acc 51.030303955078125% Val Acc 30.849998474121094% Train Loss 0.5887457132339478 Val Loss 1.4535932540893555
Trainable Parameters : 198660
Epoch 22 Train Acc 52.79798126220703% Val Acc 30.899999618530273% Train Loss 0.5801870822906494 Val Loss 1.4698864221572876
Trainable Parameters : 198660
Epoch 23 Train Acc 51.93939208984375% Val Acc 29.8799991607666% Train Loss 0.5799381136894226 Val Loss 1.4720723628997803
Trainable Parameters : 198660
Epoch 24 Train Acc 53.161617279052734% Val Acc 30.19999885559082% Train Loss 0.5706005692481995 Val Loss 1.4853014945983887
Trainable Parameters : 198660
Epoch 25 Train Acc 54.34343338012695% Val Acc 30.299999237060547% Train Loss 0.5579846501350403 Val Loss 1.5115078687667847
Trainable Parameters : 198660
Epoch 26 Train Acc 53.252525329589844% Val Acc 30.399999618530273% Train Loss 0.5591945648193359 Val Loss 1.5068318843841553
Trainable Parameters : 198660
Epoch 27 Train Acc 54.82828140258789% Val Acc 30.51999855041504% Train Loss 0.5504298210144043 Val Loss 1.5100964307785034
Trainable Parameters : 198660
Epoch 28 Train Acc 54.62626266479492% Val Acc 30.03999900817871% Train Loss 0.5434391498565674 Val Loss 1.5375877618789673
Trainable Parameters : 198660
Epoch 29 Train Acc 55.47474670410156% Val Acc 30.559999465942383% Train Loss 0.5389395356178284 Val Loss 1.5451115369796753
Trainable Parameters : 198660
Epoch 30 Train Acc 55.53535461425781% Val Acc 29.979999542236328% Train Loss 0.5327017307281494 Val Loss 1.5373516082763672
Trainable Parameters : 198660
Epoch 31 Train Acc 56.989898681640625% Val Acc 30.099998474121094% Train Loss 0.525690495967865 Val Loss 1.5460662841796875
Trainable Parameters : 198660
Epoch 32 Train Acc 57.84848403930664% Val Acc 30.06999969482422% Train Loss 0.5204602479934692 Val Loss 1.5657240152359009
Trainable Parameters : 198660
Epoch 33 Train Acc 57.858585357666016% Val Acc 30.739999771118164% Train Loss 0.5177921056747437 Val Loss 1.5697544813156128
Trainable Parameters : 198660
Epoch 34 Train Acc 58.45454406738281% Val Acc 29.69999885559082% Train Loss 0.5102110505104065 Val Loss 1.6161898374557495
Trainable Parameters : 198660
Epoch 35 Train Acc 58.31312942504883% Val Acc 30.399999618530273% Train Loss 0.5002878904342651 Val Loss 1.5924617052078247
Trainable Parameters : 198660
Epoch 36 Train Acc 58.010101318359375% Val Acc 30.029998779296875% Train Loss 0.4993111193180084 Val Loss 1.669609785079956
Trainable Parameters : 198660
Epoch 37 Train Acc 58.9595947265625% Val Acc 30.369998931884766% Train Loss 0.49087685346603394 Val Loss 1.6458725929260254
Trainable Parameters : 198660
Epoch 38 Train Acc 59.898990631103516% Val Acc 29.94999885559082% Train Loss 0.48843374848365784 Val Loss 1.664021372795105
Trainable Parameters : 198660
Epoch 39 Train Acc 60.6363639831543% Val Acc 30.459999084472656% Train Loss 0.4854857623577118 Val Loss 1.701300024986267
Trainable Parameters : 198660
Epoch 40 Train Acc 62.49494934082031% Val Acc 29.739999771118164% Train Loss 0.4719770848751068 Val Loss 1.6652532815933228
Trainable Parameters : 198660
Epoch 41 Train Acc 61.24242401123047% Val Acc 30.369998931884766% Train Loss 0.4728735387325287 Val Loss 1.6457781791687012
Trainable Parameters : 198660
Epoch 42 Train Acc 61.3636360168457% Val Acc 30.229999542236328% Train Loss 0.4698953330516815 Val Loss 1.6499780416488647
Trainable Parameters : 198660
Epoch 43 Train Acc 61.64646530151367% Val Acc 30.92999839782715% Train Loss 0.46675410866737366 Val Loss 1.7155672311782837
Trainable Parameters : 198660
Epoch 44 Train Acc 62.949493408203125% Val Acc 30.899999618530273% Train Loss 0.4586949944496155 Val Loss 1.6975966691970825
Trainable Parameters : 198660
Epoch 45 Train Acc 63.010101318359375% Val Acc 30.939998626708984% Train Loss 0.45690321922302246 Val Loss 1.7139043807983398
Trainable Parameters : 198660
Epoch 46 Train Acc 64.39393615722656% Val Acc 29.739999771118164% Train Loss 0.44891655445098877 Val Loss 1.7475630044937134
Trainable Parameters : 198660
Epoch 47 Train Acc 63.48484802246094% Val Acc 30.40999984741211% Train Loss 0.4514031410217285 Val Loss 1.7190608978271484
Trainable Parameters : 198660
Epoch 48 Train Acc 63.58585739135742% Val Acc 31.049999237060547% Train Loss 0.4457453787326813 Val Loss 1.7136564254760742
Trainable Parameters : 198660
Epoch 49 Train Acc 64.67676544189453% Val Acc 30.03999900817871% Train Loss 0.44632694125175476 Val Loss 1.7075680494308472
Trainable Parameters : 198660
Epoch 50 Train Acc 64.79798126220703% Val Acc 30.119998931884766% Train Loss 0.438105970621109 Val Loss 1.8091191053390503
Trainable Parameters : 198660
Epoch 51 Train Acc 64.66666412353516% Val Acc 30.689998626708984% Train Loss 0.43527814745903015 Val Loss 1.7478246688842773
Trainable Parameters : 198660
Epoch 52 Train Acc 66.36363983154297% Val Acc 30.69999885559082% Train Loss 0.42012327909469604 Val Loss 1.7791311740875244
Trainable Parameters : 198660
Epoch 53 Train Acc 64.919189453125% Val Acc 30.34000015258789% Train Loss 0.42977628111839294 Val Loss 1.7369035482406616
Trainable Parameters : 198660
Epoch 54 Train Acc 64.8787841796875% Val Acc 30.1299991607666% Train Loss 0.43348610401153564 Val Loss 1.770154356956482
Trainable Parameters : 198660
Epoch 55 Train Acc 65.22222137451172% Val Acc 30.809999465942383% Train Loss 0.42881423234939575 Val Loss 1.7616511583328247
Trainable Parameters : 198660
Epoch 56 Train Acc 67.54545593261719% Val Acc 31.78999900817871% Train Loss 0.418503999710083 Val Loss 1.7836469411849976
Trainable Parameters : 198660
Epoch 57 Train Acc 67.6464614868164% Val Acc 29.44999885559082% Train Loss 0.41907668113708496 Val Loss 1.817681074142456
Trainable Parameters : 198660
Epoch 58 Train Acc 65.63636016845703% Val Acc 30.029998779296875% Train Loss 0.4282485544681549 Val Loss 1.7716901302337646
Trainable Parameters : 198660
Epoch 59 Train Acc 67.97979736328125% Val Acc 30.079999923706055% Train Loss 0.4150301516056061 Val Loss 1.7910935878753662
Trainable Parameters : 198660
Epoch 60 Train Acc 65.90908813476562% Val Acc 29.75% Train Loss 0.42208167910575867 Val Loss 1.9048011302947998
Trainable Parameters : 198660
Epoch 61 Train Acc 68.6868667602539% Val Acc 31.299999237060547% Train Loss 0.4016803801059723 Val Loss 1.8452930450439453
Trainable Parameters : 198660
Epoch 62 Train Acc 66.49494934082031% Val Acc 32.38999938964844% Train Loss 0.4206198751926422 Val Loss 1.9271771907806396
Trainable Parameters : 198660
Epoch 63 Train Acc 67.44444274902344% Val Acc 32.14999771118164% Train Loss 0.40398815274238586 Val Loss 2.072218656539917
Trainable Parameters : 198660
Epoch 64 Train Acc 67.62625885009766% Val Acc 32.349998474121094% Train Loss 0.40443307161331177 Val Loss 1.9043288230895996
Trainable Parameters : 198660
Epoch 65 Train Acc 67.32323455810547% Val Acc 30.389999389648438% Train Loss 0.40742772817611694 Val Loss 1.857959270477295
Trainable Parameters : 198660
Epoch 66 Train Acc 67.44444274902344% Val Acc 31.549999237060547% Train Loss 0.39981237053871155 Val Loss 1.8612452745437622
Trainable Parameters : 198660
Epoch 67 Train Acc 67.67676544189453% Val Acc 30.139999389648438% Train Loss 0.39548957347869873 Val Loss 1.846354603767395
Trainable Parameters : 198660
Epoch 68 Train Acc 68.93939208984375% Val Acc 30.28999900817871% Train Loss 0.39098644256591797 Val Loss 1.8656400442123413
Trainable Parameters : 198660
Epoch 69 Train Acc 69.26262664794922% Val Acc 31.170000076293945% Train Loss 0.3854108154773712 Val Loss 2.0074119567871094
Trainable Parameters : 198660
Epoch 70 Train Acc 69.94949340820312% Val Acc 30.099998474121094% Train Loss 0.39594846963882446 Val Loss 2.0039241313934326
Trainable Parameters : 198660
Epoch 71 Train Acc 69.1919174194336% Val Acc 30.989999771118164% Train Loss 0.39188265800476074 Val Loss 1.9512065649032593
Trainable Parameters : 198660
Epoch 72 Train Acc 69.01010131835938% Val Acc 30.09000015258789% Train Loss 0.388377845287323 Val Loss 1.9367812871932983
Trainable Parameters : 198660
Epoch 73 Train Acc 68.20201873779297% Val Acc 29.829999923706055% Train Loss 0.3933597207069397 Val Loss 1.8745805025100708
Trainable Parameters : 198660
Epoch 74 Train Acc 68.83838653564453% Val Acc 29.969999313354492% Train Loss 0.3888280391693115 Val Loss 1.8924975395202637
Trainable Parameters : 198660
Epoch 75 Train Acc 68.06060791015625% Val Acc 30.8799991607666% Train Loss 0.404450386762619 Val Loss 1.893458366394043
Trainable Parameters : 198660
Epoch 76 Train Acc 70.20201873779297% Val Acc 31.06999969482422% Train Loss 0.391301691532135 Val Loss 1.8499902486801147
Trainable Parameters : 198660
Epoch 77 Train Acc 70.55555725097656% Val Acc 31.939998626708984% Train Loss 0.3775675296783447 Val Loss 1.9483327865600586
Trainable Parameters : 198660
Epoch 78 Train Acc 67.29293060302734% Val Acc 30.459999084472656% Train Loss 0.39669719338417053 Val Loss 1.8871833086013794
Trainable Parameters : 198660
Epoch 79 Train Acc 70.70706939697266% Val Acc 31.439998626708984% Train Loss 0.3882146179676056 Val Loss 1.99205482006073
Trainable Parameters : 198660
Epoch 80 Train Acc 67.65656280517578% Val Acc 29.719999313354492% Train Loss 0.38877278566360474 Val Loss 1.8818491697311401
Trainable Parameters : 198660
Epoch 81 Train Acc 69.919189453125% Val Acc 31.399999618530273% Train Loss 0.3821162283420563 Val Loss 1.915731430053711
Trainable Parameters : 198660
Epoch 82 Train Acc 68.8080825805664% Val Acc 30.51999855041504% Train Loss 0.3883917033672333 Val Loss 1.8894556760787964
Trainable Parameters : 198660
Epoch 83 Train Acc 69.66666412353516% Val Acc 29.3799991607666% Train Loss 0.3814178705215454 Val Loss 2.1160664558410645
Trainable Parameters : 198660
Epoch 84 Train Acc 68.48484802246094% Val Acc 30.389999389648438% Train Loss 0.383989542722702 Val Loss 2.1181418895721436
Trainable Parameters : 198660
Epoch 85 Train Acc 70.6868667602539% Val Acc 31.889999389648438% Train Loss 0.3819372355937958 Val Loss 1.954953908920288
Trainable Parameters : 198660
Epoch 86 Train Acc 71.11111450195312% Val Acc 31.779998779296875% Train Loss 0.3718278408050537 Val Loss 1.9597152471542358
Trainable Parameters : 198660
Epoch 87 Train Acc 68.9595947265625% Val Acc 29.439998626708984% Train Loss 0.3823012411594391 Val Loss 2.190211296081543
Trainable Parameters : 198660
Epoch 88 Train Acc 73.58586120605469% Val Acc 30.510000228881836% Train Loss 0.36142584681510925 Val Loss 1.9614397287368774
Trainable Parameters : 198660
Epoch 89 Train Acc 70.18181610107422% Val Acc 30.01999855041504% Train Loss 0.3762780427932739 Val Loss 1.9873321056365967
Trainable Parameters : 198660
Epoch 90 Train Acc 71.28282928466797% Val Acc 31.44999885559082% Train Loss 0.3761233985424042 Val Loss 1.8976023197174072
Trainable Parameters : 198660
Epoch 91 Train Acc 71.080810546875% Val Acc 29.78999900817871% Train Loss 0.36262622475624084 Val Loss 2.0478451251983643
Trainable Parameters : 198660
Epoch 92 Train Acc 70.32323455810547% Val Acc 30.3799991607666% Train Loss 0.38064461946487427 Val Loss 2.1620190143585205
Trainable Parameters : 198660
Epoch 93 Train Acc 72.39393615722656% Val Acc 30.94999885559082% Train Loss 0.35288840532302856 Val Loss 2.135561227798462
Trainable Parameters : 198660
Epoch 94 Train Acc 72.37373352050781% Val Acc 30.03999900817871% Train Loss 0.3610997200012207 Val Loss 2.1972978115081787
Trainable Parameters : 198660
Epoch 95 Train Acc 71.03030395507812% Val Acc 31.84000015258789% Train Loss 0.3724430203437805 Val Loss 1.9265305995941162
Trainable Parameters : 198660
Epoch 96 Train Acc 73.38383483886719% Val Acc 30.229999542236328% Train Loss 0.35670310258865356 Val Loss 2.2096762657165527
Trainable Parameters : 198660
Epoch 97 Train Acc 70.82828521728516% Val Acc 31.6299991607666% Train Loss 0.3710026741027832 Val Loss 2.004210948944092
Trainable Parameters : 198660
Epoch 98 Train Acc 71.86869049072266% Val Acc 31.889999389648438% Train Loss 0.35848748683929443 Val Loss 2.046299934387207
Trainable Parameters : 198660
Configuration saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-2s/config.json
Model weights saved in ../output/umbrella_500f_devdata_local/wav2vec-ADI17-2s/pytorch_model.bin
Epoch 99 Train Acc 70.62625885009766% Val Acc 28.739999771118164% Train Loss 0.3695773780345917 Val Loss 2.476203203201294

------> EVALUATING MODEL... ------------------------------------------ 

/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/apps/python/3.8.3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CONFUSION MATRIX
[[0.   0.   0.   0.  ]
 [0.25 0.   0.   0.  ]
 [0.5  0.   0.   0.25]
 [0.   0.   0.   0.  ]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
         497       0.00      0.00      0.00       1.0
         500       0.00      0.00      0.00       3.0
        1997       0.00      0.00      0.00       0.0

    accuracy                           0.00       4.0
   macro avg       0.00      0.00      0.00       4.0
weighted avg       0.00      0.00      0.00       4.0


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/10/2022 00:46:07
