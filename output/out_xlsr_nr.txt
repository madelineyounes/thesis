Wed Oct 26 16:25:13 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 26/10/2022 16:25:25

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 396, in <module>
    TrainData = next(iter(trainDataLoader))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 530, in __next__
    data = self._next_data()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1224, in _next_data
    return self._process_data(data)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1250, in _process_data
    data.reraise()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/z5208494/thesis/customDataNR.py", line 56, in __getitem__
    speech = speech_file_to_array_fn(audiopath, self.sampling_rate, self.norm)
AttributeError: 'CustomDataset' object has no attribute 'norm'

<<<<<<< HEAD
Wed Oct 26 21:42:20 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 26/10/2022 21:42:33

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.4893e+00,  8.2514e-01,  8.7882e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.4439e+00, -1.2509e+00, -1.1298e+00,  ...,  3.4840e+00,
          3.4407e+00,  1.6194e+00],
        [-9.1274e+00, -8.7851e+00, -7.7613e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 3.3655e-01,  8.3061e-01,  2.2332e-01,  ...,  3.0693e-03,
         -1.1751e-02, -4.0876e-03],
        [ 9.0473e-04,  1.0346e-02,  1.7978e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.2065e+00, -3.5894e+00, -4.2492e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 3, 1, 2, 3, 2, 1, 0, 2, 2, 1, 2, 2, 0, 1, 1, 3, 0, 2, 0, 0, 2, 3,
        3, 1, 2, 1, 0, 3, 3, 0, 2, 3, 3, 0, 2, 0, 2, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-4.2988e-02, -4.6289e-02, -5.1633e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.0455e-03,  6.5684e-03,  6.2668e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.7407e-03,  5.7493e-03,  7.5497e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-6.1391e-04, -2.6391e-04, -2.3715e-03,  ...,  3.0025e-01,
          5.4263e-01,  8.1184e-01],
        [-2.6356e-03,  2.2939e-03, -1.8262e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-5.9910e-02, -5.7939e-02, -6.8568e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 0, 0, 3, 0, 3, 2, 0, 3, 0, 3, 0, 2, 2, 1, 2, 2, 0, 0, 3, 3, 2, 3, 2,
        1, 3, 0, 0, 0, 3, 1, 1, 2, 2, 1, 3, 3, 2, 3, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'projector.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.0058,  0.0095,  0.0123,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0200,  0.0191,  0.0218,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2705,  0.1753,  0.3237,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-1.5697, -1.3994, -1.5031,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0109, -0.0115,  0.0063,  ...,  0.0077,  0.0188,  0.0318],
        [ 0.8606,  0.9374,  1.0788,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 2, 2, 2, 2, 0, 3, 1, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1,
        3, 2, 2, 3, 2, 2, 1, 3, 3, 1, 0, 3, 0, 3, 2, 1])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 28.95437240600586% Val Acc 25.5% Train Loss 0.6869237422943115 Val Loss 1.4051316976547241
Trainable Parameters : 264452
Epoch 1 Train Acc 40.0% Val Acc 26.200000762939453% Train Loss 0.6543092727661133 Val Loss 1.4593757390975952
Trainable Parameters : 264452
Epoch 2 Train Acc 39.992393493652344% Val Acc 24.700000762939453% Train Loss 0.6482349634170532 Val Loss 1.458328127861023
Trainable Parameters : 264452
Epoch 3 Train Acc 40.19771957397461% Val Acc 24.100000381469727% Train Loss 0.6419419050216675 Val Loss 1.460398554801941
Trainable Parameters : 264452
Epoch 4 Train Acc 41.06083679199219% Val Acc 28.700000762939453% Train Loss 0.63434237241745 Val Loss 1.4519108533859253
Trainable Parameters : 264452
Epoch 5 Train Acc 42.821292877197266% Val Acc 31.399999618530273% Train Loss 0.6264311671257019 Val Loss 1.4336482286453247
Trainable Parameters : 264452
Epoch 6 Train Acc 44.39163589477539% Val Acc 31.700000762939453% Train Loss 0.6180532574653625 Val Loss 1.3913449048995972
Trainable Parameters : 264452
Epoch 7 Train Acc 46.14828872680664% Val Acc 32.29999923706055% Train Loss 0.6089162230491638 Val Loss 1.401823878288269
Trainable Parameters : 264452
Epoch 8 Train Acc 47.8745231628418% Val Acc 35.20000076293945% Train Loss 0.600373387336731 Val Loss 1.367717981338501
Trainable Parameters : 264452
Epoch 9 Train Acc 49.00380325317383% Val Acc 35.0% Train Loss 0.5912097096443176 Val Loss 1.3531748056411743
Trainable Parameters : 264452
Epoch 10 Train Acc 49.73384094238281% Val Acc 33.400001525878906% Train Loss 0.5822057127952576 Val Loss 1.4052952527999878
Trainable Parameters : 264452
Epoch 11 Train Acc 50.42585372924805% Val Acc 32.20000076293945% Train Loss 0.5768563747406006 Val Loss 1.4203563928604126
Trainable Parameters : 264452
Epoch 12 Train Acc 51.00760269165039% Val Acc 33.60000228881836% Train Loss 0.5710106492042542 Val Loss 1.3809244632720947
Trainable Parameters : 264452
Epoch 13 Train Acc 52.277565002441406% Val Acc 41.20000076293945% Train Loss 0.5634687542915344 Val Loss 1.2697018384933472
Trainable Parameters : 264452
Epoch 14 Train Acc 53.05703353881836% Val Acc 42.79999923706055% Train Loss 0.5565688014030457 Val Loss 1.2847483158111572
Trainable Parameters : 264452
Epoch 15 Train Acc 53.718631744384766% Val Acc 38.0% Train Loss 0.5502561926841736 Val Loss 1.3462340831756592
Trainable Parameters : 264452
Epoch 16 Train Acc 53.787071228027344% Val Acc 39.400001525878906% Train Loss 0.5493955612182617 Val Loss 1.3544412851333618
Trainable Parameters : 264452
Epoch 17 Train Acc 54.992393493652344% Val Acc 34.0% Train Loss 0.5455493927001953 Val Loss 1.5104097127914429
Trainable Parameters : 264452
Epoch 18 Train Acc 54.479087829589844% Val Acc 41.20000076293945% Train Loss 0.5419526696205139 Val Loss 1.284603476524353
Trainable Parameters : 264452
Epoch 19 Train Acc 54.973384857177734% Val Acc 40.20000076293945% Train Loss 0.5379464030265808 Val Loss 1.34392249584198
Trainable Parameters : 264452
Epoch 20 Train Acc 55.09885787963867% Val Acc 46.29999923706055% Train Loss 0.534542977809906 Val Loss 1.261456847190857
Trainable Parameters : 264452
Epoch 21 Train Acc 55.67680740356445% Val Acc 44.79999923706055% Train Loss 0.5314928293228149 Val Loss 1.321675181388855
Trainable Parameters : 264452
Epoch 22 Train Acc 55.794677734375% Val Acc 44.60000228881836% Train Loss 0.5298988819122314 Val Loss 1.2330163717269897
Trainable Parameters : 264452
Epoch 23 Train Acc 55.418251037597656% Val Acc 45.79999923706055% Train Loss 0.5285009741783142 Val Loss 1.2071037292480469
Trainable Parameters : 264452
Epoch 24 Train Acc 56.1026611328125% Val Acc 40.900001525878906% Train Loss 0.5266396403312683 Val Loss 1.372064471244812
Trainable Parameters : 264452
Epoch 25 Train Acc 55.98859405517578% Val Acc 46.0% Train Loss 0.5257089138031006 Val Loss 1.2040332555770874
Trainable Parameters : 264452
Epoch 26 Train Acc 56.26235580444336% Val Acc 36.20000076293945% Train Loss 0.5255396366119385 Val Loss 1.5410202741622925
Trainable Parameters : 264452
Epoch 27 Train Acc 56.167301177978516% Val Acc 43.79999923706055% Train Loss 0.5248177647590637 Val Loss 1.3050109148025513
Trainable Parameters : 264452
Epoch 28 Train Acc 56.589351654052734% Val Acc 47.900001525878906% Train Loss 0.5197764039039612 Val Loss 1.2551538944244385
Trainable Parameters : 264452
Epoch 29 Train Acc 56.77946853637695% Val Acc 38.79999923706055% Train Loss 0.5248975157737732 Val Loss 1.514435887336731
Trainable Parameters : 264452
Epoch 30 Train Acc 56.821292877197266% Val Acc 45.29999923706055% Train Loss 0.519494891166687 Val Loss 1.300317645072937
Trainable Parameters : 264452
Epoch 31 Train Acc 56.277565002441406% Val Acc 46.400001525878906% Train Loss 0.5234115123748779 Val Loss 1.2115733623504639
Trainable Parameters : 264452
Epoch 32 Train Acc 57.186309814453125% Val Acc 45.0% Train Loss 0.5196327567100525 Val Loss 1.327957034111023
Trainable Parameters : 264452
Epoch 33 Train Acc 56.49049377441406% Val Acc 43.0% Train Loss 0.5217486619949341 Val Loss 1.4010289907455444
Trainable Parameters : 264452
Epoch 34 Train Acc 57.5361213684082% Val Acc 40.5% Train Loss 0.5142330527305603 Val Loss 1.4138078689575195
Trainable Parameters : 264452
Epoch 35 Train Acc 57.15589141845703% Val Acc 43.20000076293945% Train Loss 0.5169218182563782 Val Loss 1.3524776697158813
Trainable Parameters : 264452
Epoch 36 Train Acc 56.40304183959961% Val Acc 48.0% Train Loss 0.5193210244178772 Val Loss 1.3397079706192017
Trainable Parameters : 264452
Epoch 37 Train Acc 56.86311721801758% Val Acc 48.400001525878906% Train Loss 0.5180723071098328 Val Loss 1.248003363609314
Trainable Parameters : 264452
Epoch 38 Train Acc 56.22053146362305% Val Acc 43.70000076293945% Train Loss 0.5193512439727783 Val Loss 1.4184396266937256
Trainable Parameters : 264452
Epoch 39 Train Acc 57.28517150878906% Val Acc 35.0% Train Loss 0.5144625306129456 Val Loss 1.5012482404708862
Trainable Parameters : 264452
Epoch 40 Train Acc 57.338401794433594% Val Acc 53.29999923706055% Train Loss 0.51358562707901 Val Loss 1.17648184299469
Trainable Parameters : 264452
Epoch 41 Train Acc 57.623573303222656% Val Acc 42.5% Train Loss 0.514604926109314 Val Loss 1.306745171546936
Trainable Parameters : 264452
Epoch 42 Train Acc 57.5361213684082% Val Acc 55.20000076293945% Train Loss 0.5116227269172668 Val Loss 1.1058552265167236
Trainable Parameters : 264452
Epoch 43 Train Acc 57.726234436035156% Val Acc 45.60000228881836% Train Loss 0.509967565536499 Val Loss 1.208135962486267
Trainable Parameters : 264452
Epoch 44 Train Acc 58.34600830078125% Val Acc 38.900001525878906% Train Loss 0.505830705165863 Val Loss 1.5077869892120361
Trainable Parameters : 264452
Epoch 45 Train Acc 58.00760269165039% Val Acc 49.5% Train Loss 0.5075322389602661 Val Loss 1.2818191051483154
Trainable Parameters : 264452
Epoch 46 Train Acc 58.17110061645508% Val Acc 43.900001525878906% Train Loss 0.5080139636993408 Val Loss 1.3754457235336304
Trainable Parameters : 264452
Epoch 47 Train Acc 58.48289108276367% Val Acc 54.400001525878906% Train Loss 0.5076122283935547 Val Loss 1.1156333684921265
Trainable Parameters : 264452
Epoch 48 Train Acc 58.543724060058594% Val Acc 44.70000076293945% Train Loss 0.5054258108139038 Val Loss 1.4059858322143555
Trainable Parameters : 264452
Epoch 49 Train Acc 58.372623443603516% Val Acc 45.60000228881836% Train Loss 0.5028601288795471 Val Loss 1.33469820022583
Trainable Parameters : 264452
=======
>>>>>>> ffaef3afa3ac930227cea1150efd6f9c798506a4
Fri Oct 28 11:39:01 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 28/10/2022 11:39:21

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 4.3399e-03,  4.7973e-03,  4.2158e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-7.1626e-02, -2.0482e-01, -3.6125e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-5.0736e-03, -2.2955e-03,  1.3634e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 9.7492e-04, -9.1258e-04,  1.0932e-02,  ..., -1.7715e-05,
         -3.8235e-05, -5.3355e-05],
        [ 4.8629e-02,  5.6643e-02,  6.1225e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.0555e-04,  1.2216e-03,  9.7090e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 3, 2, 0, 0, 1, 1, 0, 3, 2, 3, 0, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3,
        3, 2, 2, 3, 3, 2, 3, 3, 0, 3, 2, 2, 2, 0, 1, 1])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[ 1.0100e+00,  6.1360e-01,  4.5021e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.3435e-01, -4.9701e-01, -6.4231e-01,  ...,  2.6070e+00,
          2.4279e+00,  2.0053e+00],
        [-8.3018e-04, -1.0908e-03, -1.0095e-03,  ...,  5.0225e-04,
         -4.2785e-04, -4.7363e-04],
        ...,
        [-2.2306e-02, -3.2110e-02,  1.1299e-02,  ...,  1.3225e-03,
         -1.2796e-04,  1.2958e-03],
        [-1.2424e-03,  2.4067e-03, -3.8756e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.6645e-02, -4.5477e-02, -4.6489e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 1, 2, 1, 0, 3, 3, 2, 2, 3, 2, 0, 3, 3, 3, 1, 1, 3, 1, 3, 0, 2, 3,
        3, 3, 3, 0, 2, 3, 3, 0, 3, 3, 2, 1, 3, 2, 2, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'classifier.bias', 'projector.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 5.8808e-04, -1.3110e-04, -9.8904e-04,  ..., -8.2171e-01,
         -1.0501e+00, -1.2008e+00],
        [ 3.4467e-01,  4.6078e-01,  5.0067e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.5435e-02, -2.5318e-02, -1.0326e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 7.7631e-01,  1.3190e+00,  1.7171e+00,  ..., -1.8754e+00,
         -1.1922e+00, -6.0643e-01],
        [-3.1449e-02, -3.0929e-02,  3.5760e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.8344e-01, -3.7619e-01, -4.0563e-01,  ..., -1.0731e+00,
         -9.8752e-01, -2.6961e-01]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 1, 2, 0, 0, 2, 1, 1, 2, 1, 2, 3, 1, 0, 1, 3, 2, 2, 1, 3, 3, 2, 3, 3,
        3, 1, 2, 1, 1, 0, 2, 3, 1, 0, 0, 0, 3, 2, 1, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 720, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_nr.py", line 545, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_nr.py", line 565, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_nr.py", line 608, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 710, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 589, in forward
    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask
RuntimeError: CUDA out of memory. Tried to allocate 608.00 MiB (GPU 0; 31.75 GiB total capacity; 29.97 GiB already allocated; 6.00 MiB free; 30.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Fri Oct 28 11:44:30 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 28/10/2022 11:44:47

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 24
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0033, -0.0029, -0.0036,  ...,  0.1756,  0.1703,  0.1632],
        [ 0.2170,  0.0292,  0.0785,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1366,  0.4661,  0.6429,  ..., -0.1500, -0.2119, -0.2495],
        ...,
        [ 0.0081,  0.0186,  0.0422,  ...,  0.0535,  0.0643,  0.0716],
        [ 0.2599,  0.2803,  0.4121,  ..., -0.0054, -0.0032, -0.0011],
        [-0.0008, -0.0008, -0.0009,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 2, 3, 2, 3, 0, 0, 3, 2, 0, 0, 2, 3, 0, 3, 2, 1, 0, 0, 0, 2, 0, 2])}
Training DataCustom Files: 10502
Training Data Files: 438
Val Data Sample
{'input_values': tensor([[ 6.3268e-01,  5.1878e-01,  5.5399e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.1829e-01, -9.9147e-01, -1.2617e+00,  ...,  3.3838e-01,
          3.9886e-01,  4.5334e-01],
        [-2.8483e-01,  3.2058e-01,  2.6943e-01,  ..., -5.8935e-01,
         -4.7329e-01, -5.4390e-01],
        ...,
        [-4.4544e-01, -5.1297e-01, -4.8098e-01,  ..., -2.0383e-01,
         -1.2103e-01, -4.7997e-02],
        [ 1.2531e-02,  8.0402e-03,  1.0695e-02,  ...,  5.3830e-05,
          5.3831e-05,  5.3838e-05],
        [ 1.1190e+00,  4.8430e-01,  5.6913e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 2, 0, 1, 2, 3, 3, 0, 2, 1, 0, 2, 3, 1, 0, 3, 1, 2, 3, 3, 2, 1, 1])}
Test CustomData Files: 813
Test Data Files: 34
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'classifier.weight', 'classifier.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 4.9192e-03,  5.3284e-03,  2.1234e-03,  ..., -3.2242e-01,
         -2.8214e-01, -2.5992e-02],
        [-6.7133e-03, -4.2381e-04,  4.5386e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.4091e+00,  2.5462e+00,  2.5700e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 1.2128e+00,  8.0495e-01,  7.4335e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.1437e+00, -9.1001e-01, -4.9409e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.5821e-03, -3.4961e-04, -1.1967e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 1, 1, 2, 3, 1, 3, 2, 3, 3, 0, 2, 2, 2, 0, 3, 3, 1, 3, 2, 1, 3, 2])}
Test CustomData Files: 398
Test Data Files: 17
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 720, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_nr.py", line 545, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_nr.py", line 565, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_nr.py", line 608, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 710, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 576, in forward
    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))
RuntimeError: CUDA out of memory. Tried to allocate 366.00 MiB (GPU 0; 31.75 GiB total capacity; 29.66 GiB already allocated; 358.00 MiB free; 29.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Fri Oct 28 13:53:39 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 28/10/2022 13:53:54

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[2.3066e-01, 8.4955e-02, 2.3972e-01,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [1.2030e+00, 1.1004e+00, 1.3435e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [3.6760e+00, 3.6687e+00, 3.2004e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        ...,
        [2.3242e+00, 1.8206e+00, 1.9986e+00,  ..., 6.9472e-01, 7.4653e-01,
         7.8930e-01],
        [8.0555e-04, 1.2216e-03, 9.7090e-04,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [7.0030e-02, 5.4149e-02, 5.8230e-02,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 0, 2, 2, 2, 3, 2, 1, 2, 1, 2, 1, 2, 2, 3, 2, 0, 2, 3, 0, 3, 3, 0,
        0, 2, 0, 0, 2, 3, 2, 1, 0, 1, 2, 1, 2, 2, 1, 0])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-2.8711e-01, -2.8038e-02, -9.2422e-02,  ...,  8.7110e-01,
          2.6163e+00,  1.7656e+00],
        [-2.7270e+00, -2.0877e+00, -1.4125e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.5631e-01,  1.0004e+00,  1.5179e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-2.2700e-01, -3.3146e-01, -5.4180e-01,  ...,  5.8577e-04,
          5.3615e-04,  4.8178e-04],
        [ 6.6477e-03,  6.0643e-03,  7.3224e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.7578e-01, -4.3064e-01, -5.7764e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 0, 1, 1, 0, 3, 2, 0, 1, 3, 3, 2, 0, 3, 2, 1, 3, 1, 1, 2, 1, 1, 2,
        3, 1, 2, 3, 2, 2, 1, 0, 2, 2, 3, 2, 0, 3, 1, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.weight', 'classifier.bias', 'classifier.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 2.7913e-04, -2.6333e-04,  1.6222e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 9.1214e-02, -1.5391e-02, -1.7151e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-9.6867e-03, -1.3391e-02, -1.4628e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 9.7614e-03,  6.9365e-02, -1.4372e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.7171e-02, -2.7255e-02, -3.1989e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.6712e-03,  1.8459e-03,  1.5797e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 0, 2, 0, 0, 1, 1, 3, 0, 3, 0, 2, 0, 1, 1, 0, 3, 3, 1, 1, 2, 0, 3,
        2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 3, 2, 0, 3, 1, 3])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 720, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_nr.py", line 545, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_nr.py", line 565, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_nr.py", line 608, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 715, in forward
    hidden_states = hidden_states + self.feed_forward(self.final_layer_norm(hidden_states))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 651, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/activations.py", line 56, in forward
    return self.act(input)
RuntimeError: CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 31.75 GiB total capacity; 30.08 GiB already allocated; 156.00 MiB free; 30.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Sat Oct 29 10:54:57 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 29/10/2022 10:55:12

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-1.4715e+00, -1.5040e+00, -1.7570e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.5196e+00,  3.6348e+00,  1.8356e+01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-4.7127e-01, -2.3734e-01, -4.1282e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-6.2182e-03,  5.2288e-02, -3.8957e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0191e+00, -6.7056e-01, -2.0900e-01,  ...,  2.7865e+00,
          2.4890e+00,  2.0625e+00],
        [-5.1719e-02, -4.4632e-02, -6.2005e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 0, 1, 0, 0, 1, 2, 3, 1, 0, 3, 2, 3, 2, 3, 2, 0, 3, 3, 0, 3, 1, 2,
        3, 2, 1, 3, 2, 2, 1, 1, 1, 0, 2, 2, 2, 0, 1, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-1.8421, -2.3763, -2.5667,  ..., -1.4054, -1.1256, -0.8383],
        [ 0.3737,  0.4176,  0.4354,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4565,  0.5682,  0.7253,  ...,  0.1444,  0.1369,  0.1302],
        ...,
        [-0.0143, -0.0204, -0.0197,  ...,  0.0000,  0.0000,  0.0000],
        [-2.7420, -2.6076, -3.1934,  ...,  1.1529,  1.3819,  1.4497],
        [ 0.0188,  0.0200,  0.0212,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 1, 2, 1, 0, 0, 0, 2, 2, 1, 2, 1, 1, 0, 1, 3, 0, 3, 3, 0, 3, 0, 0,
        1, 1, 0, 0, 2, 3, 1, 3, 2, 1, 1, 2, 2, 1, 3, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'classifier.bias', 'projector.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 1.7728e+00,  1.6911e+00,  1.6479e+00,  ...,  8.7288e-01,
          6.8575e-01,  4.6735e-01],
        [ 5.3496e-01, -2.6568e-01, -4.1135e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.0738e-01,  2.4392e-01,  2.8339e-01,  ..., -1.9145e-04,
         -1.6422e-04, -1.3268e-05],
        ...,
        [ 2.7172e+00,  1.2029e+00,  1.4148e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.8618e-03, -7.3046e-04, -7.0749e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.9239e-01,  1.8293e+00,  1.7535e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 2, 1, 3, 3, 3, 0, 0, 1, 1, 1, 1, 0, 3, 0, 0, 3, 0, 0, 1, 0, 0, 1, 1,
        3, 0, 1, 1, 3, 0, 3, 2, 1, 0, 3, 2, 3, 2, 0, 3])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 35.74524688720703% Val Acc 25.5% Train Loss 0.6786112785339355 Val Loss 1.4150742292404175
Trainable Parameters : 264452
Epoch 1 Train Acc 40.0% Val Acc 26.200000762939453% Train Loss 0.6527032852172852 Val Loss 1.4586683511734009
Trainable Parameters : 264452
Epoch 2 Train Acc 39.992393493652344% Val Acc 24.399999618530273% Train Loss 0.6463303565979004 Val Loss 1.4574170112609863
Trainable Parameters : 264452
Epoch 3 Train Acc 40.25475311279297% Val Acc 24.600000381469727% Train Loss 0.6406141519546509 Val Loss 1.4564555883407593
Trainable Parameters : 264452
Epoch 4 Train Acc 41.418251037597656% Val Acc 29.700000762939453% Train Loss 0.633048951625824 Val Loss 1.449140191078186
Trainable Parameters : 264452
Epoch 5 Train Acc 42.79847717285156% Val Acc 32.29999923706055% Train Loss 0.6244764924049377 Val Loss 1.4248721599578857
Trainable Parameters : 264452
Epoch 6 Train Acc 44.95817565917969% Val Acc 30.80000114440918% Train Loss 0.6154907941818237 Val Loss 1.3839269876480103
Trainable Parameters : 264452
Epoch 7 Train Acc 46.51710891723633% Val Acc 32.0% Train Loss 0.6064847111701965 Val Loss 1.4021681547164917
Trainable Parameters : 264452
Epoch 8 Train Acc 48.05323028564453% Val Acc 35.900001525878906% Train Loss 0.5972500443458557 Val Loss 1.3566166162490845
Trainable Parameters : 264452
Epoch 9 Train Acc 49.224334716796875% Val Acc 35.5% Train Loss 0.5886512398719788 Val Loss 1.3499542474746704
Trainable Parameters : 264452
Epoch 10 Train Acc 49.89353561401367% Val Acc 34.0% Train Loss 0.5813849568367004 Val Loss 1.4067267179489136
Trainable Parameters : 264452
Epoch 11 Train Acc 50.90494155883789% Val Acc 32.60000228881836% Train Loss 0.5750350952148438 Val Loss 1.4517325162887573
Trainable Parameters : 264452
Epoch 12 Train Acc 51.441062927246094% Val Acc 34.10000228881836% Train Loss 0.5698201060295105 Val Loss 1.3771504163742065
Trainable Parameters : 264452
Epoch 13 Train Acc 51.8973388671875% Val Acc 41.70000076293945% Train Loss 0.5637909173965454 Val Loss 1.2617462873458862
Trainable Parameters : 264452
Epoch 14 Train Acc 52.8745231628418% Val Acc 40.0% Train Loss 0.5588409900665283 Val Loss 1.2966573238372803
Trainable Parameters : 264452
Epoch 15 Train Acc 53.315589904785156% Val Acc 36.79999923706055% Train Loss 0.5520913600921631 Val Loss 1.3470430374145508
Trainable Parameters : 264452
Epoch 16 Train Acc 52.927757263183594% Val Acc 40.20000076293945% Train Loss 0.5507732629776001 Val Loss 1.334381341934204
Trainable Parameters : 264452
Epoch 17 Train Acc 54.064640045166016% Val Acc 33.10000228881836% Train Loss 0.5474426746368408 Val Loss 1.5714735984802246
Trainable Parameters : 264452
Epoch 18 Train Acc 54.79847717285156% Val Acc 41.400001525878906% Train Loss 0.5395046472549438 Val Loss 1.3027749061584473
Trainable Parameters : 264452
Epoch 19 Train Acc 55.076045989990234% Val Acc 39.79999923706055% Train Loss 0.5369423627853394 Val Loss 1.3615716695785522
Trainable Parameters : 264452
Epoch 20 Train Acc 54.98479080200195% Val Acc 45.79999923706055% Train Loss 0.5362340807914734 Val Loss 1.2652772665023804
Trainable Parameters : 264452
Epoch 21 Train Acc 55.35361099243164% Val Acc 42.5% Train Loss 0.5328715443611145 Val Loss 1.333379864692688
Trainable Parameters : 264452
Epoch 22 Train Acc 55.29277420043945% Val Acc 46.60000228881836% Train Loss 0.5319584608078003 Val Loss 1.215959072113037
Trainable Parameters : 264452
Epoch 23 Train Acc 55.96577835083008% Val Acc 45.70000076293945% Train Loss 0.528085470199585 Val Loss 1.228485345840454
Trainable Parameters : 264452
Epoch 24 Train Acc 56.04562759399414% Val Acc 41.29999923706055% Train Loss 0.5264233350753784 Val Loss 1.3744558095932007
Trainable Parameters : 264452
Epoch 25 Train Acc 56.520912170410156% Val Acc 48.29999923706055% Train Loss 0.5269544720649719 Val Loss 1.1969473361968994
Trainable Parameters : 264452
Epoch 26 Train Acc 56.08745193481445% Val Acc 37.70000076293945% Train Loss 0.5266445875167847 Val Loss 1.4532374143600464
Trainable Parameters : 264452
Epoch 27 Train Acc 56.71482849121094% Val Acc 45.70000076293945% Train Loss 0.5261812806129456 Val Loss 1.3333224058151245
Trainable Parameters : 264452
Epoch 28 Train Acc 56.47148132324219% Val Acc 47.10000228881836% Train Loss 0.5260079503059387 Val Loss 1.2584031820297241
Trainable Parameters : 264452
Epoch 29 Train Acc 56.730037689208984% Val Acc 38.400001525878906% Train Loss 0.5171913504600525 Val Loss 1.6269077062606812
Trainable Parameters : 264452
Epoch 30 Train Acc 56.4638786315918% Val Acc 46.29999923706055% Train Loss 0.5206413865089417 Val Loss 1.3238645792007446
Trainable Parameters : 264452
Epoch 31 Train Acc 56.55133056640625% Val Acc 45.20000076293945% Train Loss 0.5227913856506348 Val Loss 1.2214179039001465
Trainable Parameters : 264452
Epoch 32 Train Acc 56.90874481201172% Val Acc 45.400001525878906% Train Loss 0.5190202593803406 Val Loss 1.2563966512680054
Trainable Parameters : 264452
Epoch 33 Train Acc 56.83650207519531% Val Acc 45.60000228881836% Train Loss 0.5225616097450256 Val Loss 1.3127784729003906
Trainable Parameters : 264452
Epoch 34 Train Acc 56.84790802001953% Val Acc 41.0% Train Loss 0.5172408819198608 Val Loss 1.361478567123413
Trainable Parameters : 264452
Epoch 35 Train Acc 56.581748962402344% Val Acc 44.10000228881836% Train Loss 0.5199093222618103 Val Loss 1.3472951650619507
Trainable Parameters : 264452
Epoch 36 Train Acc 57.24714660644531% Val Acc 49.29999923706055% Train Loss 0.5215276479721069 Val Loss 1.2417572736740112
Trainable Parameters : 264452
Epoch 37 Train Acc 56.615970611572266% Val Acc 48.79999923706055% Train Loss 0.5209922790527344 Val Loss 1.1640620231628418
Trainable Parameters : 264452
Epoch 38 Train Acc 56.825096130371094% Val Acc 42.70000076293945% Train Loss 0.5203666687011719 Val Loss 1.4404321908950806
Trainable Parameters : 264452
Epoch 39 Train Acc 56.96577835083008% Val Acc 33.400001525878906% Train Loss 0.5165798664093018 Val Loss 1.58161199092865
Trainable Parameters : 264452
Epoch 40 Train Acc 57.44486618041992% Val Acc 48.79999923706055% Train Loss 0.5153853893280029 Val Loss 1.1813215017318726
Trainable Parameters : 264452
Epoch 41 Train Acc 57.889732360839844% Val Acc 44.20000076293945% Train Loss 0.5114656090736389 Val Loss 1.2724874019622803
Trainable Parameters : 264452
Epoch 42 Train Acc 57.34600830078125% Val Acc 53.5% Train Loss 0.5157981514930725 Val Loss 1.1163759231567383
Trainable Parameters : 264452
Epoch 43 Train Acc 57.7414436340332% Val Acc 47.10000228881836% Train Loss 0.5146803855895996 Val Loss 1.2264164686203003
Trainable Parameters : 264452
Epoch 44 Train Acc 57.980987548828125% Val Acc 39.60000228881836% Train Loss 0.5069395303726196 Val Loss 1.4863083362579346
Trainable Parameters : 264452
Mon Oct 31 14:34:07 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 31/10/2022 14:34:24

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-first40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-first40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-3.0486e-02, -3.4805e-02, -2.8836e-02,  ...,  1.5430e-01,
          2.1431e-01,  1.1562e-01],
        [ 4.8310e-01,  9.3061e-01,  1.3262e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.4320e-02, -6.7237e-02,  1.9146e-02,  ..., -1.8169e-03,
         -6.6403e-04,  7.7211e-04],
        ...,
        [-1.0796e+00, -1.4652e+00, -1.3413e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.6497e-03,  6.8290e-03,  1.3244e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.2822e-02,  1.2372e-02,  1.4243e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 0, 3, 2, 3, 1, 2, 1, 1, 3, 2, 3, 0, 1, 0, 2, 2, 2, 3, 2, 2, 3, 0, 1,
        0, 0, 2, 3, 0, 0, 0, 3, 3, 2, 2, 2, 0, 2, 3, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[ 9.6349e-02,  8.1908e-02,  1.0313e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.3921e-03,  1.6300e-03, -8.0340e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.9813e-03,  4.2420e-04,  2.3287e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-1.1178e-05,  2.6007e-04, -1.3434e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.8906e-01, -4.3933e-01, -4.0837e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.5892e-02,  4.5299e-02, -6.0739e-02,  ...,  3.6263e-05,
          3.6224e-05,  3.6322e-05]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 2, 1, 0, 0, 1, 1, 2, 1, 2, 3, 1, 2, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3,
        2, 1, 3, 0, 1, 0, 3, 2, 0, 3, 1, 3, 1, 0, 1, 1])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'classifier.bias', 'classifier.weight', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.0197,  0.0136,  0.0192,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0659, -0.1018, -0.2386,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0459,  0.0344,  0.0489,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1145, -0.2977,  0.1189,  ..., -0.0007, -0.0007, -0.0007],
        [ 0.0912, -0.0154, -0.1715,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0354, -0.0253, -0.0103,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 3, 1, 1, 0, 1, 0, 1, 1, 3, 0, 0, 3, 2, 2, 3, 3, 2, 1, 3, 1, 1, 0, 0,
        3, 0, 2, 2, 1, 0, 1, 0, 0, 0, 1, 2, 1, 3, 2, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 27.18250846862793% Val Acc 25.5% Train Loss 0.6865466833114624 Val Loss 1.415666103363037
Trainable Parameters : 264452
Epoch 1 Train Acc 40.0% Val Acc 26.200000762939453% Train Loss 0.6541747450828552 Val Loss 1.4572182893753052
Trainable Parameters : 264452
Epoch 2 Train Acc 39.992393493652344% Val Acc 24.700000762939453% Train Loss 0.6480065584182739 Val Loss 1.4521287679672241
Trainable Parameters : 264452
Epoch 3 Train Acc 40.06843948364258% Val Acc 24.100000381469727% Train Loss 0.6414721012115479 Val Loss 1.4473950862884521
Trainable Parameters : 264452
Epoch 4 Train Acc 40.870723724365234% Val Acc 27.700000762939453% Train Loss 0.6341966390609741 Val Loss 1.4452513456344604
Trainable Parameters : 264452
Epoch 5 Train Acc 42.36882019042969% Val Acc 32.0% Train Loss 0.6255806684494019 Val Loss 1.4246779680252075
Trainable Parameters : 264452
Epoch 6 Train Acc 44.74905014038086% Val Acc 30.80000114440918% Train Loss 0.6164894700050354 Val Loss 1.3755323886871338
Trainable Parameters : 264452
Epoch 7 Train Acc 46.783267974853516% Val Acc 31.700000762939453% Train Loss 0.6063908934593201 Val Loss 1.3966082334518433
Trainable Parameters : 264452
Epoch 8 Train Acc 47.718631744384766% Val Acc 36.70000076293945% Train Loss 0.5973007082939148 Val Loss 1.348643183708191
Trainable Parameters : 264452
Epoch 9 Train Acc 49.212928771972656% Val Acc 36.400001525878906% Train Loss 0.5891366600990295 Val Loss 1.345706582069397
Trainable Parameters : 264452
Epoch 10 Train Acc 49.737640380859375% Val Acc 34.29999923706055% Train Loss 0.5828593373298645 Val Loss 1.3895952701568604
Trainable Parameters : 264452
Epoch 11 Train Acc 50.878326416015625% Val Acc 32.20000076293945% Train Loss 0.5757034420967102 Val Loss 1.4312880039215088
Trainable Parameters : 264452
Epoch 12 Train Acc 51.026615142822266% Val Acc 34.0% Train Loss 0.5695075988769531 Val Loss 1.3905432224273682
Trainable Parameters : 264452
Epoch 13 Train Acc 51.80608367919922% Val Acc 41.0% Train Loss 0.5643690228462219 Val Loss 1.2639930248260498
Trainable Parameters : 264452
Epoch 14 Train Acc 52.55133056640625% Val Acc 41.400001525878906% Train Loss 0.5573135614395142 Val Loss 1.2871445417404175
Trainable Parameters : 264452
Epoch 15 Train Acc 53.36501693725586% Val Acc 37.79999923706055% Train Loss 0.5522222518920898 Val Loss 1.364437460899353
Trainable Parameters : 264452
Epoch 16 Train Acc 53.80988693237305% Val Acc 38.0% Train Loss 0.5484796166419983 Val Loss 1.353206753730774
Trainable Parameters : 264452
Epoch 17 Train Acc 54.224334716796875% Val Acc 33.79999923706055% Train Loss 0.5479398369789124 Val Loss 1.5437421798706055
Trainable Parameters : 264452
Epoch 18 Train Acc 54.524715423583984% Val Acc 41.0% Train Loss 0.5418385863304138 Val Loss 1.301077127456665
Trainable Parameters : 264452
Epoch 19 Train Acc 55.08745193481445% Val Acc 40.0% Train Loss 0.5370084643363953 Val Loss 1.2973178625106812
Trainable Parameters : 264452
Epoch 20 Train Acc 55.038021087646484% Val Acc 46.79999923706055% Train Loss 0.5369406938552856 Val Loss 1.265420913696289
Trainable Parameters : 264452
Epoch 21 Train Acc 55.43726348876953% Val Acc 45.20000076293945% Train Loss 0.5350452661514282 Val Loss 1.2585190534591675
Trainable Parameters : 264452
Epoch 22 Train Acc 55.91634750366211% Val Acc 48.5% Train Loss 0.5340482592582703 Val Loss 1.214629888534546
Trainable Parameters : 264452
Epoch 23 Train Acc 55.53992462158203% Val Acc 44.70000076293945% Train Loss 0.5299127697944641 Val Loss 1.2232248783111572
Trainable Parameters : 264452
Epoch 24 Train Acc 55.30038070678711% Val Acc 39.79999923706055% Train Loss 0.5291373133659363 Val Loss 1.4064258337020874
Trainable Parameters : 264452
Epoch 25 Train Acc 55.44486618041992% Val Acc 46.29999923706055% Train Loss 0.5278798341751099 Val Loss 1.1991385221481323
Trainable Parameters : 264452
Epoch 26 Train Acc 56.11787033081055% Val Acc 39.79999923706055% Train Loss 0.5266238451004028 Val Loss 1.3638982772827148
Trainable Parameters : 264452
Epoch 27 Train Acc 56.85171127319336% Val Acc 44.60000228881836% Train Loss 0.5237299203872681 Val Loss 1.2959340810775757
Trainable Parameters : 264452
Epoch 28 Train Acc 56.7414436340332% Val Acc 42.900001525878906% Train Loss 0.5225479006767273 Val Loss 1.3717337846755981
Trainable Parameters : 264452
Epoch 29 Train Acc 56.26235580444336% Val Acc 38.5% Train Loss 0.5227823257446289 Val Loss 1.5404176712036133
Trainable Parameters : 264452
Epoch 30 Train Acc 56.31178665161133% Val Acc 44.79999923706055% Train Loss 0.5245084166526794 Val Loss 1.2742358446121216
Trainable Parameters : 264452
Epoch 31 Train Acc 56.60456085205078% Val Acc 44.79999923706055% Train Loss 0.5210661292076111 Val Loss 1.2316862344741821
Trainable Parameters : 264452
Epoch 32 Train Acc 56.889732360839844% Val Acc 43.10000228881836% Train Loss 0.5206652879714966 Val Loss 1.3125197887420654
Trainable Parameters : 264452
Epoch 33 Train Acc 57.04943084716797% Val Acc 39.900001525878906% Train Loss 0.5204147696495056 Val Loss 1.504132628440857
Trainable Parameters : 264452
Epoch 34 Train Acc 56.8441047668457% Val Acc 45.70000076293945% Train Loss 0.5186216831207275 Val Loss 1.274454951286316
Trainable Parameters : 264452
Epoch 35 Train Acc 56.93916320800781% Val Acc 45.0% Train Loss 0.5196242332458496 Val Loss 1.318149447441101
Trainable Parameters : 264452
Epoch 36 Train Acc 56.673004150390625% Val Acc 47.900001525878906% Train Loss 0.5211673974990845 Val Loss 1.3279699087142944
Trainable Parameters : 264452
Epoch 37 Train Acc 56.25094985961914% Val Acc 51.70000076293945% Train Loss 0.5205131769180298 Val Loss 1.1694750785827637
Trainable Parameters : 264452
Epoch 38 Train Acc 56.88212966918945% Val Acc 43.20000076293945% Train Loss 0.5218551754951477 Val Loss 1.4143356084823608
Trainable Parameters : 264452
Configuration saved in ../output/u_train_700f_local/ADI17-xlsr-nr-first40/config.json
Model weights saved in ../output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin
Epoch 39 Train Acc 56.61216735839844% Val Acc 34.79999923706055% Train Loss 0.5153988003730774 Val Loss 1.5413763523101807

------> EVALUATING MODEL... ------------------------------------------ 

Final Test Acc:35.900001525878906% Loss:1.3932040929794312
CONFUSION MATRIX
[[ 7  5 10 78]
 [ 1 13  9 77]
 [ 0  3 30 65]
 [ 0  4  3 93]]
CONFUSION MATRIX NORMALISED
[[0.01758794 0.01256281 0.02512563 0.1959799 ]
 [0.00251256 0.03266332 0.02261307 0.19346734]
 [0.         0.00753769 0.07537688 0.16331658]
 [0.         0.01005025 0.00753769 0.23366834]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.88      0.07      0.13       100
           1       0.52      0.13      0.21       100
           2       0.58      0.31      0.40        98
           3       0.30      0.93      0.45       100

    accuracy                           0.36       398
   macro avg       0.57      0.36      0.30       398
weighted avg       0.57      0.36      0.30       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 01/11/2022 02:25:57
