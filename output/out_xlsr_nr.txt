Wed Oct 26 16:25:13 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 26/10/2022 16:25:25

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 396, in <module>
    TrainData = next(iter(trainDataLoader))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 530, in __next__
    data = self._next_data()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1224, in _next_data
    return self._process_data(data)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1250, in _process_data
    data.reraise()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/z5208494/thesis/customDataNR.py", line 56, in __getitem__
    speech = speech_file_to_array_fn(audiopath, self.sampling_rate, self.norm)
AttributeError: 'CustomDataset' object has no attribute 'norm'

<<<<<<< HEAD
Wed Oct 26 21:42:20 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 26/10/2022 21:42:33

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.4893e+00,  8.2514e-01,  8.7882e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.4439e+00, -1.2509e+00, -1.1298e+00,  ...,  3.4840e+00,
          3.4407e+00,  1.6194e+00],
        [-9.1274e+00, -8.7851e+00, -7.7613e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 3.3655e-01,  8.3061e-01,  2.2332e-01,  ...,  3.0693e-03,
         -1.1751e-02, -4.0876e-03],
        [ 9.0473e-04,  1.0346e-02,  1.7978e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.2065e+00, -3.5894e+00, -4.2492e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 3, 1, 2, 3, 2, 1, 0, 2, 2, 1, 2, 2, 0, 1, 1, 3, 0, 2, 0, 0, 2, 3,
        3, 1, 2, 1, 0, 3, 3, 0, 2, 3, 3, 0, 2, 0, 2, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-4.2988e-02, -4.6289e-02, -5.1633e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.0455e-03,  6.5684e-03,  6.2668e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.7407e-03,  5.7493e-03,  7.5497e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-6.1391e-04, -2.6391e-04, -2.3715e-03,  ...,  3.0025e-01,
          5.4263e-01,  8.1184e-01],
        [-2.6356e-03,  2.2939e-03, -1.8262e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-5.9910e-02, -5.7939e-02, -6.8568e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 0, 0, 3, 0, 3, 2, 0, 3, 0, 3, 0, 2, 2, 1, 2, 2, 0, 0, 3, 3, 2, 3, 2,
        1, 3, 0, 0, 0, 3, 1, 1, 2, 2, 1, 3, 3, 2, 3, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'projector.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.0058,  0.0095,  0.0123,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0200,  0.0191,  0.0218,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2705,  0.1753,  0.3237,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-1.5697, -1.3994, -1.5031,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0109, -0.0115,  0.0063,  ...,  0.0077,  0.0188,  0.0318],
        [ 0.8606,  0.9374,  1.0788,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 2, 2, 2, 2, 0, 3, 1, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1,
        3, 2, 2, 3, 2, 2, 1, 3, 3, 1, 0, 3, 0, 3, 2, 1])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 28.95437240600586% Val Acc 25.5% Train Loss 0.6869237422943115 Val Loss 1.4051316976547241
Trainable Parameters : 264452
Epoch 1 Train Acc 40.0% Val Acc 26.200000762939453% Train Loss 0.6543092727661133 Val Loss 1.4593757390975952
Trainable Parameters : 264452
Epoch 2 Train Acc 39.992393493652344% Val Acc 24.700000762939453% Train Loss 0.6482349634170532 Val Loss 1.458328127861023
Trainable Parameters : 264452
Epoch 3 Train Acc 40.19771957397461% Val Acc 24.100000381469727% Train Loss 0.6419419050216675 Val Loss 1.460398554801941
Trainable Parameters : 264452
Epoch 4 Train Acc 41.06083679199219% Val Acc 28.700000762939453% Train Loss 0.63434237241745 Val Loss 1.4519108533859253
Trainable Parameters : 264452
Epoch 5 Train Acc 42.821292877197266% Val Acc 31.399999618530273% Train Loss 0.6264311671257019 Val Loss 1.4336482286453247
Trainable Parameters : 264452
Epoch 6 Train Acc 44.39163589477539% Val Acc 31.700000762939453% Train Loss 0.6180532574653625 Val Loss 1.3913449048995972
Trainable Parameters : 264452
Epoch 7 Train Acc 46.14828872680664% Val Acc 32.29999923706055% Train Loss 0.6089162230491638 Val Loss 1.401823878288269
Trainable Parameters : 264452
Epoch 8 Train Acc 47.8745231628418% Val Acc 35.20000076293945% Train Loss 0.600373387336731 Val Loss 1.367717981338501
Trainable Parameters : 264452
Epoch 9 Train Acc 49.00380325317383% Val Acc 35.0% Train Loss 0.5912097096443176 Val Loss 1.3531748056411743
Trainable Parameters : 264452
Epoch 10 Train Acc 49.73384094238281% Val Acc 33.400001525878906% Train Loss 0.5822057127952576 Val Loss 1.4052952527999878
Trainable Parameters : 264452
Epoch 11 Train Acc 50.42585372924805% Val Acc 32.20000076293945% Train Loss 0.5768563747406006 Val Loss 1.4203563928604126
Trainable Parameters : 264452
Epoch 12 Train Acc 51.00760269165039% Val Acc 33.60000228881836% Train Loss 0.5710106492042542 Val Loss 1.3809244632720947
Trainable Parameters : 264452
Epoch 13 Train Acc 52.277565002441406% Val Acc 41.20000076293945% Train Loss 0.5634687542915344 Val Loss 1.2697018384933472
Trainable Parameters : 264452
Epoch 14 Train Acc 53.05703353881836% Val Acc 42.79999923706055% Train Loss 0.5565688014030457 Val Loss 1.2847483158111572
Trainable Parameters : 264452
Epoch 15 Train Acc 53.718631744384766% Val Acc 38.0% Train Loss 0.5502561926841736 Val Loss 1.3462340831756592
Trainable Parameters : 264452
Epoch 16 Train Acc 53.787071228027344% Val Acc 39.400001525878906% Train Loss 0.5493955612182617 Val Loss 1.3544412851333618
Trainable Parameters : 264452
Epoch 17 Train Acc 54.992393493652344% Val Acc 34.0% Train Loss 0.5455493927001953 Val Loss 1.5104097127914429
Trainable Parameters : 264452
Epoch 18 Train Acc 54.479087829589844% Val Acc 41.20000076293945% Train Loss 0.5419526696205139 Val Loss 1.284603476524353
Trainable Parameters : 264452
Epoch 19 Train Acc 54.973384857177734% Val Acc 40.20000076293945% Train Loss 0.5379464030265808 Val Loss 1.34392249584198
Trainable Parameters : 264452
Epoch 20 Train Acc 55.09885787963867% Val Acc 46.29999923706055% Train Loss 0.534542977809906 Val Loss 1.261456847190857
Trainable Parameters : 264452
Epoch 21 Train Acc 55.67680740356445% Val Acc 44.79999923706055% Train Loss 0.5314928293228149 Val Loss 1.321675181388855
Trainable Parameters : 264452
Epoch 22 Train Acc 55.794677734375% Val Acc 44.60000228881836% Train Loss 0.5298988819122314 Val Loss 1.2330163717269897
Trainable Parameters : 264452
Epoch 23 Train Acc 55.418251037597656% Val Acc 45.79999923706055% Train Loss 0.5285009741783142 Val Loss 1.2071037292480469
Trainable Parameters : 264452
Epoch 24 Train Acc 56.1026611328125% Val Acc 40.900001525878906% Train Loss 0.5266396403312683 Val Loss 1.372064471244812
Trainable Parameters : 264452
Epoch 25 Train Acc 55.98859405517578% Val Acc 46.0% Train Loss 0.5257089138031006 Val Loss 1.2040332555770874
Trainable Parameters : 264452
Epoch 26 Train Acc 56.26235580444336% Val Acc 36.20000076293945% Train Loss 0.5255396366119385 Val Loss 1.5410202741622925
Trainable Parameters : 264452
Epoch 27 Train Acc 56.167301177978516% Val Acc 43.79999923706055% Train Loss 0.5248177647590637 Val Loss 1.3050109148025513
Trainable Parameters : 264452
Epoch 28 Train Acc 56.589351654052734% Val Acc 47.900001525878906% Train Loss 0.5197764039039612 Val Loss 1.2551538944244385
Trainable Parameters : 264452
Epoch 29 Train Acc 56.77946853637695% Val Acc 38.79999923706055% Train Loss 0.5248975157737732 Val Loss 1.514435887336731
Trainable Parameters : 264452
Epoch 30 Train Acc 56.821292877197266% Val Acc 45.29999923706055% Train Loss 0.519494891166687 Val Loss 1.300317645072937
Trainable Parameters : 264452
Epoch 31 Train Acc 56.277565002441406% Val Acc 46.400001525878906% Train Loss 0.5234115123748779 Val Loss 1.2115733623504639
Trainable Parameters : 264452
Epoch 32 Train Acc 57.186309814453125% Val Acc 45.0% Train Loss 0.5196327567100525 Val Loss 1.327957034111023
Trainable Parameters : 264452
Epoch 33 Train Acc 56.49049377441406% Val Acc 43.0% Train Loss 0.5217486619949341 Val Loss 1.4010289907455444
Trainable Parameters : 264452
Epoch 34 Train Acc 57.5361213684082% Val Acc 40.5% Train Loss 0.5142330527305603 Val Loss 1.4138078689575195
Trainable Parameters : 264452
Epoch 35 Train Acc 57.15589141845703% Val Acc 43.20000076293945% Train Loss 0.5169218182563782 Val Loss 1.3524776697158813
Trainable Parameters : 264452
Epoch 36 Train Acc 56.40304183959961% Val Acc 48.0% Train Loss 0.5193210244178772 Val Loss 1.3397079706192017
Trainable Parameters : 264452
Epoch 37 Train Acc 56.86311721801758% Val Acc 48.400001525878906% Train Loss 0.5180723071098328 Val Loss 1.248003363609314
Trainable Parameters : 264452
Epoch 38 Train Acc 56.22053146362305% Val Acc 43.70000076293945% Train Loss 0.5193512439727783 Val Loss 1.4184396266937256
Trainable Parameters : 264452
Epoch 39 Train Acc 57.28517150878906% Val Acc 35.0% Train Loss 0.5144625306129456 Val Loss 1.5012482404708862
Trainable Parameters : 264452
Epoch 40 Train Acc 57.338401794433594% Val Acc 53.29999923706055% Train Loss 0.51358562707901 Val Loss 1.17648184299469
Trainable Parameters : 264452
Epoch 41 Train Acc 57.623573303222656% Val Acc 42.5% Train Loss 0.514604926109314 Val Loss 1.306745171546936
Trainable Parameters : 264452
Epoch 42 Train Acc 57.5361213684082% Val Acc 55.20000076293945% Train Loss 0.5116227269172668 Val Loss 1.1058552265167236
Trainable Parameters : 264452
Epoch 43 Train Acc 57.726234436035156% Val Acc 45.60000228881836% Train Loss 0.509967565536499 Val Loss 1.208135962486267
Trainable Parameters : 264452
Epoch 44 Train Acc 58.34600830078125% Val Acc 38.900001525878906% Train Loss 0.505830705165863 Val Loss 1.5077869892120361
Trainable Parameters : 264452
Epoch 45 Train Acc 58.00760269165039% Val Acc 49.5% Train Loss 0.5075322389602661 Val Loss 1.2818191051483154
Trainable Parameters : 264452
Epoch 46 Train Acc 58.17110061645508% Val Acc 43.900001525878906% Train Loss 0.5080139636993408 Val Loss 1.3754457235336304
Trainable Parameters : 264452
Epoch 47 Train Acc 58.48289108276367% Val Acc 54.400001525878906% Train Loss 0.5076122283935547 Val Loss 1.1156333684921265
Trainable Parameters : 264452
Epoch 48 Train Acc 58.543724060058594% Val Acc 44.70000076293945% Train Loss 0.5054258108139038 Val Loss 1.4059858322143555
Trainable Parameters : 264452
Epoch 49 Train Acc 58.372623443603516% Val Acc 45.60000228881836% Train Loss 0.5028601288795471 Val Loss 1.33469820022583
Trainable Parameters : 264452
=======
>>>>>>> ffaef3afa3ac930227cea1150efd6f9c798506a4
Fri Oct 28 11:39:01 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 28/10/2022 11:39:21

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 4.3399e-03,  4.7973e-03,  4.2158e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-7.1626e-02, -2.0482e-01, -3.6125e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-5.0736e-03, -2.2955e-03,  1.3634e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 9.7492e-04, -9.1258e-04,  1.0932e-02,  ..., -1.7715e-05,
         -3.8235e-05, -5.3355e-05],
        [ 4.8629e-02,  5.6643e-02,  6.1225e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.0555e-04,  1.2216e-03,  9.7090e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 3, 2, 0, 0, 1, 1, 0, 3, 2, 3, 0, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3,
        3, 2, 2, 3, 3, 2, 3, 3, 0, 3, 2, 2, 2, 0, 1, 1])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[ 1.0100e+00,  6.1360e-01,  4.5021e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.3435e-01, -4.9701e-01, -6.4231e-01,  ...,  2.6070e+00,
          2.4279e+00,  2.0053e+00],
        [-8.3018e-04, -1.0908e-03, -1.0095e-03,  ...,  5.0225e-04,
         -4.2785e-04, -4.7363e-04],
        ...,
        [-2.2306e-02, -3.2110e-02,  1.1299e-02,  ...,  1.3225e-03,
         -1.2796e-04,  1.2958e-03],
        [-1.2424e-03,  2.4067e-03, -3.8756e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.6645e-02, -4.5477e-02, -4.6489e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 1, 2, 1, 0, 3, 3, 2, 2, 3, 2, 0, 3, 3, 3, 1, 1, 3, 1, 3, 0, 2, 3,
        3, 3, 3, 0, 2, 3, 3, 0, 3, 3, 2, 1, 3, 2, 2, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'classifier.bias', 'projector.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 5.8808e-04, -1.3110e-04, -9.8904e-04,  ..., -8.2171e-01,
         -1.0501e+00, -1.2008e+00],
        [ 3.4467e-01,  4.6078e-01,  5.0067e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.5435e-02, -2.5318e-02, -1.0326e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 7.7631e-01,  1.3190e+00,  1.7171e+00,  ..., -1.8754e+00,
         -1.1922e+00, -6.0643e-01],
        [-3.1449e-02, -3.0929e-02,  3.5760e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.8344e-01, -3.7619e-01, -4.0563e-01,  ..., -1.0731e+00,
         -9.8752e-01, -2.6961e-01]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 1, 2, 0, 0, 2, 1, 1, 2, 1, 2, 3, 1, 0, 1, 3, 2, 2, 1, 3, 3, 2, 3, 3,
        3, 1, 2, 1, 1, 0, 2, 3, 1, 0, 0, 0, 3, 2, 1, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 720, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_nr.py", line 545, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_nr.py", line 565, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_nr.py", line 608, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 710, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 589, in forward
    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask
RuntimeError: CUDA out of memory. Tried to allocate 608.00 MiB (GPU 0; 31.75 GiB total capacity; 29.97 GiB already allocated; 6.00 MiB free; 30.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Fri Oct 28 11:44:30 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 28/10/2022 11:44:47

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 24
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0033, -0.0029, -0.0036,  ...,  0.1756,  0.1703,  0.1632],
        [ 0.2170,  0.0292,  0.0785,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1366,  0.4661,  0.6429,  ..., -0.1500, -0.2119, -0.2495],
        ...,
        [ 0.0081,  0.0186,  0.0422,  ...,  0.0535,  0.0643,  0.0716],
        [ 0.2599,  0.2803,  0.4121,  ..., -0.0054, -0.0032, -0.0011],
        [-0.0008, -0.0008, -0.0009,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 2, 3, 2, 3, 0, 0, 3, 2, 0, 0, 2, 3, 0, 3, 2, 1, 0, 0, 0, 2, 0, 2])}
Training DataCustom Files: 10502
Training Data Files: 438
Val Data Sample
{'input_values': tensor([[ 6.3268e-01,  5.1878e-01,  5.5399e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.1829e-01, -9.9147e-01, -1.2617e+00,  ...,  3.3838e-01,
          3.9886e-01,  4.5334e-01],
        [-2.8483e-01,  3.2058e-01,  2.6943e-01,  ..., -5.8935e-01,
         -4.7329e-01, -5.4390e-01],
        ...,
        [-4.4544e-01, -5.1297e-01, -4.8098e-01,  ..., -2.0383e-01,
         -1.2103e-01, -4.7997e-02],
        [ 1.2531e-02,  8.0402e-03,  1.0695e-02,  ...,  5.3830e-05,
          5.3831e-05,  5.3838e-05],
        [ 1.1190e+00,  4.8430e-01,  5.6913e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 2, 0, 1, 2, 3, 3, 0, 2, 1, 0, 2, 3, 1, 0, 3, 1, 2, 3, 3, 2, 1, 1])}
Test CustomData Files: 813
Test Data Files: 34
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'classifier.weight', 'classifier.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 4.9192e-03,  5.3284e-03,  2.1234e-03,  ..., -3.2242e-01,
         -2.8214e-01, -2.5992e-02],
        [-6.7133e-03, -4.2381e-04,  4.5386e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.4091e+00,  2.5462e+00,  2.5700e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 1.2128e+00,  8.0495e-01,  7.4335e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.1437e+00, -9.1001e-01, -4.9409e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.5821e-03, -3.4961e-04, -1.1967e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 1, 1, 2, 3, 1, 3, 2, 3, 3, 0, 2, 2, 2, 0, 3, 3, 1, 3, 2, 1, 3, 2])}
Test CustomData Files: 398
Test Data Files: 17
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 720, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_nr.py", line 545, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_nr.py", line 565, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_nr.py", line 608, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 710, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 576, in forward
    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))
RuntimeError: CUDA out of memory. Tried to allocate 366.00 MiB (GPU 0; 31.75 GiB total capacity; 29.66 GiB already allocated; 358.00 MiB free; 29.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Fri Oct 28 13:53:39 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 28/10/2022 13:53:54

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[2.3066e-01, 8.4955e-02, 2.3972e-01,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [1.2030e+00, 1.1004e+00, 1.3435e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [3.6760e+00, 3.6687e+00, 3.2004e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        ...,
        [2.3242e+00, 1.8206e+00, 1.9986e+00,  ..., 6.9472e-01, 7.4653e-01,
         7.8930e-01],
        [8.0555e-04, 1.2216e-03, 9.7090e-04,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [7.0030e-02, 5.4149e-02, 5.8230e-02,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 0, 2, 2, 2, 3, 2, 1, 2, 1, 2, 1, 2, 2, 3, 2, 0, 2, 3, 0, 3, 3, 0,
        0, 2, 0, 0, 2, 3, 2, 1, 0, 1, 2, 1, 2, 2, 1, 0])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-2.8711e-01, -2.8038e-02, -9.2422e-02,  ...,  8.7110e-01,
          2.6163e+00,  1.7656e+00],
        [-2.7270e+00, -2.0877e+00, -1.4125e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.5631e-01,  1.0004e+00,  1.5179e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-2.2700e-01, -3.3146e-01, -5.4180e-01,  ...,  5.8577e-04,
          5.3615e-04,  4.8178e-04],
        [ 6.6477e-03,  6.0643e-03,  7.3224e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.7578e-01, -4.3064e-01, -5.7764e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 0, 1, 1, 0, 3, 2, 0, 1, 3, 3, 2, 0, 3, 2, 1, 3, 1, 1, 2, 1, 1, 2,
        3, 1, 2, 3, 2, 2, 1, 0, 2, 2, 3, 2, 0, 3, 1, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.weight', 'classifier.bias', 'classifier.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 2.7913e-04, -2.6333e-04,  1.6222e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 9.1214e-02, -1.5391e-02, -1.7151e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-9.6867e-03, -1.3391e-02, -1.4628e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 9.7614e-03,  6.9365e-02, -1.4372e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.7171e-02, -2.7255e-02, -3.1989e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.6712e-03,  1.8459e-03,  1.5797e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 0, 2, 0, 0, 1, 1, 3, 0, 3, 0, 2, 0, 1, 1, 0, 3, 3, 1, 1, 2, 0, 3,
        2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 3, 2, 0, 3, 1, 3])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  2 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 720, in <module>
    trainer.fit(trainDataLoader, testDataLoader, set_num_train_epochs)
  File "run_xlsr_nr.py", line 545, in fit
    train_loss, train_acc = self._train(train_loader, tr_itt, loss_sum_tr, acc_sum_tr)
  File "run_xlsr_nr.py", line 565, in _train
    loss, acc = self._compute_loss(model, inputs, labels)
  File "run_xlsr_nr.py", line 608, in _compute_loss
    prediction = model(**inputs).logits
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1793, in forward
    outputs = self.wav2vec2(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1304, in forward
    encoder_outputs = self.encoder(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 876, in forward
    layer_outputs = layer(
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 715, in forward
    hidden_states = hidden_states + self.feed_forward(self.final_layer_norm(hidden_states))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 651, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/activations.py", line 56, in forward
    return self.act(input)
RuntimeError: CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 31.75 GiB total capacity; 30.08 GiB already allocated; 156.00 MiB free; 30.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Sat Oct 29 10:54:57 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 29/10/2022 10:55:12

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 100
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-1.4715e+00, -1.5040e+00, -1.7570e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.5196e+00,  3.6348e+00,  1.8356e+01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-4.7127e-01, -2.3734e-01, -4.1282e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-6.2182e-03,  5.2288e-02, -3.8957e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0191e+00, -6.7056e-01, -2.0900e-01,  ...,  2.7865e+00,
          2.4890e+00,  2.0625e+00],
        [-5.1719e-02, -4.4632e-02, -6.2005e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 0, 1, 0, 0, 1, 2, 3, 1, 0, 3, 2, 3, 2, 3, 2, 0, 3, 3, 0, 3, 1, 2,
        3, 2, 1, 3, 2, 2, 1, 1, 1, 0, 2, 2, 2, 0, 1, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-1.8421, -2.3763, -2.5667,  ..., -1.4054, -1.1256, -0.8383],
        [ 0.3737,  0.4176,  0.4354,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4565,  0.5682,  0.7253,  ...,  0.1444,  0.1369,  0.1302],
        ...,
        [-0.0143, -0.0204, -0.0197,  ...,  0.0000,  0.0000,  0.0000],
        [-2.7420, -2.6076, -3.1934,  ...,  1.1529,  1.3819,  1.4497],
        [ 0.0188,  0.0200,  0.0212,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 1, 2, 1, 0, 0, 0, 2, 2, 1, 2, 1, 1, 0, 1, 3, 0, 3, 3, 0, 3, 0, 0,
        1, 1, 0, 0, 2, 3, 1, 3, 2, 1, 1, 2, 2, 1, 3, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.weight', 'classifier.bias', 'projector.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 1.7728e+00,  1.6911e+00,  1.6479e+00,  ...,  8.7288e-01,
          6.8575e-01,  4.6735e-01],
        [ 5.3496e-01, -2.6568e-01, -4.1135e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.0738e-01,  2.4392e-01,  2.8339e-01,  ..., -1.9145e-04,
         -1.6422e-04, -1.3268e-05],
        ...,
        [ 2.7172e+00,  1.2029e+00,  1.4148e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.8618e-03, -7.3046e-04, -7.0749e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.9239e-01,  1.8293e+00,  1.7535e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 2, 1, 3, 3, 3, 0, 0, 1, 1, 1, 1, 0, 3, 0, 0, 3, 0, 0, 1, 0, 0, 1, 1,
        3, 0, 1, 1, 3, 0, 3, 2, 1, 0, 3, 2, 3, 2, 0, 3])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 35.74524688720703% Val Acc 25.5% Train Loss 0.6786112785339355 Val Loss 1.4150742292404175
Trainable Parameters : 264452
Epoch 1 Train Acc 40.0% Val Acc 26.200000762939453% Train Loss 0.6527032852172852 Val Loss 1.4586683511734009
Trainable Parameters : 264452
Epoch 2 Train Acc 39.992393493652344% Val Acc 24.399999618530273% Train Loss 0.6463303565979004 Val Loss 1.4574170112609863
Trainable Parameters : 264452
Epoch 3 Train Acc 40.25475311279297% Val Acc 24.600000381469727% Train Loss 0.6406141519546509 Val Loss 1.4564555883407593
Trainable Parameters : 264452
Epoch 4 Train Acc 41.418251037597656% Val Acc 29.700000762939453% Train Loss 0.633048951625824 Val Loss 1.449140191078186
Trainable Parameters : 264452
Epoch 5 Train Acc 42.79847717285156% Val Acc 32.29999923706055% Train Loss 0.6244764924049377 Val Loss 1.4248721599578857
Trainable Parameters : 264452
Epoch 6 Train Acc 44.95817565917969% Val Acc 30.80000114440918% Train Loss 0.6154907941818237 Val Loss 1.3839269876480103
Trainable Parameters : 264452
Epoch 7 Train Acc 46.51710891723633% Val Acc 32.0% Train Loss 0.6064847111701965 Val Loss 1.4021681547164917
Trainable Parameters : 264452
Epoch 8 Train Acc 48.05323028564453% Val Acc 35.900001525878906% Train Loss 0.5972500443458557 Val Loss 1.3566166162490845
Trainable Parameters : 264452
Epoch 9 Train Acc 49.224334716796875% Val Acc 35.5% Train Loss 0.5886512398719788 Val Loss 1.3499542474746704
Trainable Parameters : 264452
Epoch 10 Train Acc 49.89353561401367% Val Acc 34.0% Train Loss 0.5813849568367004 Val Loss 1.4067267179489136
Trainable Parameters : 264452
Epoch 11 Train Acc 50.90494155883789% Val Acc 32.60000228881836% Train Loss 0.5750350952148438 Val Loss 1.4517325162887573
Trainable Parameters : 264452
Epoch 12 Train Acc 51.441062927246094% Val Acc 34.10000228881836% Train Loss 0.5698201060295105 Val Loss 1.3771504163742065
Trainable Parameters : 264452
Epoch 13 Train Acc 51.8973388671875% Val Acc 41.70000076293945% Train Loss 0.5637909173965454 Val Loss 1.2617462873458862
Trainable Parameters : 264452
Epoch 14 Train Acc 52.8745231628418% Val Acc 40.0% Train Loss 0.5588409900665283 Val Loss 1.2966573238372803
Trainable Parameters : 264452
Epoch 15 Train Acc 53.315589904785156% Val Acc 36.79999923706055% Train Loss 0.5520913600921631 Val Loss 1.3470430374145508
Trainable Parameters : 264452
Epoch 16 Train Acc 52.927757263183594% Val Acc 40.20000076293945% Train Loss 0.5507732629776001 Val Loss 1.334381341934204
Trainable Parameters : 264452
Epoch 17 Train Acc 54.064640045166016% Val Acc 33.10000228881836% Train Loss 0.5474426746368408 Val Loss 1.5714735984802246
Trainable Parameters : 264452
Epoch 18 Train Acc 54.79847717285156% Val Acc 41.400001525878906% Train Loss 0.5395046472549438 Val Loss 1.3027749061584473
Trainable Parameters : 264452
Epoch 19 Train Acc 55.076045989990234% Val Acc 39.79999923706055% Train Loss 0.5369423627853394 Val Loss 1.3615716695785522
Trainable Parameters : 264452
Epoch 20 Train Acc 54.98479080200195% Val Acc 45.79999923706055% Train Loss 0.5362340807914734 Val Loss 1.2652772665023804
Trainable Parameters : 264452
Epoch 21 Train Acc 55.35361099243164% Val Acc 42.5% Train Loss 0.5328715443611145 Val Loss 1.333379864692688
Trainable Parameters : 264452
Epoch 22 Train Acc 55.29277420043945% Val Acc 46.60000228881836% Train Loss 0.5319584608078003 Val Loss 1.215959072113037
Trainable Parameters : 264452
Epoch 23 Train Acc 55.96577835083008% Val Acc 45.70000076293945% Train Loss 0.528085470199585 Val Loss 1.228485345840454
Trainable Parameters : 264452
Epoch 24 Train Acc 56.04562759399414% Val Acc 41.29999923706055% Train Loss 0.5264233350753784 Val Loss 1.3744558095932007
Trainable Parameters : 264452
Epoch 25 Train Acc 56.520912170410156% Val Acc 48.29999923706055% Train Loss 0.5269544720649719 Val Loss 1.1969473361968994
Trainable Parameters : 264452
Epoch 26 Train Acc 56.08745193481445% Val Acc 37.70000076293945% Train Loss 0.5266445875167847 Val Loss 1.4532374143600464
Trainable Parameters : 264452
Epoch 27 Train Acc 56.71482849121094% Val Acc 45.70000076293945% Train Loss 0.5261812806129456 Val Loss 1.3333224058151245
Trainable Parameters : 264452
Epoch 28 Train Acc 56.47148132324219% Val Acc 47.10000228881836% Train Loss 0.5260079503059387 Val Loss 1.2584031820297241
Trainable Parameters : 264452
Epoch 29 Train Acc 56.730037689208984% Val Acc 38.400001525878906% Train Loss 0.5171913504600525 Val Loss 1.6269077062606812
Trainable Parameters : 264452
Epoch 30 Train Acc 56.4638786315918% Val Acc 46.29999923706055% Train Loss 0.5206413865089417 Val Loss 1.3238645792007446
Trainable Parameters : 264452
Epoch 31 Train Acc 56.55133056640625% Val Acc 45.20000076293945% Train Loss 0.5227913856506348 Val Loss 1.2214179039001465
Trainable Parameters : 264452
Epoch 32 Train Acc 56.90874481201172% Val Acc 45.400001525878906% Train Loss 0.5190202593803406 Val Loss 1.2563966512680054
Trainable Parameters : 264452
Epoch 33 Train Acc 56.83650207519531% Val Acc 45.60000228881836% Train Loss 0.5225616097450256 Val Loss 1.3127784729003906
Trainable Parameters : 264452
Epoch 34 Train Acc 56.84790802001953% Val Acc 41.0% Train Loss 0.5172408819198608 Val Loss 1.361478567123413
Trainable Parameters : 264452
Epoch 35 Train Acc 56.581748962402344% Val Acc 44.10000228881836% Train Loss 0.5199093222618103 Val Loss 1.3472951650619507
Trainable Parameters : 264452
Epoch 36 Train Acc 57.24714660644531% Val Acc 49.29999923706055% Train Loss 0.5215276479721069 Val Loss 1.2417572736740112
Trainable Parameters : 264452
Epoch 37 Train Acc 56.615970611572266% Val Acc 48.79999923706055% Train Loss 0.5209922790527344 Val Loss 1.1640620231628418
Trainable Parameters : 264452
Epoch 38 Train Acc 56.825096130371094% Val Acc 42.70000076293945% Train Loss 0.5203666687011719 Val Loss 1.4404321908950806
Trainable Parameters : 264452
Epoch 39 Train Acc 56.96577835083008% Val Acc 33.400001525878906% Train Loss 0.5165798664093018 Val Loss 1.58161199092865
Trainable Parameters : 264452
Epoch 40 Train Acc 57.44486618041992% Val Acc 48.79999923706055% Train Loss 0.5153853893280029 Val Loss 1.1813215017318726
Trainable Parameters : 264452
Epoch 41 Train Acc 57.889732360839844% Val Acc 44.20000076293945% Train Loss 0.5114656090736389 Val Loss 1.2724874019622803
Trainable Parameters : 264452
Epoch 42 Train Acc 57.34600830078125% Val Acc 53.5% Train Loss 0.5157981514930725 Val Loss 1.1163759231567383
Trainable Parameters : 264452
Epoch 43 Train Acc 57.7414436340332% Val Acc 47.10000228881836% Train Loss 0.5146803855895996 Val Loss 1.2264164686203003
Trainable Parameters : 264452
Epoch 44 Train Acc 57.980987548828125% Val Acc 39.60000228881836% Train Loss 0.5069395303726196 Val Loss 1.4863083362579346
Trainable Parameters : 264452
Mon Oct 31 14:34:07 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 31/10/2022 14:34:24

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-first40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: False
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-first40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40_finetuned_results.csv
--> pretrained_mod: elgeish/wav2vec2-large-xlsr-53-arabic

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-3.0486e-02, -3.4805e-02, -2.8836e-02,  ...,  1.5430e-01,
          2.1431e-01,  1.1562e-01],
        [ 4.8310e-01,  9.3061e-01,  1.3262e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.4320e-02, -6.7237e-02,  1.9146e-02,  ..., -1.8169e-03,
         -6.6403e-04,  7.7211e-04],
        ...,
        [-1.0796e+00, -1.4652e+00, -1.3413e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.6497e-03,  6.8290e-03,  1.3244e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.2822e-02,  1.2372e-02,  1.4243e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 0, 3, 2, 3, 1, 2, 1, 1, 3, 2, 3, 0, 1, 0, 2, 2, 2, 3, 2, 2, 3, 0, 1,
        0, 0, 2, 3, 0, 0, 0, 3, 3, 2, 2, 2, 0, 2, 3, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[ 9.6349e-02,  8.1908e-02,  1.0313e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.3921e-03,  1.6300e-03, -8.0340e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.9813e-03,  4.2420e-04,  2.3287e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-1.1178e-05,  2.6007e-04, -1.3434e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.8906e-01, -4.3933e-01, -4.0837e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.5892e-02,  4.5299e-02, -6.0739e-02,  ...,  3.6263e-05,
          3.6224e-05,  3.6322e-05]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 2, 1, 0, 0, 1, 1, 2, 1, 2, 3, 1, 2, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3,
        2, 1, 3, 0, 1, 0, 3, 2, 0, 3, 1, 3, 1, 0, 1, 1])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'classifier.bias', 'classifier.weight', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[ 0.0197,  0.0136,  0.0192,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0659, -0.1018, -0.2386,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0459,  0.0344,  0.0489,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.1145, -0.2977,  0.1189,  ..., -0.0007, -0.0007, -0.0007],
        [ 0.0912, -0.0154, -0.1715,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0354, -0.0253, -0.0103,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 3, 1, 1, 0, 1, 0, 1, 1, 3, 0, 0, 3, 2, 2, 3, 3, 2, 1, 3, 1, 1, 0, 0,
        3, 0, 2, 2, 1, 0, 1, 0, 0, 0, 1, 2, 1, 3, 2, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 27.18250846862793% Val Acc 25.5% Train Loss 0.6865466833114624 Val Loss 1.415666103363037
Trainable Parameters : 264452
Epoch 1 Train Acc 40.0% Val Acc 26.200000762939453% Train Loss 0.6541747450828552 Val Loss 1.4572182893753052
Trainable Parameters : 264452
Epoch 2 Train Acc 39.992393493652344% Val Acc 24.700000762939453% Train Loss 0.6480065584182739 Val Loss 1.4521287679672241
Trainable Parameters : 264452
Epoch 3 Train Acc 40.06843948364258% Val Acc 24.100000381469727% Train Loss 0.6414721012115479 Val Loss 1.4473950862884521
Trainable Parameters : 264452
Epoch 4 Train Acc 40.870723724365234% Val Acc 27.700000762939453% Train Loss 0.6341966390609741 Val Loss 1.4452513456344604
Trainable Parameters : 264452
Epoch 5 Train Acc 42.36882019042969% Val Acc 32.0% Train Loss 0.6255806684494019 Val Loss 1.4246779680252075
Trainable Parameters : 264452
Epoch 6 Train Acc 44.74905014038086% Val Acc 30.80000114440918% Train Loss 0.6164894700050354 Val Loss 1.3755323886871338
Trainable Parameters : 264452
Epoch 7 Train Acc 46.783267974853516% Val Acc 31.700000762939453% Train Loss 0.6063908934593201 Val Loss 1.3966082334518433
Trainable Parameters : 264452
Epoch 8 Train Acc 47.718631744384766% Val Acc 36.70000076293945% Train Loss 0.5973007082939148 Val Loss 1.348643183708191
Trainable Parameters : 264452
Epoch 9 Train Acc 49.212928771972656% Val Acc 36.400001525878906% Train Loss 0.5891366600990295 Val Loss 1.345706582069397
Trainable Parameters : 264452
Epoch 10 Train Acc 49.737640380859375% Val Acc 34.29999923706055% Train Loss 0.5828593373298645 Val Loss 1.3895952701568604
Trainable Parameters : 264452
Epoch 11 Train Acc 50.878326416015625% Val Acc 32.20000076293945% Train Loss 0.5757034420967102 Val Loss 1.4312880039215088
Trainable Parameters : 264452
Epoch 12 Train Acc 51.026615142822266% Val Acc 34.0% Train Loss 0.5695075988769531 Val Loss 1.3905432224273682
Trainable Parameters : 264452
Epoch 13 Train Acc 51.80608367919922% Val Acc 41.0% Train Loss 0.5643690228462219 Val Loss 1.2639930248260498
Trainable Parameters : 264452
Epoch 14 Train Acc 52.55133056640625% Val Acc 41.400001525878906% Train Loss 0.5573135614395142 Val Loss 1.2871445417404175
Trainable Parameters : 264452
Epoch 15 Train Acc 53.36501693725586% Val Acc 37.79999923706055% Train Loss 0.5522222518920898 Val Loss 1.364437460899353
Trainable Parameters : 264452
Epoch 16 Train Acc 53.80988693237305% Val Acc 38.0% Train Loss 0.5484796166419983 Val Loss 1.353206753730774
Trainable Parameters : 264452
Epoch 17 Train Acc 54.224334716796875% Val Acc 33.79999923706055% Train Loss 0.5479398369789124 Val Loss 1.5437421798706055
Trainable Parameters : 264452
Epoch 18 Train Acc 54.524715423583984% Val Acc 41.0% Train Loss 0.5418385863304138 Val Loss 1.301077127456665
Trainable Parameters : 264452
Epoch 19 Train Acc 55.08745193481445% Val Acc 40.0% Train Loss 0.5370084643363953 Val Loss 1.2973178625106812
Trainable Parameters : 264452
Epoch 20 Train Acc 55.038021087646484% Val Acc 46.79999923706055% Train Loss 0.5369406938552856 Val Loss 1.265420913696289
Trainable Parameters : 264452
Epoch 21 Train Acc 55.43726348876953% Val Acc 45.20000076293945% Train Loss 0.5350452661514282 Val Loss 1.2585190534591675
Trainable Parameters : 264452
Epoch 22 Train Acc 55.91634750366211% Val Acc 48.5% Train Loss 0.5340482592582703 Val Loss 1.214629888534546
Trainable Parameters : 264452
Epoch 23 Train Acc 55.53992462158203% Val Acc 44.70000076293945% Train Loss 0.5299127697944641 Val Loss 1.2232248783111572
Trainable Parameters : 264452
Epoch 24 Train Acc 55.30038070678711% Val Acc 39.79999923706055% Train Loss 0.5291373133659363 Val Loss 1.4064258337020874
Trainable Parameters : 264452
Epoch 25 Train Acc 55.44486618041992% Val Acc 46.29999923706055% Train Loss 0.5278798341751099 Val Loss 1.1991385221481323
Trainable Parameters : 264452
Epoch 26 Train Acc 56.11787033081055% Val Acc 39.79999923706055% Train Loss 0.5266238451004028 Val Loss 1.3638982772827148
Trainable Parameters : 264452
Epoch 27 Train Acc 56.85171127319336% Val Acc 44.60000228881836% Train Loss 0.5237299203872681 Val Loss 1.2959340810775757
Trainable Parameters : 264452
Epoch 28 Train Acc 56.7414436340332% Val Acc 42.900001525878906% Train Loss 0.5225479006767273 Val Loss 1.3717337846755981
Trainable Parameters : 264452
Epoch 29 Train Acc 56.26235580444336% Val Acc 38.5% Train Loss 0.5227823257446289 Val Loss 1.5404176712036133
Trainable Parameters : 264452
Epoch 30 Train Acc 56.31178665161133% Val Acc 44.79999923706055% Train Loss 0.5245084166526794 Val Loss 1.2742358446121216
Trainable Parameters : 264452
Epoch 31 Train Acc 56.60456085205078% Val Acc 44.79999923706055% Train Loss 0.5210661292076111 Val Loss 1.2316862344741821
Trainable Parameters : 264452
Epoch 32 Train Acc 56.889732360839844% Val Acc 43.10000228881836% Train Loss 0.5206652879714966 Val Loss 1.3125197887420654
Trainable Parameters : 264452
Epoch 33 Train Acc 57.04943084716797% Val Acc 39.900001525878906% Train Loss 0.5204147696495056 Val Loss 1.504132628440857
Trainable Parameters : 264452
Epoch 34 Train Acc 56.8441047668457% Val Acc 45.70000076293945% Train Loss 0.5186216831207275 Val Loss 1.274454951286316
Trainable Parameters : 264452
Epoch 35 Train Acc 56.93916320800781% Val Acc 45.0% Train Loss 0.5196242332458496 Val Loss 1.318149447441101
Trainable Parameters : 264452
Epoch 36 Train Acc 56.673004150390625% Val Acc 47.900001525878906% Train Loss 0.5211673974990845 Val Loss 1.3279699087142944
Trainable Parameters : 264452
Epoch 37 Train Acc 56.25094985961914% Val Acc 51.70000076293945% Train Loss 0.5205131769180298 Val Loss 1.1694750785827637
Trainable Parameters : 264452
Epoch 38 Train Acc 56.88212966918945% Val Acc 43.20000076293945% Train Loss 0.5218551754951477 Val Loss 1.4143356084823608
Trainable Parameters : 264452
Configuration saved in ../output/u_train_700f_local/ADI17-xlsr-nr-first40/config.json
Model weights saved in ../output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin
Epoch 39 Train Acc 56.61216735839844% Val Acc 34.79999923706055% Train Loss 0.5153988003730774 Val Loss 1.5413763523101807

------> EVALUATING MODEL... ------------------------------------------ 

Final Test Acc:35.900001525878906% Loss:1.3932040929794312
CONFUSION MATRIX
[[ 7  5 10 78]
 [ 1 13  9 77]
 [ 0  3 30 65]
 [ 0  4  3 93]]
CONFUSION MATRIX NORMALISED
[[0.01758794 0.01256281 0.02512563 0.1959799 ]
 [0.00251256 0.03266332 0.02261307 0.19346734]
 [0.         0.00753769 0.07537688 0.16331658]
 [0.         0.01005025 0.00753769 0.23366834]]
CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.88      0.07      0.13       100
           1       0.52      0.13      0.21       100
           2       0.58      0.31      0.40        98
           3       0.30      0.93      0.45       100

    accuracy                           0.36       398
   macro avg       0.57      0.36      0.30       398
weighted avg       0.57      0.36      0.30       398


------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 01/11/2022 02:25:57
Tue Nov 1 02:35:40 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 01/11/2022 02:35:58

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-second40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-second40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-second40_finetuned_results.csv
--> pretrained_mod: /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 3.0468,  2.2502,  1.0562,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7242, -0.2072, -0.4571,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0057, -0.0404, -0.0115,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.6137, -0.5292, -0.4876,  ...,  0.0000,  0.0000,  0.0000],
        [-1.8641, -1.8051, -1.9875,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0047, -0.7345, -2.2697,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 2, 3, 2, 0, 3, 2, 2, 3, 2, 3, 3, 3, 0, 3, 3, 0, 2, 3, 1, 0, 2, 1, 2,
        3, 2, 0, 3, 3, 0, 0, 0, 0, 2, 3, 0, 2, 3, 3, 1])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-0.0587,  0.0214,  0.0473,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2436, -0.2306, -0.2609,  ...,  0.0021,  0.0020,  0.0019],
        [-0.4076, -0.3190, -0.1435,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0613,  0.0543,  0.0603,  ...,  0.0154,  0.0261,  0.0336],
        [ 0.0035,  0.0044,  0.0055,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6327,  0.5188,  0.5540,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 2, 3, 2, 3, 0, 1, 3, 0, 2, 1, 2, 3, 1, 2, 1, 0, 1, 1, 1, 3, 2, 1, 1,
        1, 0, 3, 1, 0, 3, 2, 1, 0, 1, 2, 3, 3, 0, 2, 1])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
{'input_values': tensor([[ 6.9586e-02,  6.4154e-02,  7.3981e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.0957e-03,  1.5300e-03,  1.8849e-03,  ...,  2.4482e-01,
          3.2644e-01,  5.9892e-01],
        [-8.9393e-01, -2.3018e-01, -2.1006e-01,  ...,  2.4764e-02,
         -4.9378e-02, -1.0064e-01],
        ...,
        [-4.0617e-01, -4.9827e-01, -5.9735e-01,  ...,  5.8733e-01,
          1.6154e+00,  5.7152e-01],
        [-8.4289e-02, -1.4494e-01, -6.1073e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.6608e-01, -1.1847e-01, -1.6965e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 3, 3, 1, 0, 2, 2, 2, 1, 2, 2, 3, 3, 0, 3, 2, 0, 1, 1, 2, 3, 0, 0, 1,
        1, 3, 3, 3, 1, 2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 1])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 650, in _get_config_dict
    config_dict = cls._dict_from_json_file(resolved_config_file)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 733, in _dict_from_json_file
    text = reader.read()
  File "/apps/python/3.8.3/lib/python3.8/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_xlsr_nr.py", line 436, in <module>
    config = AutoConfig.from_pretrained(
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 705, in from_pretrained
    config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 553, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 652, in _get_config_dict
    raise EnvironmentError(
OSError: It looks like the config file at '/home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin' is not a valid JSON file.
Tue Nov 1 10:51:20 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 01/11/2022 10:51:36

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-second40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/config.json
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-second40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-second40_finetuned_results.csv
--> pretrained_mod: /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/config.json

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-3.2291e-04,  4.6950e-05, -3.1864e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.4805e-02,  9.3143e-02,  2.5549e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.2503e-03,  2.3903e-03,  2.5916e-03,  ..., -1.2287e-01,
         -1.0290e-01, -7.9808e-02],
        ...,
        [ 1.1678e+00,  7.6515e-01,  6.7102e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0675e-02, -7.9669e-03, -9.7452e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-5.3097e-02, -2.6520e-02, -3.9897e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 3, 1, 0, 2, 2, 2, 0, 2, 3, 2, 1, 3, 2, 2, 3, 3, 2, 3, 2, 2, 0, 3, 2,
        0, 0, 3, 1, 0, 3, 1, 2, 1, 0, 0, 3, 2, 2, 2, 1])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-0.0643, -0.0649, -0.0867,  ..., -0.7442, -0.6096, -0.5313],
        [ 1.1073,  0.9336,  0.9014,  ...,  0.0000,  0.0000,  0.0000],
        [-1.1394, -0.8495, -0.8348,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0865,  0.0866,  0.0933,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2518,  0.1001,  0.3086,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6845, -0.3646, -1.0073,  ...,  0.0043,  0.0155,  0.0062]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 0, 3, 2, 3, 1, 0, 1, 1, 2, 0, 3, 1, 0, 3, 2, 3, 3, 3, 2, 3, 1, 0, 1,
        3, 1, 1, 3, 0, 0, 1, 3, 1, 3, 0, 2, 0, 0, 2, 0])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
{'input_values': tensor([[ 1.1260e-04,  1.0964e-04,  1.0632e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.6743e-01,  1.2723e-01,  1.7780e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-9.0583e-01, -1.1202e+00, -1.4296e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-1.1698e-02, -3.4626e-03, -7.3151e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.3063e-02,  4.2349e-02,  1.0750e-01,  ..., -2.9931e-01,
         -3.1719e-01, -3.2908e-01],
        [-1.0946e+00, -9.5813e-01, -1.1304e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 1, 3, 0, 3, 1, 2, 1, 2, 1, 2, 0, 0, 1, 1, 0, 1, 1, 3, 1, 1, 3, 2, 2,
        2, 0, 0, 1, 1, 0, 1, 1, 3, 3, 1, 0, 1, 3, 3, 0])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
Traceback (most recent call last):
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 601, in _get_config_dict
    resolved_config_file = cached_path(
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/utils/hub.py", line 284, in cached_path
    output_path = get_from_cache(
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/utils/hub.py", line 554, in get_from_cache
    raise ValueError(
ValueError: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_xlsr_nr.py", line 436, in <module>
    config = AutoConfig.from_pretrained(
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 705, in from_pretrained
    config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 553, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/configuration_utils.py", line 634, in _get_config_dict
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/config.json is not the path to a directory containing a config.json file.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
Tue Nov 1 11:01:27 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 01/11/2022 11:01:42

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-second40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-second40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-second40_finetuned_results.csv

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 7.5148e-03, -7.2000e-03, -1.8374e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.4461e-02,  5.9400e-03, -1.3788e-02,  ..., -6.8350e-05,
         -6.8801e-05, -6.9266e-05],
        [-3.7356e-04, -2.4397e-04, -4.0475e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-1.8331e-01, -2.1715e-01, -2.4896e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.9329e-02, -3.6616e-02, -4.2759e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0296e-02,  4.9448e-02, -7.2345e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 2, 2, 2, 2, 1, 2, 0, 3, 3, 0, 2, 2, 2, 0, 3, 1, 2, 3, 3, 3, 0, 2,
        0, 2, 0, 2, 0, 3, 3, 1, 3, 2, 3, 3, 2, 2, 3, 0])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-2.3741e-02, -1.0185e-02, -2.4565e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.6337e-01, -9.7132e-01, -1.8844e+00,  ...,  3.2034e-01,
          3.1489e-01,  3.1286e-01],
        [-6.2676e-01, -1.0705e+00, -1.6418e+00,  ..., -4.5344e-01,
         -5.1294e-01, -5.6505e-01],
        ...,
        [-8.8078e-01, -2.5306e+00, -1.3939e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 7.7629e-02, -1.0903e-03, -2.2100e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.4356e-01, -2.3058e-01, -2.6091e-01,  ...,  2.0980e-03,
          1.9747e-03,  1.8526e-03]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 2, 3, 0, 2, 3, 2, 1, 2, 2, 3, 3, 1, 2, 0, 1, 1, 3, 0, 2, 1, 3, 1, 1,
        2, 3, 0, 2, 0, 2, 1, 0, 3, 3, 3, 2, 1, 1, 3, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
{'input_values': tensor([[-0.0370,  0.0022,  0.0742,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1400, -0.5655, -0.2345,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0664, -0.0410,  0.0749,  ...,  0.3190,  0.4422,  0.5227],
        ...,
        [ 0.0696,  0.0642,  0.0740,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0165, -0.0130,  0.0055,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0795, -0.5479, -0.8653,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 3, 3, 2, 0, 1, 3, 1, 3, 2, 0, 3, 0, 2, 3, 1, 0, 3, 0, 3, 3, 1, 0, 3,
        2, 3, 1, 1, 0, 0, 0, 3, 0, 1, 1, 1, 1, 0, 1, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 426, in <module>
    pretrained_mod,
NameError: name 'pretrained_mod' is not defined
Tue Nov 1 11:22:39 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 01/11/2022 11:22:53

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-second40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-second40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-second40_finetuned_results.csv

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0387,  0.0259,  0.0787,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3549, -0.2995, -0.4377,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0168, -0.0164,  0.0165,  ..., -1.0158, -0.7459, -0.2905],
        ...,
        [-0.0341, -0.0335, -0.0381,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1097,  0.2535,  0.3413,  ...,  1.0808,  2.0708,  2.8317],
        [-0.0255, -0.0275, -0.0296,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 0, 0, 0, 2, 2, 2, 2, 2, 3, 1, 2, 3, 2, 1, 3, 2, 0, 2, 1, 3, 1, 2, 2,
        2, 0, 2, 1, 3, 2, 3, 2, 2, 2, 1, 2, 2, 0, 0, 1])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-0.0430, -0.0463, -0.0516,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0085, -0.0731,  0.3722,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0389, -0.1284, -0.0973,  ...,  0.1633,  0.1665,  0.1210],
        ...,
        [-0.0328, -0.0630, -0.0252,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0238,  0.0333,  0.0305,  ...,  0.3919,  0.1378,  0.5010],
        [-0.1764, -0.1567, -0.2390,  ...,  0.1594,  0.1857,  0.1927]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([2, 0, 2, 2, 0, 2, 3, 0, 0, 0, 3, 2, 2, 3, 0, 0, 2, 1, 1, 3, 1, 0, 2, 1,
        2, 3, 0, 2, 1, 2, 2, 2, 0, 1, 3, 0, 2, 2, 2, 0])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.bias', 'classifier.weight', 'classifier.bias', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[-2.6815e-01, -3.2971e-01, -3.9647e-01,  ..., -4.9374e-01,
         -2.7702e-01, -1.3368e-01],
        [ 8.1675e-01, -1.3152e-01, -6.7256e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.1964e-03,  2.1224e-03,  2.0233e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 8.7488e-05,  7.6728e-05,  7.6589e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.9192e-03,  5.3284e-03,  2.1234e-03,  ..., -3.2242e-01,
         -2.8214e-01, -2.5992e-02],
        [ 1.9294e-02,  4.3608e-03,  2.4744e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 2, 0, 3, 2, 0, 3, 0, 2, 2, 0, 0, 3, 2, 0, 3, 0, 0, 1, 2, 3, 3, 3, 3,
        1, 2, 1, 1, 1, 3, 3, 2, 0, 2, 3, 1, 0, 2, 2, 2])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 455, in <module>
    model.load_state_dict(torch.load(checkpoint), strict=True)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-first40/pytorch_model.bin'
Tue Nov 1 11:32:54 AEDT 2022
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 01/11/2022 11:33:12

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-second40
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /srv/scratch/z5208494/ADI17-xlsr-nr-first40/pytorch_model.bin
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 40
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-second40
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-second40_finetuned_results.csv

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[ 1.4375e-01,  1.3300e-01,  1.5789e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.1451e-01,  3.6227e-01,  1.7483e-02,  ..., -2.0397e+00,
         -1.7164e+00, -9.8972e-01],
        [-1.4436e-01, -8.0138e-01, -7.4559e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 9.0535e-02,  1.3359e-01,  1.6321e-01,  ..., -1.9435e+00,
         -1.9382e+00, -1.9917e+00],
        [ 3.9500e-01,  2.8104e-01,  3.5160e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.2881e-04, -2.8709e-04, -1.8179e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 3, 1, 3, 1, 3, 1, 3, 3, 0, 1, 3, 1, 3, 2, 2, 2, 0, 2, 3, 0, 1, 1,
        2, 2, 3, 3, 1, 2, 2, 3, 0, 1, 2, 0, 2, 2, 2, 2])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[ 0.6961,  1.2832,  1.7728,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1126,  0.1596,  0.1804,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2637,  0.2392,  0.2779,  ...,  0.0033,  0.0044,  0.0045],
        ...,
        [-0.0174,  0.2320,  0.2738,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8326, -0.4532, -0.4861,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3199, -0.1389, -0.3092,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 1, 3, 2, 0, 0, 1, 2, 0, 3, 0, 3, 0, 0, 1, 1, 2, 0, 1, 2, 2, 1, 2,
        2, 2, 0, 2, 1, 3, 2, 1, 2, 0, 3, 3, 2, 3, 1, 2])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using cuda_amp half precision backend
{'input_values': tensor([[-6.8618e-03, -7.3046e-04, -7.0749e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-4.7087e-01, -4.5777e-01, -2.3750e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0129e+00,  4.4820e-01,  1.6955e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 4.1185e-03,  1.5307e-03,  8.9463e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.3501e-01, -2.7016e-02, -2.9844e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.2329e+00, -3.9056e-01,  1.6129e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 3, 1, 2, 2, 0, 1, 2, 1, 2, 2, 3, 3, 1, 2, 3, 1, 0, 3, 2, 3, 1, 3, 0,
        3, 2, 1, 3, 0, 1, 1, 2, 2, 3, 3, 2, 1, 2, 0, 0])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
-------- Setting up Model --------
GPUs Used :  3 GPUs!
SUCCESS: Pre-trained checkpoint loaded.
--> Defining Custom Trainer Class...

------> STARTING TRAINING... ----------------------------------------- 

Trainable Parameters : 264452
Epoch 0 Train Acc 52.75284957885742% Val Acc 47.5% Train Loss 0.5395147204399109 Val Loss 1.2277778387069702
Trainable Parameters : 264452
Epoch 1 Train Acc 59.83650207519531% Val Acc 49.70000076293945% Train Loss 0.49173790216445923 Val Loss 1.2232576608657837
Trainable Parameters : 264452
Epoch 2 Train Acc 60.41444778442383% Val Acc 48.70000076293945% Train Loss 0.49041086435317993 Val Loss 1.229850172996521
Trainable Parameters : 264452
Epoch 3 Train Acc 60.16349792480469% Val Acc 46.400001525878906% Train Loss 0.49244052171707153 Val Loss 1.2400635480880737
Trainable Parameters : 264452
Epoch 4 Train Acc 60.29277420043945% Val Acc 47.5% Train Loss 0.4885612428188324 Val Loss 1.2501041889190674
Trainable Parameters : 264452
Epoch 5 Train Acc 60.05323028564453% Val Acc 49.10000228881836% Train Loss 0.4931378960609436 Val Loss 1.207846999168396
Trainable Parameters : 264452
Epoch 6 Train Acc 60.18251037597656% Val Acc 48.60000228881836% Train Loss 0.49278953671455383 Val Loss 1.2404868602752686
Trainable Parameters : 264452
Epoch 7 Train Acc 59.623573303222656% Val Acc 46.70000076293945% Train Loss 0.49308905005455017 Val Loss 1.2509032487869263
Trainable Parameters : 264452
Epoch 8 Train Acc 60.129276275634766% Val Acc 48.10000228881836% Train Loss 0.48849284648895264 Val Loss 1.1922005414962769
Trainable Parameters : 264452
Epoch 9 Train Acc 59.718631744384766% Val Acc 48.5% Train Loss 0.4900909960269928 Val Loss 1.2139438390731812
Trainable Parameters : 264452
Epoch 10 Train Acc 59.923954010009766% Val Acc 47.10000228881836% Train Loss 0.4917227625846863 Val Loss 1.2641619443893433
Trainable Parameters : 264452
Epoch 11 Train Acc 60.06083679199219% Val Acc 44.29999923706055% Train Loss 0.48896753787994385 Val Loss 1.3553438186645508
Trainable Parameters : 264452
Epoch 12 Train Acc 60.627376556396484% Val Acc 46.0% Train Loss 0.4856792688369751 Val Loss 1.2821906805038452
Trainable Parameters : 264452
Epoch 13 Train Acc 59.85551452636719% Val Acc 53.10000228881836% Train Loss 0.4925232529640198 Val Loss 1.117091178894043
Trainable Parameters : 264452
Epoch 14 Train Acc 60.26235580444336% Val Acc 51.79999923706055% Train Loss 0.48856937885284424 Val Loss 1.127114176750183
Trainable Parameters : 264452
Epoch 15 Train Acc 59.94296646118164% Val Acc 47.20000076293945% Train Loss 0.4908294677734375 Val Loss 1.2410262823104858
Trainable Parameters : 264452
Epoch 16 Train Acc 59.85931396484375% Val Acc 41.60000228881836% Train Loss 0.491891086101532 Val Loss 1.4326826333999634
Trainable Parameters : 264452
Epoch 17 Train Acc 59.90113830566406% Val Acc 40.29999923706055% Train Loss 0.4904685318470001 Val Loss 1.4753952026367188
Trainable Parameters : 264452
Epoch 18 Train Acc 60.026615142822266% Val Acc 44.60000228881836% Train Loss 0.49104204773902893 Val Loss 1.243778109550476
Trainable Parameters : 264452
Epoch 19 Train Acc 59.889732360839844% Val Acc 48.0% Train Loss 0.4901435077190399 Val Loss 1.2116484642028809
Trainable Parameters : 264452
Epoch 20 Train Acc 59.76805877685547% Val Acc 51.5% Train Loss 0.49529778957366943 Val Loss 1.1860032081604004
Trainable Parameters : 264452
Epoch 21 Train Acc 59.25094985961914% Val Acc 44.79999923706055% Train Loss 0.49552035331726074 Val Loss 1.2846095561981201
Trainable Parameters : 264452
Epoch 22 Train Acc 59.680606842041016% Val Acc 46.60000228881836% Train Loss 0.4952661097049713 Val Loss 1.2132896184921265
Trainable Parameters : 264452
Epoch 23 Train Acc 59.56273651123047% Val Acc 50.5% Train Loss 0.49667707085609436 Val Loss 1.1895583868026733
Trainable Parameters : 264452
Epoch 24 Train Acc 59.39923858642578% Val Acc 45.20000076293945% Train Loss 0.4931016266345978 Val Loss 1.2374765872955322
Trainable Parameters : 264452
Epoch 25 Train Acc 59.49810028076172% Val Acc 45.10000228881836% Train Loss 0.49575677514076233 Val Loss 1.209808111190796
Trainable Parameters : 264452
Epoch 26 Train Acc 58.992393493652344% Val Acc 42.900001525878906% Train Loss 0.5009327530860901 Val Loss 1.3423572778701782
Trainable Parameters : 264452
Epoch 27 Train Acc 59.36501693725586% Val Acc 46.900001525878906% Train Loss 0.49694591760635376 Val Loss 1.3224351406097412
Trainable Parameters : 264452
Epoch 28 Train Acc 58.866920471191406% Val Acc 50.20000076293945% Train Loss 0.49777957797050476 Val Loss 1.277495265007019
Trainable Parameters : 264452
Epoch 29 Train Acc 58.41444778442383% Val Acc 41.400001525878906% Train Loss 0.5014811158180237 Val Loss 1.4384278059005737
Trainable Parameters : 264452
Epoch 30 Train Acc 59.167301177978516% Val Acc 48.70000076293945% Train Loss 0.5001930594444275 Val Loss 1.2892335653305054
Trainable Parameters : 264452
Epoch 31 Train Acc 58.95056915283203% Val Acc 46.29999923706055% Train Loss 0.5014471411705017 Val Loss 1.226336121559143
Trainable Parameters : 264452
Epoch 32 Train Acc 58.68821334838867% Val Acc 45.900001525878906% Train Loss 0.4987737238407135 Val Loss 1.3953906297683716
Trainable Parameters : 264452
Epoch 33 Train Acc 59.35361099243164% Val Acc 42.900001525878906% Train Loss 0.5014719367027283 Val Loss 1.3671764135360718
Trainable Parameters : 264452
Epoch 34 Train Acc 58.467681884765625% Val Acc 44.79999923706055% Train Loss 0.5035231709480286 Val Loss 1.3058842420578003
Trainable Parameters : 264452
Epoch 35 Train Acc 58.77946853637695% Val Acc 45.400001525878906% Train Loss 0.5001367330551147 Val Loss 1.3266206979751587
Trainable Parameters : 264452
Epoch 36 Train Acc 59.038021087646484% Val Acc 47.0% Train Loss 0.5046519637107849 Val Loss 1.389931321144104
Trainable Parameters : 264452
Epoch 37 Train Acc 58.50189971923828% Val Acc 48.60000228881836% Train Loss 0.5047500133514404 Val Loss 1.1931860446929932
Trainable Parameters : 264452
Epoch 38 Train Acc 58.90114212036133% Val Acc 44.5% Train Loss 0.5034945607185364 Val Loss 1.423361897468567
Trainable Parameters : 264452
Configuration saved in ../output/u_train_700f_local/ADI17-xlsr-nr-second40/config.json
Epoch 39 Train Acc 59.04943084716797% Val Acc 35.79999923706055% Train Loss 0.49904894828796387 Val Loss 1.4584218263626099
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 716, in <module>
    model.module.save_pretrained(model_fp)
  File "/home/z5208494/.local/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1657, in save_pretrained
    save_function(shard, os.path.join(save_directory, shard_file))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 381, in save
    return
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in __exit__
    self.file_like.close()
OSError: [Errno 122] Disk quota exceeded
Wed Nov 2 21:10:48 AEDT 2022
2022-11-02 21:10:49.886990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-02 21:10:50.095916: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-02 21:10:50.130080: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-02 21:10:52.173567: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-02 21:10:52.173649: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-02 21:10:52.173657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 02/11/2022 21:11:04

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-last20
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /srv/scratch/z5208494/ADI17-xlsr-nr-second40/pytorch_model.bin
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 20
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-last20
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-last20_finetuned_results.csv

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-1.6811e+00, -1.5824e+00, -3.0186e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.8314e-03, -1.1130e-03,  2.7323e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.3675e-03, -1.7406e-02, -1.2928e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-1.4386e+00, -1.0925e+00, -5.0916e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 7.9830e-01,  4.7284e-01,  3.7143e-01,  ..., -1.1462e+00,
         -1.0480e+00, -1.3871e-01],
        [-1.0994e-02, -7.4175e-03, -9.1961e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 0, 1, 2, 1, 2, 3, 3, 2, 3, 3, 2, 3, 2, 1, 1, 2, 2, 0, 2, 3, 1, 3,
        0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 3, 0, 2, 1])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-0.0365, -0.0435, -0.0332,  ...,  0.0000,  0.0000,  0.0000],
        [ 2.9449,  1.2775,  0.7466,  ...,  0.0000,  0.0000,  0.0000],
        [-1.9285, -2.1662, -1.5641,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.2913,  0.5539,  0.7075,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1889,  0.5987,  1.0497,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1093, -0.0264, -0.0126,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 2, 0, 2, 2, 1, 1, 1, 1, 2, 0, 1, 2, 3, 0, 3, 2, 2, 3, 0, 1, 3,
        3, 0, 3, 3, 1, 1, 3, 2, 2, 1, 1, 2, 3, 0, 1, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['projector.weight', 'classifier.bias', 'classifier.weight', 'projector.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 3.1634e-04,  2.6119e-03,  3.6247e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-7.2339e-02, -4.3615e-02, -6.7823e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.7959e-02,  5.5426e-02,  7.3344e-02,  ..., -3.1212e-02,
         -2.9442e-02, -1.6040e-02],
        ...,
        [-6.6391e-01, -5.5272e-01, -6.5471e-01,  ..., -2.6837e-01,
         -6.3992e-02,  1.9955e-01],
        [ 2.6069e-02,  2.1849e-02, -1.6808e-01,  ...,  1.4486e+00,
          1.9938e+00,  2.3683e+00],
        [ 2.1964e-03,  2.1224e-03,  2.0233e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 2, 3, 1, 0, 3, 0, 1, 2, 0, 3, 0, 0, 1, 2, 1, 3, 0, 2, 0, 2, 3, 1, 3,
        1, 3, 2, 1, 0, 0, 1, 3, 0, 2, 2, 3, 3, 2, 0, 0])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 455, in <module>
    model.load_state_dict(torch.load(checkpoint), strict=True)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 1046, in _load
    result = unpickler.load()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 1016, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 997, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch._UntypedStorage).storage()._untyped()
RuntimeError: PytorchStreamReader failed reading file data/7: invalid header or archive is corrupted
Thu Nov 3 00:14:41 AEDT 2022
2022-11-03 00:14:43.322648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-03 00:14:43.718351: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-03 00:14:43.852914: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-03 00:14:45.534200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-03 00:14:45.536694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/sox/14.4.2/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/daal/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/ipp/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64_lin/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/tbb/lib/intel64/gcc4.4:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/mkl/lib/intel64_lin:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/debugger/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/libipt/intel64/lib:/apps/intel/Composer/debugger_2019/iga/lib:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64:/apps/intel/Composer/compilers_and_libraries_2019.0.117/linux/compiler/lib/intel64_lin:/apps/python/3.8.3/lib:/apps/gcc/8.4.0/lib64:/apps/gcc/8.4.0/lib:/apps/cuda/11.1/lib64:/apps/cuda/11.1/extras/CUPTI/lib64
2022-11-03 00:14:45.536707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
------------------------------------------------------------------------
                         run_xlsr_nr.py                            
------------------------------------------------------------------------
Running:  /home/z5208494/thesis/run_xlsr_nr.py
Started: 03/11/2022 00:14:57

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing json...
-->Importing Wav2Vec transformers...
-->Importing torchaudio...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: True
experiment_id: ADI17-xlsr-nr-last20
datasetdict_id: myST-eval
data path: /srv/scratch/z5208494/dataset/
test data path: /srv/scratch/z5208494/dataset/train_segments/
training data path: /srv/scratch/z5208494/dataset/dev_segments/
test data path: /srv/scratch/z5208494/dataset/test_segments/
base_fp: /srv/scratch/z5208494/output/
train_name: u_train_700f
train_filename: u_train_700f
validation_filename: dev_u_200f
evaluation_filename: test_u_100f
use_checkpoint: True
checkpoint: /srv/scratch/z5208494/ADI17-xlsr-nr-second40/pytorch_model.bin
eval_pretrained: False

------> MODEL ARGUMENTS... -------------------------------------------

number_of_worker: 1
hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: False
gradient_checkpointing: False
pooling_mode: mean

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: no
batch_size: 40
gradient_accumulation_steps: 2
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
unfreezing_step: 10
num_train_epochs: 20
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 10
save_strategy: epoch
save_steps: 500
save_total_limit: 40
fp16: True
eval_steps: 100
load_best_model_at_end: False
metric_for_best_model: accuracy
greater_is_better: False
group_by_length: True
push_to_hub: False

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: data/u_train_700f.csv
--> data_test_fp: data/dev_u_200f.csv
--> data_test_fp: data/test_u_100f.csv
--> data_cache_fp: /srv/scratch/z5208494/cache/huggingface/datasets/myST-eval
--> model_fp: ../output/u_train_700f_local/ADI17-xlsr-nr-last20
--> finetuned_results_fp: /srv/scratch/z5208494/output/u_train_700f_local/ADI17-xlsr-nr-last20_finetuned_results.csv

------> PREPARING DATASET LABELS... ------------------------------------


------> PRE-PROCESSING DATA... ----------------------------------------- 

Max Duration: 10 s
Sampling Rate: 16000
Target Sampling Rate: 16000
Create a custom dataset ---> 
Check data has been processed correctly... 
Train Data Sample
{'input_values': tensor([[-0.0121, -0.0059, -0.0110,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0566,  0.0392, -0.0061,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0091,  0.0069, -0.0015,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0410,  0.0459,  0.0518,  ...,  0.0301,  0.0439,  0.0558],
        [-0.0075, -0.0079, -0.0082,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0329,  0.0052, -0.0040,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 3, 2, 0, 0, 2, 2, 3, 2, 3, 0, 2, 1, 1, 2, 3, 3, 0, 3, 1, 2, 2, 0, 2,
        2, 1, 3, 0, 1, 1, 2, 1, 0, 2, 2, 0, 3, 1, 3, 0])}
Training DataCustom Files: 10502
Training Data Files: 263
Val Data Sample
{'input_values': tensor([[-4.8121e-03, -8.6886e-03, -8.3052e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.2657e+00,  1.6329e+00,  1.8045e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.2873e-02, -1.0641e-02, -1.4221e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-9.0497e-03, -1.4144e-03, -8.9943e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.5131e-03, -7.3055e-02,  3.7217e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.3907e-04,  1.6314e-04,  1.1527e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 3, 2, 3, 1, 2, 1, 3, 2, 2, 3, 0, 1, 2, 0, 3, 0, 2, 0, 1, 0, 2, 0,
        0, 3, 3, 0, 3, 3, 3, 2, 3, 3, 3, 0, 0, 1, 0, 3])}
Test CustomData Files: 813
Test Data Files: 21
Test Data Sample
Some weights of the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at elgeish/wav2vec2-large-xlsr-53-arabic and are newly initialized: ['classifier.bias', 'projector.bias', 'classifier.weight', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'input_values': tensor([[ 9.8601e-02,  5.1300e-01,  2.4691e-01,  ..., -3.6650e-02,
         -4.1459e-02, -4.0090e-02],
        [ 3.1587e-01,  4.0108e-01,  4.2530e-01,  ..., -9.3143e-01,
         -9.1970e-01, -8.8143e-01],
        [-5.8074e-01, -5.4465e-01, -4.1548e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 8.0719e-02,  8.0758e-02,  1.4626e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.0738e-01,  2.4392e-01,  2.8339e-01,  ..., -1.9145e-04,
         -1.6422e-04, -1.3268e-05],
        [ 1.3664e-01,  1.2947e-01,  1.8031e-01,  ...,  5.7401e-04,
          5.7816e-04,  5.7290e-04]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 3, 0, 0, 3, 3, 0, 1, 0, 3, 3, 0, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 3, 3,
        3, 1, 2, 1, 1, 0, 0, 0, 1, 1, 3, 1, 0, 3, 1, 3])}
Test CustomData Files: 398
Test Data Files: 10
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining pooling layer...
Number of labels: 4
--> Loading pre-trained checkpoint...
Traceback (most recent call last):
  File "run_xlsr_nr.py", line 455, in <module>
    model.load_state_dict(torch.load(checkpoint), strict=True)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 1046, in _load
    result = unpickler.load()
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 1016, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/z5208494/.local/lib/python3.8/site-packages/torch/serialization.py", line 997, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch._UntypedStorage).storage()._untyped()
RuntimeError: PytorchStreamReader failed reading file data/7: invalid header or archive is corrupted
